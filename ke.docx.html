<p>Portable Systems Group</p>
<p>NT OS/2 Kernel Specification</p>
<p><strong>Author</strong>: David N. Cutler,<br />
Bryan M. Willman</p>
<p>Original Draft 1.0, March 8, 1989</p>
<p>Revision 1.1, March 16, 1989</p>
<p>Revision 1.2, March 29, 1989</p>
<p>Revision 1.3, April 18, 1989</p>
<p>Revision 1.4, May 4, 1989</p>
<p>Revision 1.5, May 8, 1989</p>
<p>Revision 1.6, August 14, 1989</p>
<p>Revision 1.7, November 15, 1989</p>
<p>Revision 1.8, November 16, 1989</p>
<p>Revision 1.9, November 17, 1989</p>
<p>Revision 1.10, January 6, 1990</p>
<p>Revision 1.11, June 6, 1990</p>
<p>Revision 1.12, September 19, 1990</p>
<p>Revision 1.13, March 11, 1991</p>
<p>Revision 1.14, May 2, 1991</p>
<p>Revision 1.15, May 28, 1991</p>
<p>Revision 1.16, June 18, 1991</p>
<p>Revision 1.17, August 7, 1991</p>
<p>Revision 1.18, August 8, 1991</p>
<p>.Begin Table C.</p>
<p>1. Overview 1</p>
<p>1.1 Kernel Execution Environment 1</p>
<p>1.2 Kernel Use of Hardware Priority Levels 2</p>
<p>1.3 Primary Kernel Data Structures 3</p>
<p>1.4 Multiprocessor Synchronization 4</p>
<p>1.4.1 Executive Multiprocessor Synchronization 6</p>
<p>1.4.1.1 Acquire Executive Spin Lock 6</p>
<p>1.4.1.2 Release Executive Spin Lock 7</p>
<p>1.5 Dispatching 7</p>
<p>1.5.1 Dispatcher Database 8</p>
<p>1.5.2 Idle Thread 8</p>
<p>2. Kernel Objects 9</p>
<p>2.1 Dispatcher Objects 9</p>
<p>2.1.1 Event Object 9</p>
<p>2.1.1.1 Initialize Event 11</p>
<p>2.1.1.2 Pulse Event 11</p>
<p>2.1.1.3 Read State Event 12</p>
<p>2.1.1.4 Reset Event 12</p>
<p>2.1.1.5 Set Event 12</p>
<p>2.1.2 Mutual Exclusion Objects 13</p>
<p>2.1.2.1 Mutant Object 14</p>
<p>2.1.2.1.1 Initialize Mutant 14</p>
<p>2.1.2.1.2 Read State Mutant 15</p>
<p>2.1.2.1.3 Release Mutant 15</p>
<p>2.1.2.2 Mutex Object 16</p>
<p>2.1.2.2.1 Initialize Mutex 17</p>
<p>2.1.2.2.2 Read State Mutex 17</p>
<p>2.1.2.2.3 Release Mutex 18</p>
<p>2.1.2.2.4 Mutex Contention Data 19</p>
<p>2.1.3 Semaphore Object 19</p>
<p>2.1.3.1 Initialize Semaphore 20</p>
<p>2.1.3.2 Read State Semaphore 20</p>
<p>2.1.3.3 Release Semaphore 20</p>
<p>2.1.4 Thread Object 21</p>
<p>2.1.4.1 Initialize Thread 24</p>
<p>2.1.4.2 Alert Thread 26</p>
<p>2.1.4.3 Alert and Resume Thread 27</p>
<p>2.1.4.4 Confine Thread 27</p>
<p>2.1.4.5 Delay Execution 28</p>
<p>2.1.4.6 Disable Queuing of APCs 29</p>
<p>2.1.4.7 Enable Queuing of APCs 29</p>
<p>2.1.4.8 Force Resumption of Thread 30</p>
<p>2.1.4.9 Freeze Thread 30</p>
<p>2.1.4.10 Query Data Alignment Mode 31</p>
<p>2.1.4.11 Query Base Priority 32</p>
<p>2.1.4.12 Read State Thread 32</p>
<p>2.1.4.13 Ready Thread 32</p>
<p>2.1.4.14 Resume Thread 33</p>
<p>2.1.4.15 Rundown Thread 33</p>
<p>2.1.4.16 Set Affinity Thread 34</p>
<p>2.1.4.17 Set Data Alignment Mode 34</p>
<p>2.1.4.18 Set Base Priority 35</p>
<p>2.1.4.19 Set Priority Thread 35</p>
<p>2.1.4.20 Suspend Thread 36</p>
<p>2.1.4.21 Terminate Thread 37</p>
<p>2.1.4.22 Test Alert Thread 37</p>
<p>2.1.4.23 Unfreeze Thread 38</p>
<p>2.1.4.24 Thread Performance Data 39</p>
<p>2.1.5 Timer Object 39</p>
<p>2.1.5.1 Initialize Timer 39</p>
<p>2.1.5.2 Cancel Timer 40</p>
<p>2.1.5.3 Read State Timer 40</p>
<p>2.1.5.4 Set Timer 40</p>
<p>2.2 Control Objects 41</p>
<p>2.2.1 Asynchronous Procedure Call (APC) Object 41</p>
<p>2.2.1.1 Initialize APC 43</p>
<p>2.2.1.2 Flush Queue APC 45</p>
<p>2.2.1.3 Insert Queue APC 46</p>
<p>2.2.1.4 Remove Queue APC 47</p>
<p>2.2.2 Deferred Procedure Call (DPC) Object 47</p>
<p>2.2.2.1 Initialize DPC 48</p>
<p>2.2.2.2 Insert Queue DPC 49</p>
<p>2.2.2.3 Remove Queue DPC 49</p>
<p>2.2.3 Device Queue Object 50</p>
<p>2.2.3.1 Initialize Device Queue 51</p>
<p>2.2.3.2 Insert Device Queue 51</p>
<p>2.2.3.3 Insert By Key Device Queue 52</p>
<p>2.2.3.4 Remove Device Queue 52</p>
<p>2.2.3.5 Remove Entry Device Queue 53</p>
<p>2.2.4 Interrupt Object 54</p>
<p>2.2.4.1 Initialize Interrupt 55</p>
<p>2.2.4.2 Connect Interrupt 58</p>
<p>2.2.4.3 Disconnect Interrupt 58</p>
<p>2.2.4.4 Synchronize Execution 59</p>
<p>2.2.5 Power Notify Object 60</p>
<p>2.2.5.1 Initialize Power Notify 61</p>
<p>2.2.5.2 Insert Power Notify 61</p>
<p>2.2.5.3 Remove Power Notify 62</p>
<p>2.2.6 Power Status Object 62</p>
<p>2.2.6.1 Initialize Power Status 63</p>
<p>2.2.6.2 Insert Power Status 63</p>
<p>2.2.6.3 Remove Power Status 64</p>
<p>2.2.7 Process Object 64</p>
<p>2.2.7.1 Initialize Process 65</p>
<p>2.2.7.2 Attach Process 66</p>
<p>2.2.7.3 Detach Process 67</p>
<p>2.2.7.4 Exclude Process 67</p>
<p>2.2.7.5 Include Process 68</p>
<p>2.2.7.6 Set Priority Process 68</p>
<p>2.2.7.7 Process Accounting Data 69</p>
<p>2.2.8 Profile Object 69</p>
<p>2.2.8.1 Initialize Profile 70</p>
<p>2.2.8.2 Start Profile 70</p>
<p>2.2.8.3 Stop Profile 71</p>
<p>2.2.8.4 Set System Profile Interval 71</p>
<p>2.2.8.5 Query System Profile Interval 72</p>
<p>3. Wait Operations 72</p>
<p>3.1 Wait For Multiple Objects 73</p>
<p>3.2 Wait For Single Object 75</p>
<p>4. Miscellaneous Operations 77</p>
<p>4.1 Bug Check 77</p>
<p>4.2 Context Frame Manipulation 78</p>
<p>4.2.1 Move Machine State To Context Frame 78</p>
<p>4.2.2 Move Machine State From Context Frame 79</p>
<p>4.3 Fill Entry Translation Buffer 80</p>
<p>4.4 Flush Data Cache 81</p>
<p>4.5 Flush Entire Translation Buffer 82</p>
<p>4.6 Flush Instruction Cache 82</p>
<p>4.7 Flush I/O Buffers 83</p>
<p>4.8 Flush Single Translation Buffer Entry 84</p>
<p>4.9 Freeze Execution 86</p>
<p>4.10 Get Current APC Environment 86</p>
<p>4.11 Get Current IRQL 86</p>
<p>4.12 Get Previous Mode 86</p>
<p>4.13 Lower IRQL 87</p>
<p>4.14 Query System Time 87</p>
<p>4.15 Raise IRQL 87</p>
<p>4.16 Run Down Thread 88</p>
<p>4.17 Set System Time 88</p>
<p>4.18 Stall Execution 89</p>
<p>4.19 Unfreeze Execution 89</p>
<p>5. Intel x86 Specific Functions. 90</p>
<p>5.1 Load an Ldt for a process. 90</p>
<p>5.2 Set and Entry in a Process's Ldt. 90</p>
<p>5.3 Get an Entry from a Thread's Gdt. 91</p>
<p>.End Table C.</p>
<h1 id="overview">1. Overview</h1>
<p>This specification describes the kernel layer of the <strong>NT
OS/2</strong> operating system. The kernel is responsible for thread
dispatching, multiprocessor synchronization, hardware exception
handling, and the implementation of low-level machine dependent
functions.</p>
<p>The kernel is used by the executive layer of the system to
synchronize its activities and to implement the higher levels of
abstraction that are exported in user-level API's.</p>
<p>Generally speaking, the kernel does not implement any policy since
this is the province of the executive. However, there are some places
where policy decisions are made by the kernel. These include the way in
which thread priority is manipulated to maximize responsiveness to
dispatching events (e.g., the input of a character from a keyboard).</p>
<p>The kernel executes entirely in kernel mode and is nonpageable. It
guards access to critical data by raising the processor Interrupt
Request Level (IRQL) to an appropriate level and then acquiring a spin
lock.</p>
<p>The primary functions provided by the kernel include:</p>
<p><strong>o</strong> Support of kernel objects</p>
<p><strong>o</strong> Trap handling and exception dispatching</p>
<p><strong>o</strong> Interrupt handling and dispatching</p>
<p><strong>o</strong> Multiprocessor coordination and context
switching</p>
<p><strong>o</strong> Power failure recovery</p>
<p><strong>o</strong> Miscellaneous hardware-specific functions</p>
<p>It is estimated that the kernel will be less than 48k bytes of
resident nonpageable code exclusive of the IEEE exception handling
code.</p>
<h2 id="kernel-execution-environment">1.1 Kernel Execution
Environment</h2>
<p>The kernel executes in the most privileged processor mode, usually at
an Interrupt Request Level (IRQL) of DISPATCH_LEVEL. The most privileged
processor mode is termed kernel mode.</p>
<p>\ On the N10 and the x86 architectures the most privileged processor
mode is called supervisor mode. However, in other architectures (e.g.,
MIPS), the most privileged processor mode is not called supervisor mode.
Furthermore, still other architectures include a supervisor mode, but it
is not the most privileged mode. Therefore, since it is intended that NT
OS/2 be portable and capable of running across several architectures,
the most privileged processor mode will be referred to as kernel mode.
\</p>
<p>The kernel can execute simultaneously on all processors in a
multiprocessor configuration and synchronize access to critical regions
as appropriate.</p>
<p>Software within the kernel is not preemptible and, therefore, cannot
be context switched, whereas all software outside the kernel is almost
always preemptible and context switchable. In general, executive
software outside the kernel is not allowed to raise the IRQL above
APC_LEVEL. However, device drivers and executive spin lock
synchronization are exceptions to this rule.</p>
<p>The kernel is not pageable and cannot take page faults.</p>
<p>Software within the kernel is written in <strong>C</strong> and
assembly language. Assembly language is used for:</p>
<p><strong>o</strong> Trap handling</p>
<p><strong>o</strong> Spin locks</p>
<p><strong>o</strong> Context switching</p>
<p><strong>o</strong> Interval timer interrupt</p>
<p><strong>o</strong> Power failure interrupt</p>
<p><strong>o</strong> Interprocessor interrupt</p>
<p><strong>o</strong> I/O Interrupt dispatching</p>
<p><strong>o</strong> Machine check processing</p>
<p><strong>o</strong> Asynchronous Procedure Call dispatching</p>
<p><strong>o</strong> Deferred Procedure Call dispatching</p>
<p><strong>o</strong> A small piece of thread startup</p>
<p><strong>o</strong> A small piece of system initialization</p>
<p>It is estimated that the number of lines of assembly code within the
kernel will be less than 3k.</p>
<h2 id="kernel-use-of-hardware-priority-levels">1.2 Kernel Use of
Hardware Priority Levels</h2>
<p>Hardware Interrupt Request Levels (IRQL's) are used to prioritize the
execution of the various kernel components. IRQL's are hierarchically
ordered and each distinct level disables interrupts on lower levels
while the respective level is active. The IRQL is raised when hardware
and software interrupt requests are granted and by the kernel when
synchronization with the possible occurrence of an interrupt is
desired.</p>
<p>The kernel uses the hardware Interrupt Request Levels (IRQL's) as
follows:</p>
<p>LOW_LEVEL - Thread execution</p>
<p>APC_LEVEL - Asynchronous Procedure Call interrupt</p>
<p>DISPATCH_LEVEL - Dispatch and Deferred Procedure Call interrupt</p>
<p>WAKE_LEVEL - Wake system debugger interrupt</p>
<p>Device levels - Device interrupts</p>
<p>CLOCK2_LEVEL - Interval timer clock interrupt</p>
<p>IPI_LEVEL - Interprocessor interrupt</p>
<p>POWER_LEVEL - Power failure interrupt</p>
<p>HIGH_LEVEL - Machine check and bus error interrupts</p>
<p>The level LOW_LEVEL is reserved for normal thread execution and
enables all other interrupts.</p>
<p>The levels APC_LEVEL and DISPATCH_LEVEL are software interrupts and
are requested only by the kernel itself. They are located below all
hardware interrupt priority levels.</p>
<p>The level WAKE_LEVEL may or may not be present depending on the host
hardware configuration and capabilities. It is intended for use in
notifying the kernel debugger.</p>
<p>Device interrupt levels are generally placed between the levels
WAKE_LEVEL and CLOCK2_LEVEL.</p>
<p>The levels CLOCK2_LEVEL, IPI_LEVEL, POWER_LEVEL, AND HIGH_LEVEL are
the highest priority levels and are the most time critical.</p>
<p>\ The exact specification of interrupt levels is dependent on the
host system architecture. The above discussion only defines the
importance of the various levels, and does not attempt to assign a
numeric value of each level. \</p>
<h2 id="primary-kernel-data-structures">1.3 Primary Kernel Data
Structures</h2>
<p>The primary kernel data structures include:</p>
<p><strong>o</strong> Interrupt Dispatch Table (IDT) - This is a
software maintained table that associates an interrupt source with an
Interrupt Service Routine (ISR).</p>
<p><strong>o</strong> Processor Control Registers (PCR's) - This is a
set of four registers that appear in the same physical address on each
processor in a multiprocessor configuration. These registers hold a
pointer to the Processor Control Block (PRCB), a pointer to the current
thread's Thread Environment Block (TEB), a pointer to the currently
active thread, and a temporary location used by the trap handler to save
the contents of the stack pointer. On a single processor implementation
the PCR is located in main memory.</p>
<p><strong>o</strong> Processor Control Block (PRCB) - This structure
holds per processor information such as a pointer to the next thread
selected for execution on the respective processor. There is a PRCB for
each processor in a multiprocessor configuration. The address of this
structure can always be obtained from a fixed virtual address on any
processor.</p>
<p><strong>o</strong> An array of pointers to PRCB's - This array is
used to address the PRCB of another processor. It is used when another
processor must be interrupted to performed some desired operation.</p>
<p><strong>o</strong> Kernel objects - These are the data abstractions
that are necessary to control processor execution and synchronization
(e.g., thread object, mutex object, etc.). Functions are provided to
initialize and manipulate these objects in a synchronized fashion.</p>
<p><strong>o</strong> Dispatcher database - This is the database that is
required to record the execution state of processors and threads. It is
used by the thread dispatcher to schedule the execution of threads on
processors.</p>
<p><strong>o</strong> Timer queue - This is a list of timers that are
due to expire at some future point in time. The timer queue is actually
implemented as a splay tree (nearly balanced binary tree maintained by
splay transformations).</p>
<p><strong>o</strong> Deferred Procedure Call (DPC) queue - This is a
list of requests to call a specified procedure when the IRQL falls below
DISPATCH_LEVEL.</p>
<p><strong>o</strong> Power restoration notify and status queues - These
are lists of power notify and status objects that are to be acted upon
if power fails and is later restored without the contents of volatile
memory being lost.</p>
<h2 id="multiprocessor-synchronization">1.4 Multiprocessor
Synchronization</h2>
<p>At various stages during its execution, the kernel must guarantee
that one, and only one, processor at a time is active within a given
critical region. This is necessary to prevent code executing on one
processor from simultaneously accessing and modifying data that is being
accessed and modified from another processor. The mechanism by which
this is achieved is called a <em>spin lock</em>.</p>
<p>Spin locks are used when mutual exclusion must exist across all
processors and context switching cannot take place. A spin lock takes
its name from the fact that, while waiting on the spin lock, software
continually tries to gain entry to a critical region and makes no
progress until it succeeds.</p>
<p>Spin locks are implemented with a test and set operation on a lock
variable. When software executes a test and set operation and finds the
previous state of the lock variable free, entry to the associated
critical region is granted. If, however, the previous state of the lock
variable is busy, then the test and set operation on the lock variable
is simply repeated until the previous state is found to be free.</p>
<p>\ The exact instructions that are used to implement spin locks are
processor architecture specific. In most architectures the test and set
operation is not repeated continuously, but rather once finding the lock
busy, ordinary instructions are used to poll the lock until it is free.
Another test and set operation is then performed to retest the lock.
This guarantees a minimum of bus contention during spin lock sequences.
\</p>
<p>Spin locks can only be operated on from a safe interrupt request
level. This means that any attempt to acquire a particular spin lock
must be at the highest IRQL from which any other attempt to acquire the
same spin lock could be made on the same processor. If this restriction
were not followed, then deadlock could occur when code running at a
lower IRQL acquired a spin lock and then was interrupted by a
higher-level interrupt whose Interrupt Service Routine (ISR) also
attempted to acquire the spin lock.</p>
<p>The kernel uses various spin locks to synchronize access to the
objects and data structures it supports. These include:</p>
<p><strong>o</strong> Dispatcher Database - The dispatcher database
describes the scheduling state of the system. Whenever a change is made
to the dispatching state of the system (e.g., the occurrence of an
event), the dispatcher database spin lock must be acquired at IRQL
DISPATCH_LEVEL.</p>
<p><strong>o</strong> Power Restoration Notify Queue - The power
restoration notify queue enables a device driver to be asynchronously
notified when power is restored after a failure. Whenever an insertion
or removal is made to/from this queue, the power notify queue spin lock
must be acquired at IRQL DISPATCH_LEVEL.</p>
<p><strong>o</strong> Power Restoration Status Queue - The power
restoration status queue provides the capability to have a specified
boolean variable set to a value of TRUE when power is restored after a
failure. Whenever an insertion or removal is made to/from this queue,
the power status queue spin lock must be acquired at IRQL
POWER_LEVEL.</p>
<p><strong>o</strong> Device Queues - A device queue is used to pass an
I/O Request Packet (IRP) between a thread and a device driver. Whenever
an insertion or removal is made to/from a device queue, the associated
device queue spin lock must be acquired at IRQL DISPATCH_LEVEL.</p>
<p><strong>o</strong> Interrupts - Each connected interrupt object has a
spin lock that prevents the associated Interrupt Service Routine (ISR)
from executing at the same time as other device driver code that
accesses the same device resources. Whenever an interrupt occurs and the
ISR executes, the associated spin lock must be acquired at the IRQL of
the interrupting source. Likewise, device driver code must acquire the
associated spin lock at the IRQL of the interrupting source when
synchronization with the ISR is required.</p>
<p><strong>o</strong> Processor Request Queue - Each processor has a
request queue that is used by other processors to signal an action to be
performed. Whenever an entry is inserted into or removed from this
queue, the associated processor request queue spin lock must be acquired
at IRQL IPI_LEVEL.</p>
<p><strong>o</strong> Kernel Debugger - The kernel debugger is used to
debug the kernel which can be in execution on several processors
simultaneously. Whenever the debugger is entered, the kernel debugger
spin lock must be acquired at IRQL HIGH_LEVEL.</p>
<p>/ The actual implementation of spin locks may be optimized in a
uniprocessor system. This could be done by either generating the system
specifically for a uniprocessor system with conditionalized code or by
dynamically modifying the code at boot time such that only IRQL is used
to synchronize kernel execution. /</p>
<h3 id="executive-multiprocessor-synchronization">1.4.1 Executive
Multiprocessor Synchronization</h3>
<p>Executive software outside the kernel also has the requirement to
synchronize access to resources in a multiprocessor environment. Unlike
the kernel, however, executive software can use kernel dispatcher
objects (e.g., mutexes, semaphores, events, etc.), as well as spin
locks, to implement mutually exclusive access.</p>
<p>Kernel dispatcher objects allow the processor to be redispatched
(context switched) and should be used when the wait or access time to a
resource is liable to be lengthy (e.g. greater than 25 microseconds on
an i860). Spin locks should be used when the wait or access time to a
resource is short and does not involve complicated interactions with
other code.</p>
<p>Executive spin locks could cause serious maintenance problems if not
used judiciously. In particular, no deadlock protection is performed and
dispatching is disabled while the executive owns a spin lock. Therefore,
certain rules must be followed by executive software when using spin
locks:</p>
<p>1. The code within a critical region that is guarded by an executive
spin lock must not be pageable and must not make any references to
pageable data.</p>
<p>2. An executive spin lock can only be acquired from IRQL's 0,
APC_LEVEL, and DISPATCH_LEVEL.</p>
<p>3. The code within a critical region that is guarded by an executive
spin lock cannot call any external procedures, nor can it generate any
software conditions or hardware exceptions.</p>
<p>Programming interfaces that support executive spin locks include:</p>
<p><strong>KeAcquireSpinLock</strong> - Acquire an executive spin
lock</p>
<p><strong>KeReleaseSpinLock</strong> - Release an executive spin
lock.</p>
<h4 id="acquire-executive-spin-lock">1.4.1.1 Acquire Executive Spin
Lock</h4>
<p>An executive spin lock can be acquired with the
<strong>KeAcquireSpinLock</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeAcquireSpinLock</strong> (</p>
<p><strong>IN</strong> <strong>PKSPIN_LOCK</strong>
<em>SpinLock</em>,</p>
<p><strong>OUT PKIRQL</strong> <em>OldIrql</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>SpinLock</em> - A pointer to an executive spin lock.</p>
<p><em>OldIrql</em> - A pointer to a variable that receives the previous
IRQL.</p>
<p>The previous IRQL is saved in the <em>OldIrql</em> parameter, the
current IRQL is raised to DISPATCH_LEVEL, and the specified spin lock is
acquired. The previous IRQL value must be specified when the spin lock
is released.</p>
<h4 id="release-executive-spin-lock">1.4.1.2 Release Executive Spin
Lock</h4>
<p>An executive spin lock can be released with the
<strong>KeReleaseSpinLock</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeReleaseSpinLock</strong> (</p>
<p><strong>IN</strong> <strong>PKSPIN_LOCK</strong>
<em>SpinLock</em>,</p>
<p><strong>IN</strong> <strong>KIRQL</strong> <em>OldIrql</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>SpinLock</em> - A pointer to an executive spin lock.</p>
<p><em>OldIrql</em> - The IRQL at which the executive spin lock was
acquired.</p>
<p>The specified spin lock is released and the current IRQL is set to
the specified value.</p>
<h2 id="dispatching">1.5 Dispatching</h2>
<p>The kernel dispatches threads for execution according to their
software priority level.</p>
<p>There are 32 levels of thread priority which are split into two
classes:</p>
<p><strong>o</strong> Realtime</p>
<p><strong>o</strong> Variable</p>
<p>The priority of threads within the realtime priority class is not
altered by the kernel. However, as quantum end events occur, the threads
within a level are round robin scheduled.</p>
<p>The priority of threads within the variable priority class is altered
by the kernel, dependent on the execution profile of the respective
threads. At each quantum end event, the priority of the executing thread
is decremented and a decision is made as to whether it should be
preempted by another thread. If it should be preempted to execute a
higher priority thread, then a context switch occurs. When a thread in
the variable priority class transitions from a Waiting state to a Ready
state, it is given a priority boost that is dependent on the type of
event that caused the Wait to be satisifed. If the event was keyboard
input, for instance, the thread would get a large boost. However, if the
event was file I/O it would be given a smaller boost.</p>
<p>When a thread is readied for execution, an attempt is made to
dispatch the thread on an idle processor. If an idle processor can be
selected, then preference is given to the last processor on which the
thread executed.</p>
<p>If an idle processor is not available, then an attempt is made to
find a processor that should be preempted. This determination is made
using the active summary and the active matrix (these structures are
described in the following two sections). If an appropriate processor is
located, then preference is given to the last processor on which the
thread executed.</p>
<p>If no processor can be preempted to execute the ready thread, the
thread is inserted at the end of the ready queue selected by its
priority and the ready summary is updated.</p>
<p>Giving preference to the last processor a thread executed on
maximizes the chances there is still thread data in the respective
processor's secondary cache.</p>
<h3 id="dispatcher-database">1.5.1 Dispatcher Database</h3>
<p>The kernel maintains several data structures to aid in choosing which
threads should be active at any instance in time. These structures
include:</p>
<p>o Ready queues - There is a ready queue for each software priority
level. Each queue contains a list of threads that are ready to execute
at that level.</p>
<p><strong>o</strong> Ready summary - A set that contains a TRUE member
for each ready queue that contains one or more threads.</p>
<p><strong>o</strong> Active matrix - The active matrix is a
two-dimensional array that represents a set of processors for each of
the software priority levels. A member is TRUE in the matrix if a
processor is executing a thread at the corresponding priority level.</p>
<p><strong>o</strong> Active summary - A set that contains a TRUE member
for each priority class that has one or more processors executing
threads at that level.</p>
<p><strong>o</strong> Idle summary - A set that contains a TRUE member
for each processor that is currently idle.</p>
<p><strong>o</strong> Idle thread - A thread that is run when no other
thread is available to execute on a processor.</p>
<p>The ready summary is used to quickly locate a thread to execute when
the currently executing thread is terminated or transitions to a Waiting
state.</p>
<p>The active summary is used to quickly determine if preemption should
occur when a thread transitions to a Ready state.</p>
<p>/ Since this determination is simple in a uniprocessor system, the
active summary and active matrix are only kept up to date and used on
configurations with multiple processors. /</p>
<h3 id="idle-thread">1.5.2 Idle Thread</h3>
<p>Each processor has an idle thread that can always execute. The idle
thread has a stack that is capable of nesting all interrupts and a
software priority that is below that of all other thread priority
levels.</p>
<p>The idle thread is selected for execution when no other thread is
available to execute. The idle thread executes at DISPATCH_LEVEL and
continually loops looking for work that has been assigned to its
processor. This work includes processing the Deferred Procedure Call
(DPC) queue and initiating a context switch when another thread is
selected for execution on the respective processor.</p>
<p>While an idle thread executes, the member in the idle summary
selected by its processor number is TRUE. This enables the kernel to
quickly determine which processors are executing idle threads.</p>
<h1 id="kernel-objects">2. Kernel Objects</h1>
<p>The kernel exports a set of abstractions to the executive layer which
are called <em>kernel objects</em>. Kernel objects are represented by a
control block that describes the contents of each object. Kernel objects
are used by the executive layer to construct more complex objects that
are exported in user level API's.</p>
<p>There are two types of kernel objects:</p>
<p>1. <em>Dispatcher</em> objects</p>
<p>2. <em>Control</em> objects</p>
<p>Dispatcher objects have a signal state (<em>Signaled</em> or
<em>Not-Signaled</em>) and control the dispatching and synchronization
of system operations. These objects include the <em>event</em>,
<em>mutant, mutex</em>, <em>semaphore</em>, <em>thread</em>, and
<em>timer</em> objects. Dispatcher objects can be specified as arguments
to the kernel Wait functions.</p>
<p>Control objects are used to control the operation of the kernel but
do not affect dispatching or synchronization. These objects include the
<em>Asynchronous Procedure Call</em> (APC), <em>Deferred Procedure
Call</em> (DPC), <em>device queue</em>, <em>interrupt</em>, <em>power
notify</em>, <em>power status</em>, <em>process</em>, and
<em>profile</em> objects.</p>
<p>The kernel neither allocates nor deallocates kernel object storage.
It is the responsibility of the executive layer to allocate an
appropriate data structure and call the kernel to initialize a specific
kernel object type.</p>
<p>The kernel exports kernel object types to the executive layer so the
executive can allocate appropriately sized data structures and can
access various read only data items (e.g., linkage pointers).</p>
<p>The executive is not allowed to manipulate the writeable data portion
of kernel objects directly. Various interfaces are provided by the
kernel to perform this type of operation.</p>
<p>Kernel objects are referenced by pointers to the respective data
structures. It is the responsibility of the executive layer to
synchronize the deallocation of kernel object storage such that the
kernel does not access an object after its storage has been deleted.</p>
<h2 id="dispatcher-objects">2.1 Dispatcher Objects</h2>
<p>This section describes the various types of dispatcher objects and
the interfaces that are provided to manipulate these objects.</p>
<h3 id="event-object">2.1.1 Event Object</h3>
<p>An <em>event</em> <em>object</em> is used to record the occurrence of
an event and synchronize it with some action that is to be
performed.</p>
<p>There are two types of event objects:</p>
<p>o <em>synchronization</em></p>
<p>o <em>notification</em></p>
<p>A synchronization event object is used when it is desirable for a
single waiter to continue execution when the event is set to the
Signaled state. The state of a synchronization event object is
automatically reset to the Not-Signaled state when a Wait for the event
object is satisfied.</p>
<p>Synchronization events provide an optimal way to implement mutual
exclusion at user level. An identical capability can be implemented
using binary semaphores, but requires calling the system each time
mutual exclusion is desired.</p>
<p>Synchronization events can also be used to provide synchronization in
producer/consumer relationships where it is otherwise undesirable to use
a counting semaphore.</p>
<p>A notification event is used when it is desirable for all waiters to
continue execution when the event is set to the Signaled state. The
state of a notification event object is not altered when a Wait for the
event object is satisfied and remains Signaled until it is explicitly
reset to the Not-Signaled state.</p>
<p>Notification events can be used to implement resource allocators
where there is not a one-to-one relationship between the release of a
resource and the allocation of the resource (e.g. a memory
allocator).</p>
<p>Waiting on an event object causes the execution of the subject thread
to be suspended until the event object attains a state of Signaled.</p>
<p>Satisfying the Wait for a synchronization event object automatically
causes the state of the event object to be reset to the Not-Signaled
state.</p>
<p>Satisfying the Wait for a notification event object does not cause
the state of the event object to change. Therefore, when a notification
event object attains a state of Signaled, an attempt is made to satisfy
as many Waits as possible.</p>
<p>The state of an event object is controlled by a count value that is
incremented each time the event object is set to the Signaled state.
Thus, the state of the event object is Signaled when the count value is
nonzero and Not-Signaled when the count value is zero.</p>
<p>The count value indicates the number of times that the event object
has been set to a Signaled state since the last time it was reset to the
Not-Signaled state.</p>
<p>Programming interfaces that support the event object include:</p>
<p><strong>KeInitializeEvent</strong> - Initialize an event object</p>
<p><strong>KePulseEvent</strong> - Set/reset event object state
atomically</p>
<p><strong>KeReadStateEvent</strong> - Read state of event object</p>
<p><strong>KeResetEvent</strong> - Set event object to Not-Signaled
state</p>
<p><strong>KeSetEvent</strong> - Set event object to Signaled state</p>
<h4 id="initialize-event">2.1.1.1 Initialize Event</h4>
<p>An event object can be initialized with the
<strong>KeInitializeEvent</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeEvent</strong> (</p>
<p><strong>IN</strong> <strong>PKEVENT</strong> <em>Event</em>,</p>
<p><strong>IN EVENT_TYPE</strong> <em>EventType</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>State</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Event</em> - A pointer to a dispatcher object of type event.</p>
<p><em>EventType</em> - The event type (<em>NotificationEvent</em> or
<em>SynchronizationEvent</em>).</p>
<p><em>State</em> - The initial state of the event.</p>
<p>The event object data structure for the specified event type is
initialized with the specified initial state.</p>
<h4 id="pulse-event">2.1.1.2 Pulse Event</h4>
<p>An event object can be atomically set to a Signaled state and then
reset to a Not-Signaled state with the <strong>KePulseEvent</strong>
function:</p>
<p><strong>LONG</strong></p>
<p><strong>KePulseEvent</strong> (</p>
<p><strong>IN</strong> <strong>PKEVENT</strong> <em>Event</em>,</p>
<p><strong>IN</strong> <strong>KPRIORITY</strong>
<em>Increment</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Wait</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Event</em> - A pointer to a dispatcher object of type event.</p>
<p><em>Increment</em> - The priority increment that is to be applied if
setting the event causes a Wait to be satisfied.</p>
<p><em>Wait</em> - A boolean value that specifies whether the call to
<strong>KePulseEvent</strong> will be IMMEDIATELY followed by a call to
one of the kernel Wait functions.</p>
<p>The function atomically sets the state of the event object to
Signaled, attempts to satisfy as many Waits as possible for the event
object, and then resets the state of the event object to
Not-Signaled.</p>
<p>The previous state of the event object is returned as the function
value. If the previous state of the event object was Signaled, then a
nonzero count value is returned. Otherwise, a value of zero is
returned.</p>
<p>If the <em>wait</em> parameter is TRUE, then the return to the caller
is executed without lowering IRQL or releasing the dispatcher database
spin lock. Thus the call to <strong>KePulseEvent</strong>
<strong>MUST</strong> be IMMEDIATELY followed by a call to one of the
kernel Wait functions. This capability is provided to allow the
executive to set an event and Wait as one atomic operation which
prevents a possible superfluous context switch.</p>
<h4 id="read-state-event">2.1.1.3 Read State Event</h4>
<p>The current state of an event object can be read with the
<strong>KeReadStateEvent</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeReadStateEvent</strong> (</p>
<p><strong>IN</strong> <strong>PKEVENT</strong> <em>Event</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Event</em> - A pointer to a dispatcher object of type event.</p>
<p>The current state of the event object is returned as the function
value. If the current state of the event object is Signaled, then a
nonzero count value is returned. Otherwise, a value of zero is
returned.</p>
<h4 id="reset-event">2.1.1.4 Reset Event</h4>
<p>An event object can be reset to a Not-Signaled state with the
<strong>KeResetEvent</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeResetEvent</strong> (</p>
<p><strong>IN</strong> <strong>PKEVENT</strong> <em>Event</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Event</em> - A pointer to a dispatcher object of type event.</p>
<p>The previous state of the event object is returned as the function
value and the state of the event object is reset to Not-Signaled (i.e.,
the count value is set to zero). If the previous state of the event
object was Signaled, then a nonzero count value is returned. Otherwise,
a value of zero is returned.</p>
<h4 id="set-event">2.1.1.5 Set Event</h4>
<p>An event object can be set to a Signaled state with the
<strong>KeSetEvent</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeSetEvent</strong> (</p>
<p><strong>IN</strong> <strong>PKEVENT</strong> <em>Event</em>,</p>
<p><strong>IN</strong> <strong>KPRIORITY</strong>
<em>Increment</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Wait</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Event</em> - A pointer to a dispatcher object of type event.</p>
<p><em>Increment</em> - The priority increment that is to be applied if
setting the event causes a Wait to be satisfied.</p>
<p><em>Wait</em> - A boolean value that specifies whether the call to
<strong>KeSetEvent</strong> will be IMMEDIATELY followed by a call to
one of the kernel Wait functions.</p>
<p>The previous state of the event object is returned as the function
value and the state of the event is set to Signaled (i.e., the count
value is incremented). If the previous state of the event object was
Signaled, then a nonzero count value is returned. Otherwise, a value of
zero is returned.</p>
<p>Setting an event object causes the event to attain a Signaled state,
and therefore, an attempt is made to satisfy as many Waits as possible
for the event object.</p>
<p>If the <em>Wait</em> parameter is TRUE, then the return to the caller
is executed without lowering IRQL or releasing the dispatcher database
spinlock. Thus the call to <strong>KeSetEvent</strong>
<strong>MUST</strong> be IMMEDIATELY followed by a call to one of the
kernel Wait functions. This capability is provided to allow the
executive to set an event and Wait as one atomic operation which
prevents a possible superfluous context switch.</p>
<h3 id="mutual-exclusion-objects">2.1.2 Mutual Exclusion Objects</h3>
<p>The kernel provides two objects for controlling mutually exclusive
access to a resource; the <em>mutant object</em> and the <em>mutex
object</em>.</p>
<p>The <em>mutant object</em> is intended for use in providing a user
mode mutual exclusion mechanism that has ownership semantics, but it can
also be used in kernel mode.</p>
<p>The <em>mutex object</em> can only be used in kernel mode and is
intended to provide a deadlock-free mutual exclusion mechanism with
ownership and other special system semantics.</p>
<p>The state of mutant and mutex objects is controlled by a count. When
the count is one, the mutant or mutex object is in the Signaled state,
the mutant or mutex object is not owned, and exclusive access to the
corresponding resource can be obtained by specifying the mutant or mutex
object in a kernel Wait function. When the count is not one, the mutant
or mutex object is in the Not-Signaled state and any attempt to acquire
the mutant or mutex object will cause the subject thread to wait until
the mutant or mutex object count is one.</p>
<p>Mutant and mutex objects are similar in that they both provide mutual
exclusion mechanisms with recursive ownership capability. They have
significant differences, however, which dictate the support of two
separate object types. These differences include the following:</p>
<p>o Mutex objects have a level number which is used to prevent
deadlock, whereas mutant objects have no level number.</p>
<p>o Mutant objects have an abandoned status and can be released by a
thread other than the owner, whereas mutex objects do not have an
abandoned status and can only be released by the owner thread.</p>
<p>o Owning a mutex object prevents the owning thread's process from
leaving the balance set, whereas owning a mutant object does not affect
the swapability of the parent process.</p>
<p>o Owning a mutex object causes the priority of the owning thread to
be raised to the greater of its current priority and the lowest realtime
priority, whereas owning a mutant object does not affect the owner
thread's priority in any way.</p>
<p>o Owning a mutex object prevents the delivery of kernel mode APCs,
whereas owning a mutant object does not affect the delivery of kernel
mode APCs.</p>
<h4 id="mutant-object">2.1.2.1 Mutant Object</h4>
<p>Waiting on (acquiring) a mutant object causes the execution of the
subject thread to be suspended until the mutant object attains a state
of Signaled. Satisfying the Wait for a mutant object causes the state of
the mutant object to become Not-Signaled.</p>
<p>Threads are allowed to recursively acquire mutant objects that they
already own. A recursively acquired mutant object must be released the
same number of times it was acquired before it will again attain the
state of Signaled.</p>
<p>Mutant objects can be exported to user mode for providing a mutual
exclusion mechanism with ownership semantics.</p>
<p>Programming interfaces that support the mutant object include:</p>
<p><strong>KeInitializeMutant</strong> - Initialize a mutant object</p>
<p><strong>KeReadStateMutant</strong> - Read the state of a mutant
object</p>
<p><strong>KeReleaseMutant</strong> - Release ownership of a mutant
object</p>
<h5 id="initialize-mutant">2.1.2.1.1 Initialize Mutant</h5>
<p>A mutant object can be initialized with the
<strong>KeInitializeMutant</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeMutant</strong> (</p>
<p><strong>IN</strong> <strong>PKMUTANT</strong> <em>Mutant</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong>
<em>InitialOwner</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Mutant</em> - A pointer to a dispatcher object of type
mutant.</p>
<p><em>InitialOwner</em> - A boolean variable that determines whether
the current thread is to be the initial owner of the mutant object.</p>
<p>If the value of the <em>InitialOwner</em> parameter is TRUE, then the
mutant object data structure is initialized with the current thread as
the owner and an initial state of Not-Signaled. Otherwise, the mutant
object data structure is initialized as unowned with an initial state of
Signaled.</p>
<h5 id="read-state-mutant">2.1.2.1.2 Read State Mutant</h5>
<p>The current state of a mutant object can be read with the
<strong>KeReadStateMutant</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeReadStateMutant</strong> (</p>
<p><strong>IN</strong> <strong>PKMUTANT</strong> <em>Mutant</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Mutant</em> - A pointer to a dispatcher object of type
mutant.</p>
<p>The current state of the mutant object is returned as the function
value. If the return value is one, then the state of the mutant object
is Signaled. Otherwise, the state of the mutant object is
Not-Signaled.</p>
<h5 id="release-mutant">2.1.2.1.3 Release Mutant</h5>
<p>A mutant object can be released with the
<strong>KeReleaseMutant</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeReleaseMutant</strong> (</p>
<p><strong>IN</strong> <strong>PKMUTANT</strong> <em>Mutant</em>,</p>
<p><strong>IN KPRIORITY</strong> <em>Increment</em>,</p>
<p><strong>IN BOOLEAN</strong> <em>Abandoned</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Wait</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Mutant</em> - A pointer to a dispatcher object of type
mutant.</p>
<p><em>Increment</em> - The priority increment that is to be applied if
releasing the mutant object causes a Wait to be satisfied.</p>
<p><em>Abandoned</em> - A boolean value that specifies whether the
release of the mutant object is to be forced.</p>
<p><em>Wait</em> - A boolean variable that specifies whether the call to
<strong>KeReleaseMutant</strong> will be IMMEDIATELY followed by a call
to one of the kernel Wait functions.</p>
<p>If the value of the <em>Abandoned</em> parameter is TRUE, then the
release of the mutant object is unconditional and can be requested by a
thread other than the owner of the mutant object. The fact that the
mutant object is being abandoned is recorded in the mutant object and is
returned by the kernel Wait services when ownership of the mutant object
is granted to another thread. Once set, the abandoned status of a mutant
object cannot be cleared and is thereafter always returned by the kernel
Wait services.</p>
<p>If the value of the <em>Abandoned</em> parameter is FALSE, then only
the owning thread can release the mutant object. Any attempt to release
the mutant object made by a thread other than the owner, will cause an
exception to be raised. If the mutant object has previously been
abandoned, then the exception STATUS_ABANDONED is raised. Otherwise, the
exception STATUS_MUTANT_NOT_OWNED is raised.</p>
<p>The previous state of the mutant object is returned as the function
value.</p>
<p>If the value of the <em>Abandoned</em> parameter is TRUE, then the
state of the mutant object is set to Signaled and the return value is
not meaningful.</p>
<p>If the value of the <em>Abandoned</em> parameter is FALSE, then the
new state of the mutant object can be determined by the value returned.
If the returned value is zero, then the mutant object was actually
released and attained a state of Signaled. Otherwise, the mutant object
was not released and still has a state of Not-Signaled (i.e., the mutant
object has been recursively acquired and has not yet been released the
proper number of times to cause it to attain a Signaled state).</p>
<p>If the mutant object attains a Signaled state, then an attempt is
made to satisfy a Wait for the mutant object.</p>
<p>If the mutant object attains a Signaled state and was previously
owned by a thread, then the mutant object is removed from the list of
mutant objects owned by the subject thread.</p>
<p>If the value of the <em>Wait</em> parameter is TRUE, then the return
to the caller is executed without lowering IRQL or releasing the
dispatcher database spin lock. Thus the call to
<strong>KeReleaseMutant</strong> <strong>MUST</strong> be IMMEDIATELY
followed by a call to one of the kernel Wait functions. This capability
is provided to allow the executive to release a mutant object and Wait
as one atomic operation which prevents a possible superfluous context
switch.</p>
<h4 id="mutex-object">2.1.2.2 Mutex Object</h4>
<p>Waiting on (acquiring) a mutex object causes the execution of the
subject thread to be suspended until the mutex object attains a state of
Signaled. Satisfying the Wait for a mutex object causes the state of the
mutex object to become Not-Signaled and disables the delivery of normal
kernel APCs to the subject thread.</p>
<p>If the subject thread did not previously own any mutexes, then the
current execution priority of the thread is saved and then raised to the
maximum of its current priority and the lowest realtime priority. This
ensures that the thread will have a very high execution priority while
it executes in a critical section and prevents the effects of priority
inversion. When the thread releases the last mutex it owns, its priority
is restored to the saved value.</p>
<p>Mutex ownership also prevents the owning thread's process from being
removed from the balance set. If the balance set manager selects the
process for removal from the balance set, all threads within the process
that own mutexes will be allowed to continue execution until they no
longer own any mutexes. This ensures that access to critical resources
is not blocked because a thread belonging to a process that has been
removed from the balance set owns one or more mutexes.</p>
<p>Each mutex object has a level number. This level number is used to
prevent possible deadlock. When an attempt is made to acquire a mutex
object, the level number of the mutex object must be higher
(numerically) than the highest level number of any mutex object owned by
the subject thread. If this condition is not met, then a system bug
check occurs.</p>
<p>Level number checking is included mainly for debugging the system
while it is under development. It may or may not be conditionalized out
in a production system.</p>
<p>Threads are allowed to recursively acquire mutex objects that they
already own. For this case level number checking does not occur since
deadlock is not possible. A recursively acquired mutex object must be
released the same number of times it was acquired before it will again
attain the state of Signaled.</p>
<p>Mutex objects are not exported by the executive to user mode and are
only available for use by the executive layer itself. Furthermore, the
executive is not allowed to acquire a mutex object and then return to
user mode while retaining ownership of the mutex.</p>
<p>Programming interfaces that support the mutex object include:</p>
<p><strong>KeInitializeMutex</strong> - Initialize a mutex object</p>
<p><strong>KeReadStateMutex</strong> - Read state of mutex object</p>
<p><strong>KeReleaseMutex</strong> - Release ownership of mutex
object</p>
<h5 id="initialize-mutex">2.1.2.2.1 Initialize Mutex</h5>
<p>A mutex object can be initialized with the
<strong>KeInitializeMutex</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeMutex</strong> (</p>
<p><strong>IN</strong> <strong>PKMUTEX</strong> <em>Mutex</em>,</p>
<p><strong>IN</strong> <strong>ULONG</strong> <em>Level</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Mutex</em> - A pointer to a dispatcher object of type mutex.</p>
<p><em>Level</em> - The level number that is to be assigned to the
mutex.</p>
<p>The mutex object data structure is initialized with the specified
level number and an initial state of Signaled.</p>
<h5 id="read-state-mutex">2.1.2.2.2 Read State Mutex</h5>
<p>The current state of a mutex object can be read with the
<strong>KeReadStateMutex</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeReadStateMutex</strong> (</p>
<p><strong>IN</strong> <strong>PKMUTEX</strong> <em>Mutex</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Mutex</em> - A pointer to a dispatcher object of type mutex.</p>
<p>The current state of the mutex object is returned as the function
value. If the return value is one, then the state of the mutex object is
Signaled. Otherwise, the state of the mutex object is Not-Signaled.</p>
<h5 id="release-mutex">2.1.2.2.3 Release Mutex</h5>
<p>A mutex object can be released with the
<strong>KeReleaseMutex</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeReleaseMutex</strong> (</p>
<p><strong>IN</strong> <strong>PKMUTEX</strong> <em>Mutex</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Wait</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Mutex</em> - A pointer to a dispatcher object of type mutex.</p>
<p><em>Wait</em> - A boolean variable that specifies whether the call to
<strong>KeReleaseMutex</strong> will be IMMEDIATELY followed by a call
to one of the kernel Wait functions.</p>
<p>The previous state of the mutex object is returned as the function
value. The state is returned as an integer value. If the returned value
is zero, then the mutex object was actually released and attained a
state of Signaled. Otherwise, the mutex object was not released and
still has a state of Not-Signaled (i.e the mutex object has been
recursively acquired and has not yet been released the proper number of
times to cause it to attain a Signaled state).</p>
<p>If the mutex object attains a Signaled state, then an attempt is made
to satisfy a Wait for the mutex object.</p>
<p>A mutex object can only be released by the subject thread that owns
the mutex. If an attempt is made to release a mutex that is not owned by
the subject thread, then a bug check will occur.</p>
<p>A mutex object can only be released if it is currently owned. An
attempt to release a mutex object whose current state is Signaled, will
also cause a bug check to occur.</p>
<p>If the mutex object attains a Signaled state, then the mutex object
is removed from the list of mutexes owned by the subject thread. If the
thread's owned mutex list does not contain any more entries, then the
thread's original priority is restored (the priority that was previously
saved) and a kernel APC is requested if the thread's kernel APC queue
contains one or more entries.</p>
<p>If the mutex object attains a Signaled state, the mutex was the last
one owned by the subject thread, and the thread's process has been
selected for removal from the balance set, then a new thread is selected
for execution, the subject thread is inserted into its process's ready
queue, and a context switch to the selected thread is performed. If no
other threads in the process own mutexes, then the balance set event is
set in the process object to notify the balance set manager that it can
remove the process from the balance set.</p>
<p>If the value of the <em>Wait</em> parameter is TRUE, then the return
to the caller is executed without lowering IRQL or releasing the
dispatcher database spin lock. Thus the call to
<strong>KeReleaseMutex</strong> <strong>MUST</strong> be IMMEDIATELY
followed by a call to one of the kernel Wait functions. This capability
is provided to allow the executive to release a mutex and Wait as one
atomic operation which prevents a possible superfluous context
switch.</p>
<h5 id="mutex-contention-data">2.1.2.2.4 Mutex Contention Data</h5>
<p>Two counters are maintained for each mutex object to determine the
activity level of the mutex object and any contention that may occur.
One of the counters records the number of times the mutex object has
been acquired and the other the number of times an attempt to acquire
the mutex object resulted in the execution of the subject thread being
suspended.</p>
<h3 id="semaphore-object">2.1.3 Semaphore Object</h3>
<p>A <em>semaphore object</em> is used to control access to a resource,
but not necessarily in a mutually exclusive fashion. A semaphore object
acts as a gate through which a variable number of threads may pass
concurrently, up to a specified limit. The gate is open (Signaled state)
as long as there are resources available. When the number of resources
specified by the limit are concurrently in use, the gate is closed
(Not-Signaled state).</p>
<p>The gating mechanism of a semaphore object is controlled by a count.
When the count is greater than zero, the semaphore object is in the
Signaled state, and one or more threads may pass through the gate by
specifying the semaphore in a kernel Wait function. When the count is
zero, the semaphore object is in the Not-Signaled state, the gate is
closed, and any attempt to pass through the gate will cause the subject
thread to Wait until the semaphore count is greater than zero.</p>
<p>Waiting on (acquiring) a semaphore object causes the execution of the
subject thread to be suspended until the semaphore object attains a
Signaled state. Satisfying the Wait for a semaphore object causes the
semaphore count to be decremented.</p>
<p>A semaphore object with a limit of one can be used to provide mutual
exclusion semantics since only one thread will be allowed to pass
through the gate concurrently. This is not, however, the same
functionality as provided by mutex objects since there is no ownership
(i.e., any thread can release the semaphore), there is no level number
checking (i.e., deadlock is not prevented), and the priority of the
subject thread is not raised (i.e., priority inversion problems can
arise).</p>
<p>A semaphore object with a limit of one can also be used as a
"<em>synchronization</em>" event provided the semaphore is never "over
Signaled" (i.e., no thread attempts to release the semaphore while it is
already in the Signaled state). For this case, the semaphore is normally
in a Not-Signaled state and is used to record the occurrence of an event
by releasing the semaphore. Waiting on the semaphore object suspends the
subject thread until the semaphore attains a Signaled state and causes
the semaphore to be immediately set to the Not-Signaled state.</p>
<p>Programming interfaces that support the semaphore object include:</p>
<p><strong>KeInitializeSemaphore</strong> - Initialize a semaphore
object</p>
<p><strong>KeReadStateSemaphore</strong> - Read state of semaphore</p>
<p><strong>KeReleaseSemaphore</strong> - Adjust semaphore object
count</p>
<h4 id="initialize-semaphore">2.1.3.1 Initialize Semaphore</h4>
<p>A semaphore object can be initialized with the
<strong>KeInitializeSemaphore</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeSemaphore</strong> (</p>
<p><strong>IN</strong> <strong>PKSEMAPHORE</strong>
<em>Semaphore</em>,</p>
<p><strong>IN</strong> <strong>LONG</strong> <em>Count</em>,</p>
<p><strong>IN</strong> <strong>LONG</strong> <em>Limit</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Semaphore</em> - A pointer to a dispatcher object of type
semaphore.</p>
<p><em>Count</em> - The initial count value to be assigned to the
semaphore. This value must be positive.</p>
<p><em>Limit</em> - The maximum count value that the semaphore can
attain. This value must be positive.</p>
<p>The semaphore object data structure is initialized with the specified
initial count and limit.</p>
<h4 id="read-state-semaphore">2.1.3.2 Read State Semaphore</h4>
<p>The current state of a semaphore object can be read with the
<strong>KeReadStateSemaphore</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeReadStateSemaphore</strong> (</p>
<p><strong>IN</strong> <strong>PKSEMAPHORE</strong>
<em>Semaphore</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Semaphore</em> - A pointer to a dispatcher object of type
semaphore.</p>
<p>The current signal state of the semaphore object is returned as the
function value. If the return value is zero, then the current state of
the semaphore object is Not-Signaled. Otherwise, the current state of
the semaphore object is Signaled.</p>
<h4 id="release-semaphore">2.1.3.3 Release Semaphore</h4>
<p>A semaphore object can be released with the
<strong>KeReleaseSemaphore</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeReleaseSemaphore</strong> (</p>
<p><strong>IN</strong> <strong>PKSEMAPHORE</strong>
<em>Semaphore</em>,</p>
<p><strong>IN</strong> <strong>KPRIORITY</strong>
<em>Increment</em>,</p>
<p><strong>IN</strong> <strong>LONG</strong> <em>Adjustment</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Wait</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Semaphore</em> - A pointer to a dispatcher object of type
semaphore.</p>
<p><em>Increment</em> - The priority increment that is to be applied if
releasing the semaphore causes a Wait to be satisfied.</p>
<p><em>Adjustment</em> - The value that is to be added to the current
semaphore count. This value must be positive.</p>
<p><em>Wait</em> - A boolean value that specifies whether the call to
<strong>KeReleaseSemaphore</strong> will be IMMEDIATELY followed by a
call to one of the kernel Wait functions.</p>
<p>Releasing a semaphore object causes the semaphore count to be
augmented by the value of the <em>Adjustment</em> parameter. If the
resultant value is greater than the limit of the semaphore object, then
the count is not adjusted and the exception
STATUS_SEMAPHORE_COUNT_EXCEEDED is raised.</p>
<p>Augmenting the semaphore object count causes the semaphore to attain
a state of Signaled, and therefore, an attempt is made to satisfy as
many Waits as possible for the semaphore object.</p>
<p>The previous state of the semaphore object is returned as an integer
function value. If the return value is zero, then the previous state of
the semaphore object was Not-Signaled. Otherwise, the previous state of
the semaphore object was Signaled.</p>
<p>If the value of the <em>wait</em> parameter is TRUE, then the return
to the caller is executed without lowering IRQL or releasing the
dispatcher database spin lock. Thus the call to
<strong>KeReleaseSemaphore</strong> <strong>MUST</strong> be IMMEDIATELY
followed by a call to one of the kernel Wait functions. This capability
is provided to allow the executive to release a semaphore and Wait as
one atomic operation which prevents a possible superfluous context
switch.</p>
<h3 id="thread-object">2.1.4 Thread Object</h3>
<p>A <em>thread object</em> is the agent that executes program code and
is dispatched for execution by the kernel.</p>
<p>Each thread is associated with a <em>process object</em> which
specifies the virtual address space mapping for the thread and
accumulates thread execution time. Several thread objects can be
associated with a single process object which enables the concurrent
execution of multiple threads in a single address space (possibly
simultaneous execution in a multiprocessor system).</p>
<p>A thread executes in kernel and user mode, usually at IRQL 0, and is
dispatched for execution according to its software priority.</p>
<p>Although there is no actual difference, threads are usually referred
to as either user threads or system threads. A user thread executes
mostly in user mode and within the user part of the virtual address
space. It enters kernel mode only to execute system services. System
threads execute only in kernel mode and usually within the system part
of the virtual address space. There are some system threads, however,
that also use the user part of the address space to store information
and execute code from. An example of such a thread is a file system.</p>
<p>The context of a thread typically consists of the following:</p>
<p><strong>o</strong> Integer registers</p>
<p><strong>o</strong> Floating point registers</p>
<p><strong>o</strong> Architecture-dependent special registers</p>
<p><strong>o</strong> A user stack pointer</p>
<p><strong>o</strong> A kernel stack pointer</p>
<p><strong>o</strong> A program counter</p>
<p><strong>o</strong> A processor status</p>
<p><strong>o</strong> A floating point status</p>
<p>\ The exact context of a thread is host architecture dependent. \</p>
<p>Each thread has a set of processors on which it can execute. This is
referred to as the processor affinity. When a thread is initialized it
is given the processor affinity of its parent process. Thereafter, the
affinity of the thread can be set to any proper subset of the parent
process's affinity.</p>
<p>A thread can be in one of six dispatcher, or scheduling, states:</p>
<p><strong>o</strong> <em>Initialized</em></p>
<p><strong>o</strong> <em>Ready</em></p>
<p><strong>o</strong> <em>Standby</em></p>
<p><strong>o</strong> <em>Running</em></p>
<p><strong>o</strong> <em>Waiting</em></p>
<p><strong>o</strong> <em>Terminated</em></p>
<p>A thread enters the <em>Initialized</em> state when its thread object
is initialized. A thread in the Initialized state can transition only to
the Ready state.</p>
<p>A thread is in a <em>Ready</em> state when it is eligible to be
selected for execution on a processor. A thread in the Ready state is
enqueued on the dispatcher ready queue selected by its priority and can
transition from the Ready state to the Standby state.</p>
<p>A thread is in a <em>Standby</em> state when it has been selected to
execute on a processor, but the actual context switch to the thread has
not yet occurred. A thread in the Standby state can transition to the
Ready and Running states.</p>
<p>A thread is in a <em>Running</em> state when it is currently being
executed by a processor. A thread in the Running state can transition to
the Ready, Waiting, and Terminated states.</p>
<p>A thread is in a <em>Waiting</em> state when it is waiting for one or
more dispatcher objects to attain a state of Signaled. A thread in the
Waiting state can transition to the Ready state.</p>
<p>A thread in the <em>Terminated</em> state has completed its execution
and the corresponding thread object will be deleted by the executive at
the appropriate time.</p>
<p>/ Note that is possible to reuse a thread object that has a state of
Terminated by simply reinitializing the thread object which will cause
it to enter the Initialized state. /</p>
<p>A thread's parent process is either in the balance set (Included) or
not in the balance set (Excluded). The balance set is that set of
processes and threads that are currently eligible for being considered
for execution. Processes and threads that are not in the balance set are
not considered for execution until they reenter the balance set.</p>
<p>The balance set is managed by the balance set manager. In a single
user system there will be no balance set manager. Server systems,
however, present the problem of having to manage more processes than
there is space for in main memory without incurring excessive paging.
Therefore, the balance set manager is responsible for determining when
excessive paging is occurring and then selecting the appropriate
processes to remove from the balance set.</p>
<p>/ There may not be a balance set manager in the first release of NT
OS/2. We may rely instead on working set trimming to obtain necessary
memory when excessive paging levels are observed. /</p>
<p>A thread is dispatched for execution according to its software
priority level. Higher priority threads are given preference and preempt
the execution of lower priority threads.</p>
<p>There are two classes of priority: 1) realtime, and 2) variable. Each
of these classes contains several levels of thread priority.</p>
<p>In the realtime priority class, a thread executes at a priority level
selected by the user. The system makes no attempt to alter or boost the
priority as the thread executes and enters and leaves wait states. The
realtime priority levels are higher than all the levels in the variable
priority class. The realtime priority class is intended for use by
time-critical threads that require a response time that is guaranteed by
application design.</p>
<p>The variable priority class is where most threads execute. As a
thread executes and experiences quantum end events, its priority decays.
When a thread enters a Waiting state and is subsequently awakened, it is
given a priority boost that is commensurate with the importance of the
event that caused the Wait to be satisifed (e.g., a large boost is given
for the completion of keyboard input but a small one is given for
completing disk I/O). A thread therefore, runs at a high priority as
long as it is interactive. When it becomes compute bound, its priority
rapidly decays, and it is considered only after other, higher priority
threads. In addition, the kernel arbitrarily boosts the priority of
threads that are compute bound and haven't received any processor time
for a given period of time.</p>
<p>As a thread executes, performance and accounting data are collected
for the thread and for the thread's parent process.</p>
<p>Programming interfaces that support the thread object include:</p>
<p><strong>KeInitializeThread</strong> - Initialize a thread object</p>
<p><strong>KeAlertThread</strong> - Set thread alert for specified
mode</p>
<p><strong>KeAlertResumeThread</strong> - Alert and resume thread
object</p>
<p><strong>KeConfineThread</strong> - Confine thread object
execution</p>
<p><strong>KeDelayExecutionThread</strong> - Delay execution of thread
object</p>
<p><strong>KeDisableApcQueuingThread</strong> - Disable queuing of
APCs</p>
<p><strong>KeEnableApcQueuingThread</strong> - Enable queuing of
APCs</p>
<p><strong>KeForceResumeThread</strong> - Force resumption of thread
execution</p>
<p><strong>KeFreezeThread</strong> - Freeze thread object execution</p>
<p><strong>KeQueryAutoAlignmentThread</strong> - Query alignment mode of
thread object</p>
<p><strong>KeQueryBasePriorityThread</strong> - Query base priority of
thread object</p>
<p><strong>KeReadStateThread</strong> - Read state of thread object</p>
<p><strong>KeReadyThread</strong> - Ready thread object for
execution</p>
<p><strong>KeResumeThread</strong> - Resume thread object execution</p>
<p><strong>KeRundownThread</strong> - Run down thread object</p>
<p><strong>KeSetAffinityThread</strong> - Set thread object processor
set</p>
<p><strong>KeSetAutoAlignmentThread</strong> - Set alignment mode of
thread object</p>
<p><strong>KeSetBasePriorityThread</strong> - Set base priority of
thread object</p>
<p><strong>KeSetPriorityThread</strong> - Set priority of thread
object</p>
<p><strong>keSuspendThread</strong> - Suspend thread object exection</p>
<p><strong>KeTerminateThread</strong> - Terminate thread object
execution</p>
<p><strong>KeTestAlertThread</strong> - Test if thread alerted for
mode</p>
<p><strong>KeUnfreezeThread</strong> - Unfreeze thread object
execution</p>
<h4 id="initialize-thread">2.1.4.1 Initialize Thread</h4>
<p>A thread object can be initialized with the
<strong>KeInitializeThread</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>KernelStack</em>,</p>
<p><strong>IN PKSYSTEM_ROUTINE</strong> <em>SystemRoutine</em>,</p>
<p><strong>IN</strong> <strong>PKSTART_ROUTINE</strong>
<em>StartRoutine</em> <strong>OPTIONAL</strong>,</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>StartContext</em>
<strong>OPTIONAL</strong>,</p>
<p><strong>IN PCONTEXT</strong> <em>ContextFrame</em>
<strong>OPTIONAL</strong>,</p>
<p><strong>IN PVOID</strong> <em>Teb</em> <strong>OPTIONAL</strong>,</p>
<p><strong>IN</strong> <strong>PKPROCESS</strong> <em>Process</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p><em>KernelStack</em> - A pointer to the base (highest address) of a
kernel stack on which the initial context for the thread is to be
constructed.</p>
<p><em>SystemRoutine</em> - A pointer to a function that is to called
when the thread is scheduled for execution. This routine performs
executive initialization.</p>
<p><em>StartRoutine</em> - An optional pointer to a function that is to
be called after the executive has finished initializing the thread.</p>
<p><em>StartContext</em> - A optional pointer to an arbitrary data
structure which will be passed to the <em>StartRoutine</em> function as
a parameter.</p>
<p><em>ContextFrame</em> - An optional pointer to a context frame which
contains the initial user mode state of the thread. This parameter is
specified if the thread will execute in user mode. If this parameter is
not specified, then the <em>Teb</em> parameter is ignored.</p>
<p><em>Teb</em> - An optional pointer to the user mode thread
environment block. This parameter is ignored if the
<em>ContextFrame</em> parameter is not specified.</p>
<p><em>Process</em> - A pointer to a control object of type process.</p>
<p>The function specified by the <em>SystemRoutine</em> parameter has
the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>VOID</strong></p>
<p>(<strong>*PKSYSTEM_ROUTINE</strong>) (</p>
<p><strong>IN PKSTART_ROUTINE</strong> <em>StartRoutine</em>
<strong>OPTIONAL</strong>,</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>StartContext</em>
<strong>OPTIONAL</strong></p>
<p>)<strong>;</strong></p>
<p><u>Parameters:</u></p>
<p><em>StartRoutine</em> - An optional pointer to a function that is to
be called after the executive has finished initializing the thread.</p>
<p><em>StartContext</em> - A optional pointer to an arbitrary data
structure which will be passed to the <em>StartRoutine</em> function as
a parameter.</p>
<p>The function specified by the <em>StartRoutine</em> parameter has the
following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>VOID</strong></p>
<p>(<strong>*PKSTART_ROUTINE</strong>) (</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>StartContext</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>StartContext</em> - A pointer to an arbitrary data structure that
was specified when the thread object was initialized.</p>
<p>The thread object data structure is initialized and the thread's
dispatcher state is set to Initialized. The thread's quantum, affinity,
data alignment handling mode, current priority, and base priority are
taken from the parent process object.</p>
<p>A kernel context frame is built on the specified kernel stack which
will cause the thread to begin execution in the kernel thread startup
routine. The kernel thread startup routine will call the specified start
routine which is responsible for initializing the executive state of the
thread as necessary. If the thread is a system thread, then the
executive startup routine will call the thread's entry point directly.
If, however, the thread is a user thread, then the executive startup
routine returns control to the kernel thread startup routine which
restores the user mode state and continues execution of the thread in
user mode.</p>
<p>A thread begins execution in kernel mode at IRQL APC_LEVEL with the
queuing of APCs enabled. It is the responsibility of the executive to
lower IRQL to 0 as soon as thread initialization is complete.</p>
<p>Once a thread object has been initialized, it can be readied for
execution with the <strong>KeReadyThread</strong> function.</p>
<h4 id="alert-thread">2.1.4.2 Alert Thread</h4>
<p>A thread object can be alerted with the
<strong>KeAlertThread</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeAlertThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN</strong> <strong>KPROCESSOR_MODE</strong>
<em>AlertMode</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p><em>AlertMode</em> - The processor mode (<em>UserMode</em> or
<em>KernelMode</em>) for which the thread is to be alerted.</p>
<p>Alerting a thread object causes the alert variable associated with
the specified processor mode to be set to a value of TRUE.</p>
<p>If the thread object is currently in a Wait state, the Wait is
alertable, and the specified processor mode is less than or equal to the
Wait mode, then the thread is Unwaited with a completion status of
<em>STATUS_ALERTED</em> and the specified alert variable is set to a
value of FALSE.</p>
<p>Alerts provide a way in which to break into a thread's execution at
well-defined points. These points occur when the thread Waits in an
alertable state and when the thread polls the alerted flag using the
<strong>KeTestAlertThread</strong> function.</p>
<p>The previous value of the alert variable for the specified processor
mode is returned as the function value. If the return value is TRUE,
then the subject thread was already alerted for the specified processor
mode. If the return value is FALSE, then the subject thread was not
previously alerted.</p>
<h4 id="alert-and-resume-thread">2.1.4.3 Alert and Resume Thread</h4>
<p>A thread object can be kernel mode alerted and its execution resumed
with the <strong>KeAlertResumeThread</strong> function:</p>
<p><strong>ULONG</strong></p>
<p><strong>KeAlertResumeThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>This function executes the equivalent of a
<strong>KeAlertThread</strong> function for kernel mode followed by a
<strong>KeResumeThread</strong> function on the specified thread
object.</p>
<p>Resuming a thread object checks the suspend count of the subject
thread. If the suspend count is zero, then the thread is not currently
suspended and no operation is performed. Otherwise, the subject thread's
suspend count is decremented. If the resultant value is zero, then the
execution of the subject thread is resumed by releasing its builtin
suspend semaphore.</p>
<p>The previous suspend count is returned as the function value. If the
return value is zero, then the subject thread was not previously
suspended. If the return value is one, then the subject thread's
execution was resumed. If the returned value is not zero or one, then
the subject thread is still suspended and must be resumed the number of
times specified by the return value minus one before it will actually
resume execution.</p>
<h4 id="confine-thread">2.1.4.4 Confine Thread</h4>
<p>The execution of the current thread can be confined to the current
processor with the <strong>KeConfineThread</strong> function:</p>
<p><strong>KAFFINITY</strong></p>
<p><strong>KeConfineThread</strong> (</p>
<p>);</p>
<p>Confining the execution of the current thread to the current
processor causes the thread's affinity to be set such that it can only
execute on the current processor. The previous affinity is returned as
the function value and can be used to later restore the thread's
affinity with the <strong>KeSetAffinityThread</strong> function.</p>
<p>This function is useful when it is desirable to avoid translation
buffer flushes across the entire multiprocessor complex while certain
page manipulations are taking place. For example, the zero page writer
selects a page to zero, confines its execution to the current processor,
flushes the current processor's translation buffer, maps the page into
the system part of the virtual address space reserved for zeroing pages,
and then proceeds to zero the page. If the execution of the zero page
writer was not confined during the page zeroing operation, then the
translation buffers of all processors in the multiprocessor complex
would have to be flushed before mapping and zeroing the page could
commence.</p>
<h4 id="delay-execution">2.1.4.5 Delay Execution </h4>
<p>The execution of the current thread can be delayed for a specified
interval of time with the <strong>KeDelayExecutionThread</strong>
function:</p>
<p><strong>NTSTATUS</strong></p>
<p><strong>KeDelayExecutionThread</strong> (</p>
<p><strong>IN</strong> <strong>KPROCESSOR_MODE</strong>
<em>WaitMode</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Alertable</em>,</p>
<p><strong>IN</strong> <strong>PTIME</strong> <em>Interval</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>WaitMode</em> - The processor mode on whose behalf the Wait is
occurring.</p>
<p><em>Alertable</em> - A boolean value that specifies whether the Wait
is alertable.</p>
<p><em>Interval</em> - The absolute or relative time over which the Wait
is to occur.</p>
<p>The expiration time is computed and the current thread is put in a
Waiting state. When the specified interval of time has passed, the
thread will exit the Waiting state and continue execution.</p>
<p>The reason for the Wait is set to DelayExecution.</p>
<p>The <em>WaitMode</em> parameter specifies on whose behalf the Wait is
occurring (i.e., kernel or user).</p>
<p>The <em>Alertable</em> parameter specifies whether the thread can be
alerted while it is in the Waiting state. If the value of this parameter
is TRUE and the thread is alerted for a mode that is equal to or more
privileged than the Wait mode, then the thread's Wait will be satisfied
with a completion status of STATUS_ALERTED.</p>
<p>If the <em>WaitMode</em> parameter is <em>UserMode</em> and the
<em>Alertable</em> parameter TRUE, then the thread can also be awakened
to deliver a user mode APC. Kernel mode APCs always cause the subject
thread to be awakened if the Wait IRQL is zero and no kernel APC is in
progress.</p>
<p>The expiration time of the delay is expressed as either an absolute
time at which the delay is to expire, or time that is relative to the
current system time. If the value of the <em>Interval</em> parameter is
negative, then the expiration time is relative. Otherwise, the
expiration time is absolute.</p>
<p>The value returned by <strong>KeDelayExecutionThread</strong>
function determines how the delay was completed.</p>
<p>A value of STATUS_SUCCESS is returned if the delay was completed
because the specified interval of time elapsed.</p>
<p>A value of STATUS_ALERTED is returned if the delay was completed
because the thread was alerted.</p>
<p>A value of STATUS_USER_APC is returned if a user mode APC is to be
delivered.</p>
<h4 id="disable-queuing-of-apcs">2.1.4.6 Disable Queuing of APCs</h4>
<p>The queuing of APCs to a thread object can be disabled with the
<strong>KeDisableApcQueuingThread</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeDisableApcQueuingThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Disabling the queuing of APCs to a thread object causes any attempt
to direct an APC to the thread to be ignored.</p>
<p>During the termination of a thread, the executive must run down and
clean up all thread data structures. When the APC queue itself is
processed, the executive first disables APCs and then flushes the APC
queue.</p>
<p>The previous value of the APC queuable state is returned as the
function value. If the return value is TRUE, then APC queuing was
previously enabled. Otherwise, a value of FALSE is returned and APC
queuing was disabled.</p>
<h4 id="enable-queuing-of-apcs">2.1.4.7 Enable Queuing of APCs</h4>
<p>The queuing of APCs to a thread object can be enabled with the
<strong>KeEnableApcQueuingThread</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeEnableApcQueuingThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Enabling the queuing of APCs to a thread object allows APC objects to
be inserted in the subject thread's APC queue for subsequent delivery
when conditions permit.</p>
<p>The previous value of the APC queuable state is returned as the
function value. If the return value is TRUE, then APC queuing was
previously enabled. Otherwise, a value of FALSE is returned and APC
queuing was disabled.</p>
<h4 id="force-resumption-of-thread">2.1.4.8 Force Resumption of
Thread</h4>
<p>A thread object's execution can be forced to resume with the
<strong>KeForceResumeThread</strong> function:</p>
<p><strong>ULONG</strong></p>
<p><strong>KeForceResumeThread</strong> (</p>
<p><strong>IN PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Forcing the resumption of a thread object's execution checks the
suspend and freeze count of the subject thread. If both counts are zero,
then the thread is not currently suspended and no operation is
performed. Otherwise, the subject thread's suspend and freeze counts are
both set to zero, and the execution of the subject thread is resumed by
releasing its builtin suspend semaphore.</p>
<p>The sum of the previous suspend and freeze counts is returned as the
function value. If the return value is zero, then the subject thread was
not previously suspended. Otherwise, the subject thread was suspended
and its execution was resumed.</p>
<p>This function is intended for use by the executive when it wants to
terminate the execution of a thread that may be in a suspended
state.</p>
<h4 id="freeze-thread">2.1.4.9 Freeze Thread</h4>
<p>The execution of a thread object can be frozen with the
<strong>KeFreezeThread</strong> function:</p>
<p><strong>ULONG</strong></p>
<p><strong>KeFreezeThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Freezing a thread object causes the thread's freeze count to be
incremented. If incrementing the freeze count would cause it to
overflow, then the count is not incremented and the exception
STATUS_SUSPEND_COUNT_EXCEEDED is raised. Otherwise, the freeze count is
incremented. If the resultant value is one and the suspend count is
zero, then the thread's builtin suspend APC object is queued.</p>
<p>When the suspend APC is delivered to the subject thread, a
nonalertable Wait on the thread's builtin semaphore object is executed
which freezes thread execution. The subject thread can be subsequently
unfrozen with the <strong>KeUnfreezeThread</strong> function.</p>
<p>The previous freeze count is returned as the function value. If the
return value is zero, then the subject thread was not previously frozen.
Otherwise, the thread was previously frozen and must be unfrozen the
number of times specified by the return value plus one before it will
actually resume execution.</p>
<p>The freeze and unfreeze functions are similar to the suspend and
resume functions, but are intended for use by system software as opposed
to being exported to users. The freeze and unfreeze functions are used
to suspend and resume thread execution during debugging operations.</p>
<h4 id="query-data-alignment-mode">2.1.4.10 Query Data Alignment
Mode</h4>
<p>The data alignment handling mode for the current thread can be
queried with the <strong>KeQueryAutoAlignmentThread</strong>
function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeQueryAutoAlignmentThread</strong> (</p>
<p>)</p>
<p>The data alignment handling mode for the current thread is returned
as the function value. A value of TRUE is returned if user mode data
alignment exceptions are automatically handled by the kernel and are not
raised as exceptions. Otherwise, user mode data alignment exceptions are
not handled by the kernel and may, or may not, be raised as exceptions
depending on host hardware capabilities. Automatic handling of user mode
data alignment exceptions means that the kernel emulates misaligned data
references and completes the offending instructions as if no
misalignment exception had occurred. Misaligned references in kernel
mode are never automatically handled and are always raised as
exceptions.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>Certain processors (e.g., the i386) always handle misaligned data in
hardware. On these processors, enabling or disabling the automatic
handling of data alignment exceptions has no effect. On other processors
(e.g., i486, MIPS r3000, r4000SP, and r4000MP) the handling of
misaligned data is handled according to the mode established for the
respective thread.</p>
<h4 id="query-base-priority">2.1.4.11 Query Base Priority</h4>
<p>The base priority of a thread object can be queried with the
<strong>KeQueryBasePriorityThread</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeQueryBasePriorityThread</strong> (</p>
<p><strong>IN PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>The base priority increment of the specified thread is returned as
the function value. The base priority increment is defined as the
difference between the specified thread's base priority and the base
priority of the thread's process.</p>
<h4 id="read-state-thread">2.1.4.12 Read State Thread</h4>
<p>The current state of a thread object can be read with the
<strong>KeReadStateThread</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeReadStateThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>The current state of the thread object is returned as the function
value. If the current state of the thread is Signaled, then a value of
TRUE is returned. Otherwise, a value of FALSE is returned.</p>
<h4 id="ready-thread">2.1.4.13 Ready Thread</h4>
<p>A thread object can be readied for execution with the
<strong>KeReadyThread</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeReadyThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Readying a thread object causes the thread to be considered for
immediate execution on a processor.</p>
<p>If the thread's process is not in the balance set, then the thread's
dispatching state is set to Ready and the thread object is inserted in
the process' ready queue. Otherwise, an attempt is made to dispatch the
thread on one of the processors in the multiprocessor complex. If the
priority of the subject thread is greater than the priority of one or
more threads running on processors that the subject thread can also run
on, then the thread with the lowest priority is selected for preemption,
the subject thread's dispatching state is set to Standby and an
interprocessor interrupt is sent to the target processor to cause it to
redispatch. Otherwise, the subject thread's dispatching state is set to
Ready and the thread is inserted at the tail of the dispatcher ready
queue selected by its priority.</p>
<h4 id="resume-thread">2.1.4.14 Resume Thread</h4>
<p>The execution of a thread object can be resumed with the
<strong>KeResumeThread</strong> function:</p>
<p><strong>ULONG</strong></p>
<p><strong>KeResumeThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Resuming a thread object checks the suspend count of the subject
thread. If the suspend count is zero, then the thread is not currently
suspended and no operation is performed. Otherwise, the subject thread's
suspend count is decremented. If the resultant value is zero and the
freeze count is also zero, then the execution of the subject thread is
resumed by releasing its builtin suspend semaphore.</p>
<p>The previous suspend count is returned as the function value. If the
return value is zero, then the subject thread was not previously
suspended. If the return value is one, then the subject thread's
execution was resumed. If the returned value is not zero or one, then
the subject thread is still suspended and must be resumed the number of
times specified by the return value minus one before it will actually
resume execution.</p>
<p>The suspend and resume functions are similar to the freeze and
unfreeze functions, but are usable from both system and user software.
The freeze and unfreeze functions are used to suspend and resume thread
execution during debugging operations.</p>
<h4 id="rundown-thread">2.1.4.15 Rundown Thread</h4>
<p>The current thread object can be run down with the
<strong>KeRundownThread</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeRundownThread</strong> (</p>
<p>);</p>
<p>This function runs down thread structures that are guarded by the
dispatcher database lock and which must be processed before actually
terminating the thread. An example of such a data structure is the
mutant ownership list that is anchored in the thread object.</p>
<h4 id="set-affinity-thread">2.1.4.16 Set Affinity Thread</h4>
<p>The affinity of a thread object can be set with the
<strong>KeSetAffinity</strong> function:</p>
<p><strong>KAFFINITY</strong></p>
<p><strong>KeSetAffinityThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN</strong> <strong>KAFFINITY</strong> <em>Affinity</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p><em>Affinity</em> - The new set of processors on which the thread can
run.</p>
<p>Setting the affinity of a thread object establishes a new set of
processors on which the thread can execute. The new affinity must be a
subset of the parent process's affinity. If the new affinity is zero, or
is not a subset of the parent process's affinity, then an error
condition is raised. Otherwise, the new affinity of the thread is set,
and the previous affinity is returned as the function value.</p>
<p>If the dispatching state of the thread object is Running or Standby
and the new affinity is such that the thread cannot execute on the
target processor, then a new thread is selected for execution and an
interprocessor interrupt is sent to the target processor.</p>
<h4 id="set-data-alignment-mode">2.1.4.17 Set Data Alignment Mode</h4>
<p>The data alignment handling mode for the current thread can be set
with the <strong>KeSetAutoAlignmentThread</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeSetAutoAlignmentThread</strong> (</p>
<p><strong>IN BOOLEAN</strong> <em>Enable</em></p>
<p>)</p>
<p><u>Parameters:</u></p>
<p><em>Enable</em> - A boolean variable that specifies the handling mode
for data alignment exceptions in the current thread.</p>
<p>The <em>Enable</em> parameter specifies the handling mode for data
alignment exceptions in the current thread. If this parameter is TRUE,
then user mode data alignment exceptions are automatically handled by
the kernel and are not raised as exceptions. Otherwise, user mode data
alignment exceptions are not handled by the kernel and may, or may not,
be raised as exceptions depending on host hardware capabilities.
Automatic handling of user mode data alignment exceptions means that the
kernel emulates misaligned data references and completes the offending
instructions as if no misalignment exception had occurred. Misaligned
references in kernel mode are never automatically handled and are always
raised as exceptions.</p>
<p>The previous data alignment handling mode is returned as the function
value.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>Certain processors (e.g., the i386) always handle misaligned data in
hardware. On these processors, enabling or disabling the automatic
handling of data alignment exceptions has no effect. On other processors
(e.g., i486, MIPS r3000, r4000SP, and r4000MP) the handling of
misaligned data is handled according to the mode established for the
respective thread.</p>
<h4 id="set-base-priority">2.1.4.18 Set Base Priority</h4>
<p>The base priority of a thread object can be set with the
<strong>KeSetBasePriorityThread</strong> function:</p>
<p><strong>LONG</strong></p>
<p><strong>KeSetBasePriorityThread</strong> (</p>
<p><strong>IN PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN LONG</strong> <em>Increment</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p><em>Increment</em> - The base priority increment that is to be
applied to the specified thread.</p>
<p>The new base priority is computed by adding the specified priority
increment to the base priority of the specified thread's process. The
resultant value is stored as the base priority of the specified
thread.</p>
<p>The new base priority is restricted to the priority class of the
specified thread's process. This means that the base priority is not
allowed to cross over from a realtime priority class to a variable
priority class or vice versa.</p>
<p>The previous base priority increment of the specified thread is
returned as the function value. The previous base priority increment is
defined as the difference between the specified thread's old base
priority and the base priority of the thread's process.</p>
<h4 id="set-priority-thread">2.1.4.19 Set Priority Thread</h4>
<p>The priority of a thread object can be set with the
<strong>KeSetPriority</strong> function:</p>
<p><strong>KPRIORITY</strong></p>
<p><strong>KeSetPriorityThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN</strong> <strong>KPRIORITY</strong> <em>Priority</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p><em>Priority</em> - The new priority of the thread.</p>
<p>Setting the priority of a thread object causes its eligibility for
execution to be reexamined. The exact action that is taken depends on
the current dispatching state of the thread. If the new priority is
greater than the maximum thread priority, then an error condition is
raised.</p>
<p>If the dispatching state of the thread object is Ready and the thread
is currently inserted in the parent process's ready queue, then the
priority of the thread is changed and no further action is taken.</p>
<p>If the dispatching state of the thread object is Ready and the thread
is currently inserted in one of the dispatcher ready queues, then the
thread is removed from its current ready queue, its priority is set to
the specified value, and the thread is readied for execution as if it
had just entered the ready state.</p>
<p>If the dispatching state of the thread object is Waiting or
Terminated, then the priority of the thread is changed and no further
action is taken.</p>
<p>If the dispatching state of the thread object is Standby or Running
and the priority of the thread is being raised, then the priority of the
thread is changed and no further action is taken.</p>
<p>If the dispatching state of the thread object is Standby or Running
and the priority of the thread is being lowered, then a check is
performed to determine if the thread should be preempted to run a higher
priority thread. If a higher priority thread can execute on the target
processor, then it is selected for execution and an interprocessor
interrupt is sent to the target processor. Otherwise, no action is
taken.</p>
<p>The previous priority of the subject thread is returned as the
function value.</p>
<h4 id="suspend-thread">2.1.4.20 Suspend Thread</h4>
<p>The execution of a thread object can be suspended with the
<strong>KeSuspendThread</strong> function:</p>
<p><strong>ULONG</strong></p>
<p><strong>KeSuspendThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Suspending a thread object causes the thread's suspend count to be
incremented. If incrementing the suspend count would cause it to
overflow, then the count is not incremented and the exception
STATUS_SUSPEND_COUNT_EXCEEDED is raised. Otherwise, the suspend count is
incremented, and if the resultant value is one and the freeze count is
zero, then the thread's builtin suspend APC object is queued.</p>
<p>When the suspend APC is delivered to the subject thread, a
nonalertable Wait on the thread's builtin semaphore object is executed
which suspends thread execution. The subject thread can be subsequently
resumed with either the <strong>KeResumeThread</strong> or
<strong>KeAlertResumeThread</strong> function.</p>
<p>The previous suspend count is returned as the function value. If the
return value is zero, then the subject thread was not previously
suspended. Otherwise, the thread was previously suspended and must be
resumed the number of times specified by the return value plus one
before it will actually resume execution.</p>
<p>The suspend and resume functions are similar to the freeze and
unfreeze functions, but are usable from both system and user software.
The freeze and unfreeze functions are used to suspend and resume thread
execution during debugging operations.</p>
<h4 id="terminate-thread">2.1.4.21 Terminate Thread</h4>
<p>The execution of the current thread can be terminated with the
<strong>KeTerminateThread</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeTerminateThread</strong> (</p>
<p><strong>IN</strong> <strong>KPRIORITY</strong> <em>Increment</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Increment</em> - The priority increment that is to be applied is
terminating the current thread causes a Wait to be satisfied.</p>
<p>Terminating the current thread causes the dispatching state of the
thread to be set to Terminated and the state of the thread object to be
set to Signaled.</p>
<p>An attempt is made to satisfy as many Waits as possible for the
current thread object.</p>
<p>A new thread object is selected for execution on the current
processor and a context switch to the new thread is performed. There is
no return from this function.</p>
<h4 id="test-alert-thread">2.1.4.22 Test Alert Thread</h4>
<p>An alert condition for the current thread can be tested for with the
<strong>KeTestAlertThread</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeTestAlertThread</strong> (</p>
<p><strong>IN</strong> <strong>KPROCESSOR_MODE</strong>
<em>AlertMode</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>AlertMode</em> - The processor mode (<em>UserMode</em> or
<em>KernelMode</em>) which is to be tested for an alert condition.</p>
<p>This function tests to determine if the current thread's alert
variable for the specified processor mode has a value of TRUE or whether
a user mode APC should be delivered to the current thread.</p>
<p>If the alert variable associated with the specified processor mode is
TRUE, then it is set to a value of FALSE.</p>
<p>If the alert variable associated with the specified processor mode is
FALSE and the specified processor mode is user, then the subject
thread's APC queue is examined to determine whether a user mode APC
should be delivered. If the user mode APC queue contains one or more
entries, then the user APC pending variable is set to a value of TRUE in
the current thread object.</p>
<p>The previous value of the alert variable for the specified processor
mode is returned as the function value. If the return value is TRUE,
then the current thread was alerted. Otherwise, a value of FALSE is
returned and the current thread was not alerted.</p>
<h4 id="unfreeze-thread">2.1.4.23 Unfreeze Thread</h4>
<p>The execution of a thread object can be unfrozen with the
<strong>KeUnfreezeThread</strong> function:</p>
<p><strong>ULONG</strong></p>
<p><strong>KeUnfreezeThread</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p>Unfreezing a thread object checks the freeze count of the subject
thread. If the freeze count is zero, then the thread is not currently
frozen and no operation is performed. Otherwise, the subject thread's
freeze count is decremented. If the resultant value is zero and the
suspend count is also zero, then the execution of the subject thread is
unfrozen by releasing its builtin suspend semaphore.</p>
<p>The previous freeze count is returned as the function value. If the
return value is zero, then the subject thread was not previously frozen.
If the return value is one, then the subject thread's execution was
unfrozen. If the returned value is not zero or one, then the subject
thread is still frozen and must be unfrozen the number of times
specified by the return value minus one before it will actually resume
execution.</p>
<p>The freeze and unfreeze functions are similar to the suspend and
resume functions, but are intended for use by system software as opposed
to being exported to users. The freeze and unfreeze functions are used
to suspend and resume thread execution during debugging operations.</p>
<h4 id="thread-performance-data">2.1.4.24 Thread Performance Data</h4>
<p>Several counters are maintained for each thread object to determine
the various execution characteristics of the thread.</p>
<p>Two of the counters maintain the number of clock ticks that occurred
while the thread was in user mode and while the thread was in kernel
mode. These counters provide a quantitative measure of the distribution
of computation time between the system and the user.</p>
<h3 id="timer-object">2.1.5 Timer Object</h3>
<p>A <em>timer object</em> is used to record the passage of time. A
timer object is set to a specified time and then expires when the time
becomes due. When a timer object is set, its state is set to
Not-Signaled and it is inserted in the system timer queue according to
its expiration time. When the timer object expires, it is removed from
the system timer queue and its state is set to Signaled.</p>
<p>A Deferred Procedure Call (DPC) can optionally be executed when a
timer expires. This procedure executes at IRQL DISPATCH_LEVEL in the
context of whatever thread happens to be executing when the timer
expires.</p>
<p>Waiting on a timer object causes the execution of the subject thread
to be suspended until the timer object attains a Signaled state.
Satisfying the Wait for a timer object does not cause the state of the
timer object to change. Therefore, when a timer object attains a
Signaled state, an attempt is made to Satisfy as many Waits as
possible.</p>
<p>Timer objects can be used to synchronize the execution of specific
actions with time. This execution can occur at fixed points in time or
at various intervals.</p>
<p>Programming interfaces that support the thread object include:</p>
<p><strong>KeInitializeTimer</strong> - Initialize a timer object</p>
<p><strong>KeCancelTimer</strong> - Cancel timer object expiration</p>
<p><strong>KeReadStateTimer</strong> - Read state of timer object</p>
<p><strong>KeSetTimer</strong> - Set timer object expiration time</p>
<h4 id="initialize-timer">2.1.5.1 Initialize Timer</h4>
<p>A timer object can be initialized with the
<strong>KeInitializeTime</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeTimer</strong> (</p>
<p><strong>IN</strong> <strong>PKTIMER</strong> <em>Timer</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Timer</em> - A pointer to a dispatcher object of type timer.</p>
<p>The timer object data structure is initialized with a state of
Not-Signaled.</p>
<h4 id="cancel-timer">2.1.5.2 Cancel Timer</h4>
<p>A timer object can be canceled with the
<strong>KeCancelTimer</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeCancelTimer</strong> (</p>
<p><strong>IN</strong> <strong>PKTIMER</strong> <em>Timer</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Timer</em> - A pointer to a dispatcher object of type timer.</p>
<p>If the timer object is currently in the system timer queue, then it
is removed from the queue and a value of TRUE is returned as the
function value (a boolean state variable records whether the timer
object is in the system timer queue). Otherwise, no operation is
performed and a value of FALSE is returned as the function value.</p>
<h4 id="read-state-timer">2.1.5.3 Read State Timer</h4>
<p>The current state of a timer object can be read with the
<strong>KeReadStateTimer</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeReadStateTimer</strong> (</p>
<p><strong>IN</strong> <strong>PKTIMER</strong> <em>Timer</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Timer</em> - A pointer to a dispatcher object of type timer.</p>
<p>The current state of the timer object is returned as the function
value. If the current state of the timer object is Signaled, then a
value of TRUE is returned. Otherwise, a value of FALSE is returned.</p>
<h4 id="set-timer">2.1.5.4 Set Timer</h4>
<p>A timer object can be set to expire at a specified time with the
<strong>KeSetTimer</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeSetTimer</strong> (</p>
<p><strong>IN</strong> <strong>PKTIMER</strong> <em>Timer</em>,</p>
<p><strong>IN</strong> <strong>TIME</strong> <em>DueTime</em>,</p>
<p><strong>IN</strong> <strong>PKDPC</strong> <em>Dpc</em>
<strong>OPTIONAL</strong></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Timer</em> - A pointer to a dispatcher object of type timer.</p>
<p><em>DueTime</em> - The absolute or relative time at which the timer
is to expire.</p>
<p><em>Dpc</em> - An optional pointer to a control object of type
deferred procedure call.</p>
<p>Setting a timer object causes the absolute expiration time to be
computed, the state of the timer to be set to Not-Signaled, and the
timer object to be inserted in the system timer queue. If the timer
object is already in the timer queue, then it is implicitly canceled
before it is set to the new expiration time (a boolean state variable
records whether the timer object is in the system timer queue).</p>
<p>The expiration time of the timer object is expressed as either the
absolute time that the timer is to expire, or a time that is relative to
the current system time. If the value of the <em>DueTime</em> parameter
is negative, then the expiration time is relative. Otherwise, the
expiration time is absolute.</p>
<p>The expiration time is expressed in system time units which are 100ns
intervals.</p>
<p>If the <em>Dpc</em> parameter is specified, then a DPC object is
associated with the timer object.</p>
<p>If the timer object was previously in the system timer queue, then a
value of TRUE is returned as the function value. Otherwise, a value of
FALSE is returned.</p>
<p>When the timer object expires, it is removed from the system timer
queue and its state is set to Signaled. If a DPC object was associated
with the timer object when it was set, then it is inserted in the system
DPC queue and will execute as soon as conditions permit (a boolean state
variable records whether the DPC object is in the system DPC queue).</p>
<h2 id="control-objects">2.2 Control Objects</h2>
<p>This section describes the various types of control objects and the
interfaces that are provided to manipulate these objects.</p>
<h3 id="asynchronous-procedure-call-apc-object">2.2.1 Asynchronous
Procedure Call (APC) Object</h3>
<p>An <em>Asynchronous Procedure Call</em> (APC) object provides the
capability to break into the execution of a specified thread and cause a
procedure to be called in a specified processor mode. Software running
in kernel mode can only be interrupted to execute asynchronous
procedures in kernel mode, whereas software running in user mode can be
interrupted to execute asynchronous procedures in both user and kernel
mode.</p>
<p>An asynchronous procedure call occurs in the context of a specified
thread and is triggered by a software interrupt at APC_LEVEL.</p>
<p>There are two types of APC objects:</p>
<p>1. <em>Special</em></p>
<p>2. <em>Normal</em></p>
<p>Special APC objects cause the execution of a thread to be interrupted
to execute a procedure in kernel mode at IRQL APC_LEVEL. Special APC
objects can break into the execution of a thread at any time the thread
is executing at IRQL 0.</p>
<p>Ordinarily, special APC procedures perform a minimal amount of work
and return immediately to the APC dispatcher without calling any
external procedures. However, if code running as part of a special APC
procedure acquires a mutex that is also acquired by code outside the
special APC procedure, then the code outside the special APC procedure
must explicitly raise IRQL to APC_LEVEL when it wants to acquire the
mutex.</p>
<p>This convention is required to prevent the special APC procedure from
acquiring the mutex at an inappropriate time, which can happen if the
thread that receives the special APC already owns the mutex when the
special APC procedure is executed.</p>
<p>During the execution of a special APC procedure, page faults can be
taken and all the kernel services are available. However, system
services are not available, and care must be taken to ensure that any
executive services that are used can be safely called.</p>
<p>Normal APC objects cause the execution of a thread to be interrupted
to execute a procedure in kernel mode at IRQL APC_LEVEL and, in
addition, a procedure in either kernel or user mode at IRQL 0. The first
procedure (executed in kernel mode) is called just prior to calling the
second procedure in the specified mode, and must adhere to the
conventions for special APC procedures.</p>
<p>Normal APC objects can only break into the execution of a thread when
the thread is executing at IRQL 0 and a normal APC for the specified
mode is not already active.</p>
<p>While a normal APC is active for kernel mode, further normal APCs are
software disabled until the active APC completes. The delivery of normal
APCs for kernel mode is also implicitly disabled while a thread owns one
or more mutexes (i.e, the thread does not have to explicitly raise IRQL
to APC_LEVEL in order to synchronize with normal APC procedures).</p>
<p>Normal user mode APCs are only delivered when the subject thread is
alertable. This occurs when a thread waits user-mode alertable and when
the thread calls <strong>KeTestAlertThread</strong>.</p>
<p>While a normal APC is active for user mode, further normal APCs for
user mode are software disabled by the alert mechanism. Upon completion
of a normal APC in user mode, <strong>KeTestAlertThread</strong> is
automatically called, which enables the delivery of another user mode
APC. Thus, once a thread is user-mode alertable and an APC is delivered,
further APCs are delivered one after the other until there are no APCs
remaining in the user-mode APC queue.</p>
<p>During the execution of a normal APC procedure, all system operations
are available and page faults can be taken.</p>
<p>Programming interfaces that support the APC object include:</p>
<p><strong>KeInitializeApc</strong> - Initialize an APC object</p>
<p><strong>KeFlushQueueApc</strong> - Flush all APC objects from APC
queue</p>
<p><strong>KeInsertQueueApc</strong> - Insert APC object into APC
queue</p>
<p><strong>KeRemoveQueueApc</strong> - Remove APC object from APC
queue</p>
<h4 id="initialize-apc">2.2.1.1 Initialize APC</h4>
<p>An APC object can be initialized with the
<strong>KeInitializeApc</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeApc</strong> (</p>
<p><strong>IN</strong> <strong>PKAPC</strong> <em>Apc</em>,</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN KAPC_ENVIRONMENT</strong> <em>Environment</em>,</p>
<p><strong>IN</strong> <strong>PKKERNEL_ROUTINE</strong>
<em>KernelRoutine</em>,</p>
<p><strong>IN PKRUNDOWN_ROUTINE</strong> <em>RundownRoutine</em>
<strong>OPTIONAL</strong>,</p>
<p><strong>IN</strong> <strong>PKNORMAL_ROUTINE</strong>
<em>NormalRoutine</em> <strong>OPTIONAL</strong>,</p>
<p><strong>IN</strong> <strong>KPROCESSOR_MODE</strong> <em>ApcMode</em>
<strong>OPTIONAL</strong>,</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>NormalContext</em>
<strong>OPTIONAL</strong></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Apc</em> - A pointer to a control object of type APC.</p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p><em>Environment</em> - The environment in which the APC will execute
(<em>OriginalApcEnvironment</em>, <em>AttachedApcEnvironment</em>, or
<em>CurrentApcEnvironment</em>).</p>
<p><em>KernelRoutine</em> - A pointer to a function that is to be
executed at IRQL APC_LEVEL in kernel mode.</p>
<p><em>RundownRoutine</em> - An optional pointer to a function that is
to be executed if the APC object is contained in a thread's APC queue
when the thread terminates.</p>
<p><em>NormalRoutine</em> - An optional pointer to a function that is to
be executed at IRQL 0 in the specified processor mode. If this parameter
is not specified, then the <em>ApcMode</em> and <em>NormalContext</em>
parameters are ignored.</p>
<p><em>ApcMode</em> - The processor mode (<em>UserMode</em> or
<em>KernelMode)</em> in which the function specified by the
<em>NormalRoutine</em> parameter is to be executed. This parameter is
ignored if the <em>NormalRoutine</em> parameter is not specified.</p>
<p><em>NormalContext</em> - A pointer to an arbitrary data structure
which is to be passed to the function specified by the
<em>NormalRoutine</em> parameter. This parameter is ignored if the
<em>NormalRoutine</em> parameter is not specified.</p>
<p>The function specified by the <em>KernelRoutine</em> parameter has
the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>VOID</strong></p>
<p>(<strong>*PKKERNEL_ROUTINE</strong>) (</p>
<p><strong>IN PKAPC</strong> <em>Apc</em>,</p>
<p><strong>IN OUT</strong> <strong>PKNORMAL_ROUTINE</strong>
<em>*NormalRoutine</em>,</p>
<p><strong>IN OUT PVOID</strong> <em>*NormalContext</em>,</p>
<p><strong>IN OUT PVOID</strong> <em>*SystemArgument1</em>,</p>
<p><strong>IN OUT PVOID</strong> <em>*SystemArgument2</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Apc</em> - A pointer to a control object of type APC.</p>
<p><em>NormalRoutine</em> - A pointer to a pointer to the normal routine
function that was specified when the APC was initialized.</p>
<p><em>NormalContext</em> - A pointer to a pointer to an arbitrary data
structure that was specified when the APC was initialized.</p>
<p><em>SystemArgument1</em>, <em>SystemArgument2</em> - A set of two
pointers to two arguments that contain untyped data.</p>
<p>The function specified by the <em>RundownRoutine</em> parameter has
the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>VOID</strong></p>
<p>(<strong>*PKRUNDOWN_ROUTINE</strong>) (</p>
<p><strong>IN</strong> <strong>PKAPC</strong> <em>Apc</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Apc</em> - A pointer to a control object of type APC.</p>
<p>The function specified by the <em>NormalRoutine</em> parameter has
the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>VOID</strong></p>
<p>(<strong>*PKNORMAL_ROUTINE</strong>) (</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>NormalContext</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SystemArgument1</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SystemArgument2</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>NormalContext</em> - A pointer to an arbitrary data structure
that was specified when the corresponding APC object was
initialized.</p>
<p><em>SystemArgument1</em>, <em>SystemArgument2</em> - A set of two
arguments that contain untyped data.</p>
<p>The type of APC object to be initialized is determined by the
presence or absence of the optional <em>NormalRoutine</em> parameter. If
the <em>NormalRoutine</em> parameter is present, then a normal APC
object is initialized and the values of the <em>ApcMode</em> and
<em>NormalContext</em> parameters are stored in the APC object.
Otherwise, a special APC object is initialized for execution in kernel
mode.</p>
<p>The <em>Environment</em> parameter specifies the execution
environment of the specified APC object. An APC object can be executed
in the context of a thread's parent process or a process to which the
thread has attached.</p>
<p>The <em>KernelRoutine</em> parameter specifies the procedure that is
to be called in kernel mode at IRQL APC_LEVEL. This procedure is called
with a copy of the parameters that are specified for the normal routine
when the APC is initialized and can modify these parameters as necessary
to alter the execution of the normal routine. If the normal routine is
not specified when the APC is initialized, then any assignment to these
parameters is ignored.</p>
<p>If specified, the <em>RundownRoutine</em> parameter specifies a
procedure that is to be called when a thread terminates with the APC
object in its APC queue. The purpose of this routine is to allow for
special disposition of the APC object during thread rundown.</p>
<p>If specified, the <em>NormalRoutine</em> parameter specifies the
procedure that is to be executed in the processor mode specified by the
<em>ApcMode</em> parameter. This procedure will be called with the
<em>NormalContext</em> parameter and two additional arguments provided
by the system when the APC queued.</p>
<p>In order to actually interrupt the execution of a thread, an APC
object must be inserted into one of the thread's APC queues (there is a
separate APC queue for user and kernel mode).</p>
<h4 id="flush-queue-apc">2.2.1.2 Flush Queue APC</h4>
<p>All the APC objects in a specified thread's APC queue can be flushed
with the <strong>KeFlushQueueApc</strong> function:</p>
<p><strong>PLIST_ENTRY</strong></p>
<p><strong>KeFlushQueueApc</strong> (</p>
<p><strong>IN</strong> <strong>PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN</strong> <strong>KPROCESSOR_MODE</strong>
<em>ApcMode</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> - A pointer to a dispatcher object of type
thread.</p>
<p><em>ApcMode</em> - The processor mode (<em>UserMode</em> or
<em>KernelMode</em>) of the APC queue that is to be flushed.</p>
<p>An APC queue is flushed by removing the APC listhead from the list of
APC entries, reinitializing the APC listhead, and returning the list of
APC objects as the function value. If the APC queue is empty, then a
NULL pointer is returned. Otherwise, the address of the list entry for
the first APC object is returned as the function value. It is the
responsibility of the caller to scan the list of APC objects and
dispense with each object as appropriate.</p>
<p>The APC objects are linked together by a list entry in each object.
Scanning this list can be accomplished using the CONTAINING_RECORD
function to locate the address of the respective APC object given the
address of its list entry.</p>
<p>This function is used by the executive during thread termination to
remove remaining entries from the thread's APC lists.</p>
<h4 id="insert-queue-apc">2.2.1.3 Insert Queue APC</h4>
<p>An APC object can be inserted into a thread's APC queue with the
<strong>KeInsertQueueApc</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeInsertQueueApc</strong> (</p>
<p><strong>IN</strong> <strong>PKAPC</strong> <em>Apc</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SystemArgument1</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SystemArgument2</em>,</p>
<p><strong>IN KPRIORITY</strong> <em>Increment</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Apc</em> - A pointer to a control object of type APC.</p>
<p><em>SystemArgument1</em>, <em>SystemArgument2</em> - A set of two
arguments that contain untyped data.</p>
<p><em>Increment</em> - The priority increment that is to be applied if
queuing the APC causes the target thread's wait to be satisfied.</p>
<p>If the specified APC object is already in an APC queue (a boolean
state variable records whether the APC object is in an APC queue) or APC
queuing is disabled for the subject thread, then no operation is
performed and a function value of FALSE is returned. Otherwise, the APC
object is inserted into the APC queue specified by the <em>ApcMode</em>
and <em>Thread</em> parameters that were supplied when the APC object
was initialized and a function value of TRUE is returned.</p>
<p>When proper enabling conditions are present, the APC will be
delivered to the subject thread and the specified procedure(s) will be
executed in the specified processor mode.</p>
<p>A special APC is deliverable whenever the IRQL of the subject thread
is zero.</p>
<p>A normal kernel APC is deliverable whenever the IRQL of the subject
thread is zero, a normal kernel APC is not already in progress, and the
subject thread does not own any mutexes.</p>
<p>A normal user APC is deliverable when the subject thread waits
user-mode alertable and when the subject thread calls
<strong>KeTestAlertThread</strong>.</p>
<h4 id="remove-queue-apc">2.2.1.4 Remove Queue APC</h4>
<p>An APC object can be removed from an APC queue with the
<strong>KeRemoveQueueApc</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeRemoveQueueApc</strong> (</p>
<p><strong>IN</strong> <strong>PKAPC</strong> <em>Apc</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Apc</em> - A pointer to a control object of type APC.</p>
<p>If the specified APC object is not currently in an APC queue (a
boolean state variable records whether the APC object is in an APC
queue), then a value of FALSE is returned and no operation is performed.
Otherwise, the specified APC object is removed from its APC queue and a
function value of TRUE is returned.</p>
<h3 id="deferred-procedure-call-dpc-object">2.2.2 Deferred Procedure
Call (DPC) Object</h3>
<p>A <em>Deferred Procedure Call</em> (DPC) object provides the
capability to break into the execution of the current thread and cause a
procedure to be executed in kernel mode at IRQL DISPATCH_LEVEL.</p>
<p>There is one DPC queue for the entire system. When a DPC object is
inserted in the DPC queue, a software interrupt is requested at
DISPATCH_LEVEL on the current processor. As soon as the IRQL falls below
DISPATCH_LEVEL, a software interrupt will be taken which will cause the
DPC dispatcher to execute.</p>
<p>The DPC dispatcher removes entries from the DPC queue, calls the
specified procedure, and upon return, removes another entry from the
queue. This is continued until there are no longer any entries in the
DPC queue, at which time the DPC dispatcher checks to determine if
another thread has been selected for execution on the current processor.
If a thread has been selected, then a context switch to that thread is
performed. Otherwise, the interrupt is dismissed and execution of the
current thread is continued.</p>
<p>A deferred procedure call occurs at IRQL DISPATCH_LEVEL in the
context of whatever thread was interrupted when the DISPATCH_LEVEL
interrupt occurred. A very limited set of operations can be performed by
the DPC procedure.</p>
<p>No system services can be executed by the DPC procedure nor can any
page faults be taken. The kernel services are generally available.
However, the Wait functions can only be called if it is known that they
will not actually cause a wait to occur. (Using an explicit time-out
value of zero implements a conditional Wait operation). If page faults
or waits were allowed, then it would be possible to randomly cause an
arbitrary thread to wait in the kernel at IRQL DISPATCH_LEVEL causing
possible deadlocks and data corruption.</p>
<p>Deferred procedure execution is intended mainly for use by device
drivers that need to lower their IRQL to complete an I/O operation. The
kernel itself, however, uses DPC objects to implement timers, quantum
end, and power failure recovery.</p>
<p>Programming interfaces that support the DPC object include:</p>
<p><strong>KeInitializeDpc -</strong> Initialize a DPC object</p>
<p><strong>KeInsertQueueDpc</strong> - Insert DPC object into the DPC
queue</p>
<p><strong>KeRemoveQueueDpc</strong> - Remove DPC object from the DPC
queue</p>
<h4 id="initialize-dpc">2.2.2.1 Initialize DPC</h4>
<p>A DPC object can be initialized with the
<strong>KeInitializeDpc</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeDpc</strong> (</p>
<p><strong>IN</strong> <strong>PKDPC</strong> <em>Dpc</em>,</p>
<p><strong>IN</strong> <strong>PKDEFERRED_ROUTINE</strong>
<em>DeferredRoutine</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>DeferredContext</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Dpc</em> - A pointer to a control object of type DPC.</p>
<p><em>DeferredRoutine</em> - A pointer to a function that is to be
called when the DPC object is removed from the DPC queue.</p>
<p><em>DeferredContext</em> - A pointer to an arbitrary data structure
that is to be passed to the function specified by the
<em>DeferredRoutine</em> parameter.</p>
<p>The function specified by the <em>DeferredRoutine</em> parameter has
the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>VOID</strong></p>
<p><strong>(*PKDEFERRED_ROUTINE)</strong> (</p>
<p><strong>IN PKDPC</strong> <em>Dpc,</em></p>
<p><strong>IN PVOID</strong> <em>DeferredContext</em>,</p>
<p><strong>IN PVOID</strong> <em>SystemArgument1</em>,</p>
<p><strong>IN PVOID</strong> <em>SystemArgument2</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Dpc</em> - A pointer to a control object of type DPC.</p>
<p><em>DeferredContext</em> - A pointer to an arbitrary data structure
that was specified when the DPC was initialized.</p>
<p><em>SystemArgument1</em>, <em>SystemArgument2</em> - A set of two
arguments that contain untyped data.</p>
<h4 id="insert-queue-dpc">2.2.2.2 Insert Queue DPC</h4>
<p>A DPC object can be inserted in the system DPC queue with the
<strong>KeInsertQueueDpc</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeInsertQueueDpc</strong> (</p>
<p><strong>IN</strong> <strong>PKDPC</strong> <em>Dpc</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SystemArgument1</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SystemArgument2</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Dpc</em> - A pointer to a control object of type DPC.</p>
<p><em>SystemArgument1</em>, <em>SystemArgument2</em> - A set of two
arguments that contain untyped data.</p>
<p>If the specified DPC object is already in the DPC queue (a boolean
state variable records whether the DPC object is in the DPC queue), then
no operation is performed and a function value of FALSE is returned.
Otherwise, the DPC object is inserted in the DPC queue, a software
interrupt is request at IRQL DISPATCH_LEVEL on the current processor,
and a function value of TRUE is returned.</p>
<p>The deferred procedure will be executed as soon as the IRQL of the
current processor drops below DISPATCH_LEVEL.</p>
<h4 id="remove-queue-dpc">2.2.2.3 Remove Queue DPC</h4>
<p>A DPC object can be removed from the DPC queue with the
<strong>KeRemoveQueueDpc</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeRemoveQueueDpc</strong> (</p>
<p><strong>IN</strong> <strong>PKDPC</strong> <em>Dpc</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Dpc</em> - A pointer to a control object of type DPC.</p>
<p>If the specified DPC object is not currently in the DPC queue (a
boolean state variable records whether the DPC object is in the DPC
queue), then a value of FALSE is returned and no operation is performed.
Otherwise, the specified DPC object is removed from the DPC queue and a
function value of TRUE is returned.</p>
<h3 id="device-queue-object">2.2.3 Device Queue Object</h3>
<p>A <em>device queue object</em> is used to record the state of a
device driver and to provide a queue into which I/O requests can be
placed for subsequent processing.</p>
<p>A device queue object has a state which is either <em>Busy</em> or
<em>Not-Busy</em>.</p>
<p>When the state of a device queue object is Not-Busy, the associated
device driver is idle and therefore not performing any work.</p>
<p>A device queue object transitions to the Busy state when an attempt
is made to insert a device queue entry into a device queue that is
empty. For this case, the device queue entry is not actually placed in
the device queue, but rather, the device queue object is marked Busy and
a boolean value of FALSE is returned to signify that the associated
device driver should process the device queue entry immediately.</p>
<p>Once a device queue object is Busy, further I/O requests are placed
in the device queue in either a FIFO or key-sorted order.</p>
<p>A device queue object transitions to a Not-Busy state when an attempt
is made to remove a device queue entry from a device queue object and
the corresponding device queue is empty.</p>
<p>A device queue entry has the following type definition:</p>
<p><strong>typedef struct _KDEVICE_QUEUE_ENTRY</strong> {</p>
<p><strong>LIST_ENTRY</strong> <em>DeviceListEntry</em>;</p>
<p><strong>ULONG</strong> <em>SortKey</em>;</p>
<p><strong>BOOLEAN</strong> <em>Inserted</em>;</p>
<p>} <strong>KDEVICE_QUEUE_ENTRY</strong>;</p>
<p>Programming interfaces that support the device queue object
include:</p>
<p><strong>KeInitializeDeviceQueue</strong> - Initialize a device
queue</p>
<p><strong>KeInsertDeviceQueue</strong> - Insert entry at tail of device
queue</p>
<p><strong>KeInsertByKeyDeviceQueue</strong> - Insert entry by key into
device queue</p>
<p><strong>KeRemoveDeviceQueue</strong> - Remove entry from head of
device queue</p>
<p><strong>KeRemoveEntryDeviceQueue</strong> - Remove entry from device
queue</p>
<h4 id="initialize-device-queue">2.2.3.1 Initialize Device Queue</h4>
<p>A device queue object can be initialized with the
<strong>KeInitializeDeviceQueue</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeDeviceQueue</strong> (</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE</strong>
<em>DeviceQueue</em>,</p>
<p><strong>IN PKSPIN_LOCK</strong> <em>SpinLock</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>DeviceQueue</em> - A pointer to a control object of type device
queue.</p>
<p>SpinLock - A pointer to an executive spin lock.</p>
<p>The device queue object data structure is initialized and the state
of the device queue is set to Not-Busy.</p>
<h4 id="insert-device-queue">2.2.3.2 Insert Device Queue</h4>
<p>An entry can be inserted at the tail of a device queue with the
<strong>KeInsertDeviceQueue</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeInsertDeviceQueue</strong> (</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE</strong>
<em>DeviceQueue</em>,</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE_ENTRY</strong>
<em>DeviceQueueEntry</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>DeviceQueue</em> - A pointer to a control object of type device
queue.</p>
<p><em>DeviceQueueEntry</em> - A pointer to the device queue entry that
is to be inserted at the tail of the device queue.</p>
<p>The specified device queue spin lock is acquired, and the state of
the device queue is checked.</p>
<p>If the state of the device queue is Not-Busy, then the state of the
device queue is set to Busy, the device queue spin lock is released, and
a value of FALSE is returned as the function value (i.e., the device
queue entry is not inserted in the device queue).</p>
<p>If the state of the device queue is Busy, then the specified device
queue entry is inserted at the tail of device queue, the device queue
spin lock is released, and a value of TRUE is returned as the function
value.</p>
<p>This function is intended for use by code that queues an I/O request
to a device driver. It must be called from an IRQL of
DISPATCH_LEVEL.</p>
<h4 id="insert-by-key-device-queue">2.2.3.3 Insert By Key Device
Queue</h4>
<p>An entry can be inserted into a device queue according to a key value
with the <strong>KeInsertByKeyDeviceQueue</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeInsertByKeyDeviceQueue</strong> (</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE</strong>
<em>DeviceQueue</em>,</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE_ENTRY</strong>
<em>DeviceQueueEntry</em>,</p>
<p><strong>IN</strong> <strong>ULONG</strong> <em>SortKey</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>DeviceQueue</em> - A pointer to a control object of type device
queue.</p>
<p><em>DeviceQueueEntry</em> - A pointer to the device queue entry that
is to be inserted into the device queue by key.</p>
<p><em>SortKey</em> - The sort key value that is to be used to determine
the position at which the device queue entry is to be inserted in the
specified device queue.</p>
<p>The specified device queue spin lock is acquired, and the state of
the device queue is checked.</p>
<p>If the state of the device queue is Not-Busy, then the state of the
device queue is set to Busy, the device queue spin lock is released, and
a value of FALSE is returned as the function value (i.e., the device
queue entry is not inserted in the device queue).</p>
<p>If the state of the device queue is Busy, then the specified device
queue entry is inserted into the device queue according to its sort key
value, the device queue spin lock is released, and a value of TRUE is
returned as the function value.</p>
<p>Insertion in the device queue is such that the preceding entry in the
queue has a sort key that is less than or equal to the new entry's sort
key and the succeeding entry has a sort key that is greater than the new
entry's sort key.</p>
<p>This function is intended for use by code that queues an I/O request
to a device driver. It must be called from an IRQL of
DISPATCH_LEVEL.</p>
<h4 id="remove-device-queue">2.2.3.4 Remove Device Queue</h4>
<p>An entry can be removed from the head of a device queue with the
<strong>KeRemoveDeviceQueue</strong> function:</p>
<p><strong>PKDEVICE_QUEUE_ENTRY</strong></p>
<p><strong>KeRemoveDeviceQueue</strong> (</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE</strong>
<em>DeviceQueue</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>DeviceQueue</em> - A pointer to a control object of type device
queue.</p>
<p>This function can only be called from an IRQL of DISPATCH_LEVEL and
is intended for use by device driver code that completes one I/O request
and starts the next one.</p>
<p>The specified device queue spin lock is acquired and the state of the
device queue is checked.</p>
<p>If the state of the device queue is Not-Busy, then a bug check will
occur (i.e., <strong>KeRemoveDeviceQueue</strong> cannot be called when
the device queue is Not-Busy).</p>
<p>If the state of the device queue is Busy, then an attempt is made to
remove an entry from the head of the device queue. If the device queue
is empty, then the state of the device queue is set to Not-Busy and a
NULL pointer is returned as the function value. Otherwise, the next
entry is removed from the head of the device queue, the inserted status
of the entry is set to FALSE, and the address of the entry is returned
as the function value.</p>
<p>The specified device queue spin lock is released.</p>
<h4 id="remove-entry-device-queue">2.2.3.5 Remove Entry Device
Queue</h4>
<p>A specific entry can be removed from a device queue with the
<strong>KeRemoveEntryDeviceQueue</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeRemoveEntryDeviceQueue</strong> (</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE</strong>
<em>DeviceQueue</em>,</p>
<p><strong>IN</strong> <strong>PKDEVICE_QUEUE_ENTRY</strong>
<em>DeviceQueueEntry</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>DeviceQueue</em> - A pointer to a control object of type device
queue.</p>
<p><em>DeviceQueueEntry</em> - A pointer to the device queue entry that
is to be removed from the specified device queue.</p>
<p>The IRQL is raised to DISPATCH_LEVEL and the specified device queue
spin lock is acquired.</p>
<p>If the specified device queue entry is currently in a device queue (a
boolean state variable records whether a device queue entry is in a
device queue), then the device queue entry is removed from the device
queue, the inserted status of the device queue entry is set to FALSE,
and a value of TRUE is returned as the function value. Otherwise, the
specified device queue entry is not in a device queue and a value of
FALSE is returned.</p>
<p>The specified device queue spin lock is released and IRQL is restored
to its previous value.</p>
<p>This function is intended for use in canceling I/O operations and is
callable from any IRQL that is less than or equal to DISPATCH_LEVEL.</p>
<h3 id="interrupt-object">2.2.4 Interrupt Object</h3>
<p>An <em>interrupt</em> <em>object</em> provides the capability to
connect an interrupt source to an interrupt service routine via an entry
in an Interrupt Dispatch Table (IDT). Each processor has an IDT that is
used to dispatch interrupts which occur on that processor.</p>
<p>The IDT is a software-defined table that contains an entry for each
of the Interrupt Request Levels (IRQLs). When an interrupt occurs at one
of these levels, the interrupt dispatcher reads the IRQL of the
interrupting source from the interrupt controller. This value is then
used to locate the corresponding entry in the IDT that is used to
dispatch the execution of the associated service routine.</p>
<p>Several of the IDT entries are reserved for use by the kernel and
cannot be connected to interrupt objects. These entries include the
following:</p>
<p>o PASSIVE_LEVEL - Passive release</p>
<p>o APC_LEVEL - Asynchronous Procedure Call</p>
<p>o DISPATCH_LEVEL - Dispatch and Deferred Procedure Call</p>
<p>o WAKE_LEVEL - Wake system debugger</p>
<p>o CLOCK2_LEVEL - Interval timer</p>
<p>o IPI_LEVEL - Interprocessor request</p>
<p>o POWER_LEVEL - Power failure</p>
<p>o HIGH_LEVEL - Machine check</p>
<p>The remaining levels can be used for device interrupts or bus
adapters.</p>
<p>In addition to the 16 entries that are directly associated with the
hardware interrupt request levels, there are 48 more entries in the IDT
that are provided to allow secondary level dispatching of interrupts.
These entries can be used by a first-level service routine (i.e., one
connected to IRQLs 0 - 15) to dispatch secondary level interrupts such
as those that might be received from a bus adapter. For example, a bus
adapter might have several devices that can cause interrupts and a
mechanism for identifying which device is requesting service. When a bus
adapter interrupt is received, the service routine connected to the
appropriate first level IDT entry is executed. This service routine
reads the adapter register that identifies the interrupting device and
uses the information to locate the appropriate second-level IDT entry.
The second-level IDT entry must be connected to an interrupt object and
contains the address of the interrupt transfer routine which is
called.</p>
<p>An interrupt transfer routine has the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>BOOLEAN</strong></p>
<p><strong>(*PKTRANSFER_ROUTINE)</strong> (</p>
<p>);</p>
<p>Interrupt sources are classified as either <em>LevelSensitive</em> or
<em>Latched</em>. Level sensitive interrupts request an interrupt
whenever the corresponding interrupt request signal is asserted. The
service routine associated with the interrupt source must remove the
cause of the interrupt before the interrupt request is dropped. Latched
interrupts are requested whenever the corresponding interrupt request
signal transitions from the deasserted to the asserted state.</p>
<p>An interrupt object can only be connected to a single IDT entry. If a
particular service routine must be connected to the same interrupt on
multiple processors, then multiple interrupt objects must be used.
Multiple interrupt objects can be connected to a single IDT entry. They
must, however, all have the same interrupt type (i.e., level sensitive
or latched).</p>
<p>Interrupt objects are intended for use by device drivers.</p>
<p>\ Kernel code that utilizes interrupts directly does not connect
interrupts using this object. These interrupts include the interval
timer, power failure, machine check, and the two software interrupt
levels. The code for these interrupts is written in assembler since it
is small and system dependent. \</p>
<p>Programming interfaces that support the interrupt object include:</p>
<p><strong>KeInitializeInterrupt</strong> - Initialize an interrupt
object</p>
<p><strong>KeConnectInterrupt</strong> - Connect interrupt object to an
IDT entry</p>
<p><strong>KeDisconnectInterrupt</strong> - Disconnect interrupt object
from an IDT entry</p>
<p><strong>KeSynchronizeExecution</strong> - Synchronize execution with
an interrupt</p>
<h4 id="initialize-interrupt">2.2.4.1 Initialize Interrupt</h4>
<p>An interrupt object can be initialized with the
<strong>KeInitializeInterrupt</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeInterrupt</strong> (</p>
<p><strong>IN</strong> <strong>PKINTERRUPT</strong>
<em>Interrupt</em>,</p>
<p><strong>IN</strong> <strong>PKSERVICE_ROUTINE</strong>
<em>ServiceRoutine</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>ServiceContext</em>,</p>
<p><strong>IN PKSPIN_LOCK</strong> <em>SpinLock</em>,</p>
<p><strong>IN</strong> <strong>CCHAR</strong> <em>Vector</em>,</p>
<p><strong>IN</strong> <strong>KIRQL</strong>
<em>InterruptIrql</em>,</p>
<p><strong>IN KIRQL</strong> <em>SynchronizeIrql</em>,</p>
<p><strong>IN KINTERRUPT_MODE</strong> <em>InterruptMode</em>,</p>
<p><strong>IN BOOLEAN</strong> <em>ShareVector</em>,</p>
<p><strong>IN CCHAR</strong> <em>ProcessorNumber</em>,</p>
<p><strong>IN BOOLEAN</strong> <em>FloatingSave</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Interrupt</em> - A pointer to a control object of type
interrupt.</p>
<p><em>ServiceRoutine</em> - A pointer to a function that is to be
called when an interrupt occurs on the specified processor through the
specified IDT entry.</p>
<p><em>ServiceContext</em> - A pointer to an arbitrary data structure
which will be passed to the <em>ServiceRoutine</em> function as a
parameter.</p>
<p><em>SpinLock</em> - A pointer to an spin lock that is to be used to
synchronize the execution of the <em>ServiceRoutine</em> function with
the corresponding device driver.</p>
<p><em>Vector</em> - The index of the entry in the specified IDT that is
to be associated with <em>ServiceRoutine</em> function.</p>
<p><em>InterruptIrql</em> - The request priority of the interrupting
source.</p>
<p><em>SynchronizeIrql</em> - The request priority that the interrupt
should be synchronzied with.</p>
<p><em>InterruptMode</em> - The mode of the interrupt
(<em>LevelSensitive</em> or <em>Latched</em>).</p>
<p><em>ShareVector</em> - A boolean that specifies whether the interrupt
vector to which the object is connected may be shared. If FALSE then the
vector may not be shared, if TRUE it may be.</p>
<p><em>ProcessorNumber</em> - The number of the processor whose IDT is
to used when connecting the interrupt.</p>
<p><em>FloatingSave</em> - A boolean variable that specifies whether the
floating point context needs to be saved when a interrupt is received
from the interrupt source.</p>
<p>The function specified by the <em>ServiceRoutine</em> parameter has
the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>BOOLEAN</strong></p>
<p>(<strong>*PKSERVICE_ROUTINE</strong>) (</p>
<p><strong>IN</strong> <strong>PKINTERRUPT</strong>
<em>Interrupt</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>ServiceContext</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Interrupt</em> - A pointer to a control object of type interrupt
which is connected to the associated interrupt source.</p>
<p><em>ServiceContext</em> - A pointer to an arbitrary data structure
that was specified when the corresponding interrupt object was
initialized.</p>
<p>The interrupt object is initialized with the specified parameters. In
order for the function specified by the <em>ServiceRoutine</em>
parameter to actually get called when an interrupt is received from the
interrupt source, the interrupt object must be connected to the
specified IDT entry using the <strong>KeConnectInterrupt</strong>
function.</p>
<p>The spin lock specified by the <em>SpinLock</em> parameter is used to
synchronize execution.</p>
<p>If <em>SynchronizeIrql</em> is not equal to <em>InterruptIrql</em>,
then the system will raise its priority level to
<em>SynchronizeIrql</em> level before acquiring the lock specified by
<em>SpinLock</em>. This allows support for devices with multiple
interrupt sources, since all can be synchronized with a single spin lock
at a single priority level.</p>
<p>It is an error for <em>SynchronizeIrql</em> to be less than
<em>InterruptIrql</em>, the system will refuse to connect such an
interrupt object.</p>
<p>An interrupt object can only be connected to a single IDT entry on a
single processor. The <em>Vector</em> parameter specifies the IDT entry
and the <em>ProcessorNumber</em> parameter specifies which IDT is to be
used. If a particular service routine must be connected to the same IDT
entry on multiple processors, then multiple interrupt objects must be
used. More than one interrupt object, however, can be connected to the
same IDT entry on the same processor, but all such interrupt objects
must have been initialized with <em>ShareVector</em> set to TRUE. When
this happens, appropriate data structures are automatically set up to
call each connected interrupt service routine one after the other.</p>
<p>The mode of the interrupt specifies whether the interrupt is a
<em>LevelSensitive</em> or <em>Latched</em> interrupt. Level sensitive
interrupts are continually requested as long as the interrupt signal
stays asserted. Therefore, the interrupt service routine must remove the
reason for the interrupt before returning control. Latched interrupts
are requested only on the transition of the interrupt signal from
deasserted to asserted. The function specified by the
<em>ServiceRoutine</em> parameter must return a boolean value that
signifies whether the interrupt was handled or not.</p>
<p>The <em>ShareVector</em> parameter declares whether the interrupt
object may be connected to its interrupt vector at the same time as
other interrupt objects. All interrupt objects sharing an interrupt
vector must have <em>ShareVector</em> set to TRUE. The system may
disallow sharing of an interrupt vector, even if all interrupt objects
for which connections are attempted have <em>ShareVector</em> set to
TRUE. This could happen because the underlying hardware does not support
sharing.</p>
<p>The <em>FloatingSave</em> parameter specifies whether the
<em>ServiceRoutine</em> function uses the floating point registers. If
this parameter is TRUE, then the floating context is saved before
calling the specified service routine. Otherwise, it is not saved and a
fair amount of overhead is saved.</p>
<p>\ This parameter is being provided with the hope that a compiler
option will be implemented that allows a module to be compiled such that
it will not use the floating point registers. This option does not
currently exist and this parameter should always be specified as TRUE.
\</p>
<p>Initializing an interrupt causes code to be generated that will
synchronize execution with the appropriate interrupt object, call the
specified interrupt service routine, and dismiss the interrupt.</p>
<h4 id="connect-interrupt">2.2.4.2 Connect Interrupt</h4>
<p>An interrupt object can be connected to an IDT entry with the
<strong>KeConnectInterrupt</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeConnectInterrupt</strong> (</p>
<p><strong>IN</strong> <strong>PKINTERRUPT</strong>
<em>Interrupt</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Interrupt</em> - A pointer to a control object of type
interrupt.</p>
<p>If the specified interrupt object is already connected (a boolean
state variable records whether the interrupt object is connected), the
specified vector number is greater than the maximum vector, the
specified IRQL is greater than HIGH_LEVEL, the specified level cannot be
connected to (e.g., a reserved level, sharing conflicts), or the
specified processor number is greater than the number of processors in
the configuration, then no operation is performed and a function value
of FALSE is returned. Otherwise, the interrupt object is connected to
the IDT entry that was specified when the interrupt object was
initialized and a function value of TRUE is returned.</p>
<p>Once an interrupt object is connected to an IDT entry, the
corresponding service routine will be called each time an interrupt is
received from that interrupt source. If multiple interrupt objects are
connected to a single IDT entry, then the service routines are called in
the order in which they were connected.</p>
<h4 id="disconnect-interrupt">2.2.4.3 Disconnect Interrupt</h4>
<p>An interrupt object can be disconnected from an IDT entry with the
<strong>KeDisconnectInterrupt</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeDisconnectInterrupt</strong> (</p>
<p><strong>IN</strong> <strong>PKINTERRUPT</strong>
<em>interrupt</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Interrupt</em> - A pointer to a control object of type
interrupt.</p>
<p>If the specified interrupt object is not connected (a boolean state
variable records whether the interrupt object is connected), then no
operation is performed and a function value of FALSE is returned.
Otherwise, the interrupt object is disconnected from the IDT entry that
was specified when the interrupt object was initialized and a function
value of TRUE is returned.</p>
<p>Further interrupts received from the interrupting source will be
logged, but otherwise ignored.</p>
<h4 id="synchronize-execution">2.2.4.4 Synchronize Execution</h4>
<p>The execution of a device driver function can be synchronized with
the execution of the service routine associated with an interrupt object
with the <strong>KeSynchronizeExecution</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeSynchronizeExecution</strong> (</p>
<p><strong>IN</strong> <strong>PKINTERRUPT</strong>
<em>Interrupt</em>,</p>
<p><strong>IN</strong> <strong>PKSYNCHRONIZE_ROUTINE</strong>
<em>SynchronizeRoutine</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SynchronizeContext</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Interrupt</em> - A pointer to a control object of type
interrupt.</p>
<p><em>SynchronizeRoutine</em> - A pointer to a device driver function
whose execution is to be synchronized with the execution of the service
routine associated with the specified interrupt object.</p>
<p><em>SynchronizeContext</em> - A pointer to an arbitrary data
structure which is to be passed to the function specified by the
<em>SynchronizeRoutine</em> parameter.</p>
<p>The function specified by the <em>SynchronizeRoutine</em> parameter
has the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>BOOLEAN</strong></p>
<p>(*<strong>PKSYNCHRONIZE_ROUTINE</strong>) (</p>
<p><strong>IN</strong> <strong>PVOID</strong>
<em>SynchronizeContext</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>ServiceContext</em> - A pointer to an arbitrary data structure
that was specified when the call to
<strong>KeSynchronizeExecution</strong> was executed.</p>
<p>This function is used by a device driver to synchronize execution
with a service routine which may be executing on another processor in a
multiprocessor configuration. Such synchronization is only necessary in
those cases where both the service routine and device driver access the
same resources in a way that requires mutually exclusive access.</p>
<p>When this function is executed, the IRQL is raised to the level
specified by the interrupt source's interrupt object (the higher of
<em>InterruptIrql</em> and <em>SynchronizeIrql</em>), access is
synchronized with the corresponding service routine by acquiring the
associated spin lock, and then the specified routine is called. The
routine should access resources as necessary and return a boolean value.
Upon return, the IRQL is restored and the boolean value is returned as
the function value.</p>
<p>Routines executed with this function execute at an elevated IRQL and
must be very short in duration. It is intended that these routines be
used for such purposes as loading device registers and should be only a
few microseconds in length.</p>
<p>The boolean return value is intended to be attached to the occurrence
of a power failure. A device driver can use a power status object to
record the occurrence of a power failure. The synchronize routine should
raise IRQL to POWER_LEVEL and test the corresponding status variable
before loading any device registers. If the value is TRUE, then power
has failed and the device may not be in an appropriate state. If the
value is FALSE, then power has not failed and a sequence of device
register loads can be performed without a power failure since power
failure interrupts are disabled.</p>
<h3 id="power-notify-object">2.2.5 Power Notify Object</h3>
<p>A <em>power notify object</em> provides the capability to
automatically have a specified function called when power is restored
after a power failure.</p>
<p>This object is intended for use by device drivers and other code that
needs to be asynchronously notified via a function call when power is
restored after a failure. The function call can be used to reinitialize
device state, restart I/O operations, etc.</p>
<p>A power notify object, when inserted in the power notify queue, is a
repeatable operation. That is, the specified function will be called
each time the power is restored. The kernel guarantees that once called,
the specified function will not be recursively recalled until it has
completed its execution and returned to the kernel.</p>
<p>When power is restored after a power failure, the kernel scans the
power notify queue and calls the specified functions in the order in
which they were inserted. Thus layered device drivers can ensure that
they are called in the correct order.</p>
<p>If the power fails and is restored during the scan of the power
notify queue, then the scan is immediately restarted at the beginning of
the queue.</p>
<p>A power notify object cannot be inserted in, or removed from, the
power notify queue from a function that is called as the result of power
restoration (i.e., a power notify routine).</p>
<p>Programming interfaces that support the power notify object
include:</p>
<p><strong>KeInitializePowerNotify</strong> - Initialize notify
object</p>
<p><strong>KeInsertQueuePowerNotify</strong> - Insert power notify
object</p>
<p><strong>KeRemoveQueuePowerNotify</strong> - Remove power notify
object</p>
<h4 id="initialize-power-notify">2.2.5.1 Initialize Power Notify</h4>
<p>A power notify object can be initialized with the
<strong>KeInitializePowerNotify</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializePowerNotify</strong> (</p>
<p><strong>IN</strong> <strong>PKPOWER_NOTIFY</strong>
<em>PowerNotify</em>,</p>
<p><strong>IN PKNOTIFY_ROUTINE</strong> <em>NotifyRoutine</em>,</p>
<p><strong>IN PVOID</strong> <em>NotifyContext</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>PowerNotify</em> - A pointer to a control object of type power
notify.</p>
<p><em>NotifyRoutine</em> - A pointer to a function that is to be called
when power is restored after a power failure.</p>
<p><em>NotifyContext</em> - A pointer to an arbitrary data structure
which will be passed to the <em>NotifyRoutine</em> as a parameter.</p>
<p>The function specified by the <em>NotifyRoutine</em> parameter has
the following type definition:</p>
<p><strong>typedef</strong></p>
<p><strong>VOID</strong></p>
<p><strong>(*PKNOTIFY_ROUTINE)</strong> (</p>
<p><strong>IN PVOID</strong> <em>NotifyContext</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>NotifyContext</em> - A pointer to an arbitrary data structure
that was specified when the power notify object was initialized.</p>
<p>The power notify object data structure is initialized.</p>
<p>In order to actually have the specified function called when power is
restored after a failure, the power notify object must be inserted in
the power notify queue.</p>
<h4 id="insert-power-notify">2.2.5.2 Insert Power Notify</h4>
<p>A power notify object can be inserted in the power notify queue with
the <strong>KeInsertQueuePowerNotify</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeInsertQueuePowerNotify</strong> (</p>
<p><strong>IN</strong> <strong>PKPOWER_NOTIFY</strong>
<em>PowerNotify</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>PowerNotify</em> - A pointer to a control object of type power
notify.</p>
<p>If the specified power notify object is already in the power notify
queue (a boolean state variable records whether the power notify object
is in the power notify queue), then no operation is performed and a
function value of FALSE is returned. Otherwise, the power notify object
is inserted in the power notify queue and a function value of TRUE is
returned.</p>
<p>When the power is restored after a failure, the kernel scans the
power notify queue and calls the specified function.</p>
<h4 id="remove-power-notify">2.2.5.3 Remove Power Notify</h4>
<p>A power notify object can be removed from the power notify queue with
the <strong>KeRemoveQueuePowerNotify</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeRemoveQueuePowerNotify</strong> (</p>
<p><strong>IN</strong> <strong>PKPOWER_NOTIFY</strong>
<em>PowerNotify</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>PowerNotify</em> - A pointer to a control object of type power
notify.</p>
<p>If the power notify object is not in the power notify queue (a
boolean state variable records whether the power notify object is in the
power notify queue), then no operation is performed and a function value
of FALSE is returned. Otherwise, the power notify object is removed from
the power notify queue and a function value of TRUE is returned.</p>
<h3 id="power-status-object">2.2.6 Power Status Object</h3>
<p>A <em>power status object</em> provides the capability to
automatically have a boolean state variable set to a value of TRUE when
power is restored after a power failure.</p>
<p>This object is intended for use by device drivers and other code
which needs to synchronize access to volatile register and device state
such that a power failure does not leave the registers or device in an
indeterminate state. The boolean value can be interrogated at critical
points during driver execution to determine whether a given operation
should be continued or restarted.</p>
<p>A power status object, when inserted in the power status queue, is a
one-shot operation. That is, the boolean variable will be set to a value
of TRUE exactly once after the power is restored. If it is desirable to
have the boolean variable set to a value of TRUE the next time that
power fails, then the power status object must be reinserted in the
power status queue.</p>
<p>Programming interfaces that support the power status object
include:</p>
<p><strong>KeInitializePowerStatus</strong> - Initialize status
object</p>
<p><strong>KeInsertQueuePowerStatus</strong> - Insert power status
object</p>
<p><strong>KeRemoveQueuePowerStatus</strong> - Remove power status
object</p>
<h4 id="initialize-power-status">2.2.6.1 Initialize Power Status</h4>
<p>A power status object can be initialized with the
<strong>KeInitializePowerStatus</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializePowerStatus</strong> (</p>
<p><strong>IN</strong> <strong>PKPOWER_STATUS</strong>
<em>PowerStatus</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>PowerStatus</em> - A pointer to a control object of type power
status.</p>
<p>The power status object data structure is initialized.</p>
<p>In order to actually have a boolean variable set to a value of TRUE
when power is restored after a failure, the power status object must be
inserted in the power status queue.</p>
<h4 id="insert-power-status">2.2.6.2 Insert Power Status</h4>
<p>A power status object can be inserted in the power status queue with
the <strong>KeInsertQueuePowerStatus</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeInsertQueuePowerStatus</strong> (</p>
<p><strong>IN</strong> <strong>PKPOWER_STATUS</strong>
<em>PowerStatus</em>,</p>
<p><strong>IN</strong> <strong>PBOOLEAN</strong> <em>Status</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>PowerStatus</em> - A pointer to a control object of type power
status.</p>
<p><em>Status</em> - A pointer to a boolean variable that is to be set
to a value of TRUE when power is restored after a failure.</p>
<p>If the specified power status object is already in the power status
queue (a boolean state variable records whether the power status object
is in the power status queue), then no operation is performed and a
function value of FALSE is returned. Otherwise, the power status object
is inserted in the power status queue, the specified boolean variable is
set to a value of FALSE, and a function value of TRUE is returned.</p>
<p>When the power is restored after a failure, the kernel removes each
entry from the power status queue, sets the specified boolean variable
to a value of TRUE, and sets the inserted state of the power status
object to FALSE.</p>
<h4 id="remove-power-status">2.2.6.3 Remove Power Status</h4>
<p>A power status object can be removed from the power status queue with
the <strong>KeRemoveQueuePowerStatus</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeRemoveQueuePowerStatus</strong> (</p>
<p><strong>IN</strong> <strong>PKPOWER_STATUS</strong>
<em>PowerStatus</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>PowerStatus</em> - A pointer to a control object of type power
status.</p>
<p>If the power status object is not in the power status queue (a
boolean state variable records whether the power status object is in the
power status queue), then no operation is performed and a function value
of FALSE is returned. Otherwise, the power status object is removed from
the power status queue and a function value of TRUE is returned.</p>
<h3 id="process-object">2.2.7 Process Object</h3>
<p>A <em>process object</em> represents the virtual address space and
control information necessary for the execution of a set of thread
objects.</p>
<p>A process object contains a pointer to an address map, a thread ready
list to hold thread objects while the process is not in the balance set,
a list of threads that are children of the process, the total
accumulated time for all threads executing within the process, a base
priority, and a default thread affinity.</p>
<p>A process object must be initialized before any thread objects can be
initialized that specify the process as their parent.</p>
<p>A process is either in the balance set (Included) or not in the
balance set (Excluded). When a process is in the balance set, then all
threads that are children of the process are eligible to be considered
for execution on a processor. When a process is not in the balance set,
then necessary pages are not locked in memory (e.g. thread kernel
stacks) and threads that are children of the process are not eligible
for execution on a processor.</p>
<p>The balance set is managed by the balance set manager; see also the
discussion under Thread Object.</p>
<p>A process cannot leave the balance set while any of its children
threads own mutexes. Therefore, when a process is selected for removal
from the balance set, any children threads that own mutexes are allowed
to continue execution until they release their last mutex. When this
occurs, execution of the thread is suspended and it is placed in the
process ready queue rather than returning to one of the dispatcher ready
queues. When no threads in the process own mutexes, then the process can
actually be removed from the balance set.</p>
<p>Programming interfaces that support the process object include:</p>
<p><strong>KeInitializeProcess</strong> - Initialize a process
object</p>
<p><strong>KeAttachProcess</strong> - Attach process address space</p>
<p><strong>KeDetachProcess</strong> - Detach process address space</p>
<p><strong>KeExcludeProcess</strong> - Exclude process from balance
set</p>
<p><strong>KeIncludeProcess</strong> - Include process in balance
set</p>
<p><strong>KeSetPriorityProcess</strong> - Set priority of process
object</p>
<h4 id="initialize-process">2.2.7.1 Initialize Process</h4>
<p>A process object can be initialized with the
<strong>KeInitializeProcess</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeProcess</strong> (</p>
<p><strong>IN</strong> <strong>PKPROCESS</strong> <em>Process,</em></p>
<p><strong>IN</strong> <strong>KPRIORITY</strong>
<em>BasePriority</em>,</p>
<p><strong>IN</strong> <strong>KAFFINITY</strong> <em>Affinity</em>,</p>
<p><strong>IN</strong> <strong>ULONG</strong>
<em>DirectoryTableBase</em>,</p>
<p><strong>IN BOOLEAN</strong> <em>Enable</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Process</em> - A pointer to a control object of type process.</p>
<p><em>BasePriority</em> - The base priority of the process.</p>
<p><em>Affinity</em> - The set of processors on which children threads
of the process can execute.</p>
<p><em>DirectoryTableBase</em> - The value that is to be loaded into the
Directory Table Base Register when a child thread of the process is
dispatched for execution.</p>
<p><em>Enable</em> - A boolean variable that specifies the default
handling mode for data alignment exceptions in children threads.</p>
<p>The process object data structure is initialized with the specified
base priority, affinity, directory table base, and default alignment
exception handling mode. The process and thread quantum values are
initialized with system default values and the process is not considered
to be in the balance set.</p>
<p>The <em>Enable</em> parameter specifies the default handling mode for
data alignment exceptions in children threads. If this parameter is
TRUE, then user mode data alignment exceptions are automatically handled
by the kernel and are not raised as exceptions. Otherwise, user mode
data alignment exceptions are not handled by the kernel and may, or may
not, be raised as exceptions depending on host hardware capabilities.
Automatic handling of user data alignment exceptions means that the
kernel emulates misaligned data references and completes the offending
instructions as if no misalignment exception had occurred. Misaligned
references in kernel mode are never automatically handled and are always
raised as exceptions.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>Certain processors (e.g., the i386) always handle misaligned data in
hardware. On these processors, enabling or disabling the automatic
handling of data alignment exceptions has no effect. On other processors
(e.g., i486, MIPS r3000, r4000SP, and r4000MP) the handling of
misaligned data is handled according to the mode established for the
respective thread.</p>
<h4 id="attach-process">2.2.7.2 Attach Process</h4>
<p>A thread can attach to another process's address space with the
<strong>KeAttachProcess</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeAttachProcess</strong> (</p>
<p><strong>IN</strong> <strong>PKPROCESS</strong> <em>Process</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Process</em> - A pointer to a control object of type process.</p>
<p>Attaching to another process's address space causes the subject
thread to leave the parent process's address space and enter the address
space of the target process. This provides the capability for one thread
to alter the address space and resources of another process without
having complicated data structures or locking protocols.</p>
<p>All of the resources of the target process can be accessed and
manipulated by the subject thread while the thread is executing in the
target process's address space. This includes the process object table,
process private mapping information, working set, etc.</p>
<p>A thread can only attach to one address space at a time. If an
attempt is made to attach to a second process's address space while the
thread is already attached to another process's address space, then a
bug check will occur. In addition, a thread cannot own any mutexes when
it attaches to another process's address space. An attempt to do will
also cause a bug check to occur.</p>
<p>Attaching to another process's address causes the current APC state
of the subject thread to be saved and a new state initialized. While the
thread is executing in the attached process's address space, it can
receive APCs that were initiated in that address space. APCs that were
initiated in the parent process's address space are queued, but not
delivered until the thread returns to the parent process's address
space.</p>
<p>Attaching to another process's address space does not cause the
kernel stack of the subject thread to be locked in memory while the
target process is in the balance set. Therefore, both the source and
target processes are not allowed to leave the balance set while a thread
has the target process's address space attached. This is accomplished by
incrementing the process mutex count of both the source and target
processes. Artificially incrementing this count prevents each of the
processes from being removed from the balance set until their respective
counts go to zero. In addition, a thread that has another process's
address space attached is allowed to continue execution as if it owned a
mutex, if one of the processes is selected for removal from the balance
set by the balance set manager.</p>
<p>The execution time of a thread that has another process's address
space attached is charged to the target process.</p>
<p>This service will be used by the executive to alter the address map
of another process.</p>
<h4 id="detach-process">2.2.7.3 Detach Process</h4>
<p>A thread can detach from another process's address space with the
<strong>KeDetachProcess</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeDetachProcess</strong> (</p>
<p>);</p>
<p>Detaching from another process's address space causes the subject
thread to return to the parent process's address space.</p>
<p>If an attempt is made to detach from another process's address space
when the subject thread does not have another process's address space
attached, then a bug check will occur. In addition, if a kernel APC is
in progress, the kernel APC queue contains an entry, the user APC queue
contains an entry, or the thread owns one or more mutexes, then a bug
check will also occur.</p>
<p>Detaching from another process's address space causes the saved APC
state to be restored and the process mutex counts to be adjusted. If the
kernel APC queue is not empty, then an APC_LEVEL software interrupt is
requested which will cause the kernel mode APCs to get delivered as
appropriate.</p>
<h4 id="exclude-process">2.2.7.4 Exclude Process</h4>
<p>A process object can be excluded from the balance set with the
<strong>KeExcludeProcess</strong> function:</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeExcludeProcess</strong> (</p>
<p><strong>IN</strong> <strong>PKPROCESS</strong> <em>Process</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Process</em> - A pointer to a control object of type process.</p>
<p>The specified process is excluded from the balance set and its
children threads will be removed from further consideration by the
thread dispatcher when they no longer own any mutexes and do not have
another process's address space attached.</p>
<p>A value of TRUE is returned as the function value, if the process can
be immediately removed from the balance set (i.e., none of its children
threads own any mutexes or have any address spaces attached). Otherwise,
a value of FALSE is returned and the caller must wait on the process's
balance set event to determine the exact point when the process can be
removed from the balance set.</p>
<p>Processors on which children threads are running (Running state) or
about to run (Standby state) are forced to redispatch if their
respective threads do not own any mutexes and are not attached to
another process's address space.</p>
<p>As ready threads are considered for execution, a test is made to
determine if the thread's process is in the balance set. If the thread
does not own any mutexes, is not attached to another process' address
space, and its parent process is excluded from the balance set, then the
thread is removed from its dispatcher ready queue and inserted in the
process ready queue. The process ready queue is scanned when the process
reenters the balance set and any threads in the process's ready queue
are rereadied for execution.</p>
<p>This function is intended for use by the balance set manager.</p>
<h4 id="include-process">2.2.7.5 Include Process</h4>
<p>A process object can be included in the balance set with the
<strong>KeIncludeProcess</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeIncludeProcess</strong> (</p>
<p><strong>IN</strong> <strong>PKPROCESS</strong> <em>Process</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Process</em> - A pointer to a control object of type process.</p>
<p>The specified process is included in the balance set and the
process's ready queue is scanned. The process ready queue is a list of
threads that are ready to run, but which were moved to the process ready
queue when they were encountered in one of the dispatcher ready queues.
Each thread in the list is removed and readied for execution.</p>
<p>This function is intended for use by the balance set manager.</p>
<h4 id="set-priority-process">2.2.7.6 Set Priority Process</h4>
<p>The base priority of a process object can be set with the
<strong>KeSetPriorityProcess</strong> function:</p>
<p><strong>KPRIORITY</strong></p>
<p><strong>KeSetPriorityProcess</strong> (</p>
<p><strong>IN</strong> <strong>PKPROCESS</strong> <em>Process</em>,</p>
<p><strong>IN</strong> <strong>KPRIORITY</strong>
<em>BasePriority</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Process</em> - A pointer to a control object of type process.</p>
<p><em>BasePriority</em> - The new base priority of the process
object.</p>
<p>The base priority of the specified process is set to the specified
value and the priority of all the process's children threads are
adjusted as appropriate.</p>
<p>If the new priority is in the realtime class, then the priority of
each child thread is set to the new base priority.</p>
<p>If the new priority is in the variable class, then the priority of
each thread is computed by taking the current priority of the thread,
subtracting out the old base priority, and then adding the new base
priority. The computed value is not allowed to cross into the realtime
class or go below a priority of 1.</p>
<h4 id="process-accounting-data">2.2.7.7 Process Accounting Data</h4>
<p>As children threads within a process execute, their runtime is
accumulated in the parent process object. The units of this summation
are clock ticks.</p>
<h3 id="profile-object">2.2.8 Profile Object</h3>
<p>A <em>profile object</em> provides the capability to measure the
distribution of execution time within a block of code. Both user and
system code may be profiled.</p>
<p>Each profile object has three key attributes. First, a profile object
applies to an address range or a set of address ranges. The address
range is specified by the <em>RangeBase</em>, <em>RangeSize</em>, and
<em>Process</em> parameters. <em>RangeBase</em> and <em>RangeSize</em>
select a range of bytes (that is, the area of code) on which to collect
profile data. This range is within the address space described by the
<em>Process</em> parameter. A given profile object either profiles a
single address range within a single address space (i.e., applies to one
process) or profiles the same single address range across all processes
in the system.</p>
<p>Second, a profile object divides the address range being profiled
into buckets. Each time a program counter (PC) sample shows the PC to be
in one of these buckets, the corresponding counter is incremented. The
<em>BucketSize</em> parameter controls the size of these buckets.</p>
<p>Third, a profile object reports the number of sampling hits for any
given bucket in the corresponding counter. Counters reside in the buffer
associated with the profile object when it is created.</p>
<p>Profiling works by sampling the processors PC using a periodic
interrupt. The handler for the profiling interrupt searches the list of
active profile objects for those with address ranges that match the PC.
(I.e., the sampled PC falls within the address range associated with the
profile object, and the current process matches the process associated
with the profile object.) For each matching profile object, the bucket
is computed, and the counter corresponding to the bucket is updated.</p>
<p>When profiling is off, it consumes no processor cycles, and thus may
be present in any system. When turned on, the burden it places on the
system is inversely proportional to the profiling interval set with
<strong>KeSetIntervalProfile</strong> and proportional to the number of
active (started) profile objects. A small number of profile objects may
be active at any one time.</p>
<p>IMPLEMENTATION NOTE:</p>
<p>On symmetric MP machines, profiling interrupts occur on all
processors (at the same rate). On asymmetric machines (i.e., the
SystemPro) slave processors do NOT do profiling.</p>
<p>Programming interfaces that support the profile object include:</p>
<p><strong>KeInitializeProfile</strong> - Initialize a profile
object</p>
<p><strong>KeStartProfile</strong> - Start data collection for a profile
object</p>
<p><strong>KeStopProfile</strong> - Stop data collection for a profile
object</p>
<p><strong>KeSetIntervalProfile</strong> - Set length of profile
interval (globally)</p>
<p><strong>KeQueryIntervalProfile</strong> - Query length of profile
interval</p>
<h4 id="initialize-profile">2.2.8.1 Initialize Profile</h4>
<p>A profile object is initialized with
<strong>KeInitializeProfile.</strong></p>
<p><strong>VOID</strong></p>
<p><strong>KeInitializeProfile</strong> (</p>
<p><strong>IN PKPROFILE</strong> <em>Profile</em>,</p>
<p><strong>IN PKPROCESS</strong> <em>Process</em>
<strong>OPTIONAL</strong>,</p>
<p><strong>IN PVOID</strong> <em>RangeBase</em>,</p>
<p><strong>IN ULONG</strong> <em>RangeSize</em>,</p>
<p><strong>IN ULONG</strong> <em>BucketSize</em></p>
<p>);</p>
<p><u>Parameters</u>:</p>
<p><em>Profile</em> - A pointer to a control object of type profile.</p>
<p><em>Process</em> - If specified, a pointer to a kernel process object
that describes the address space to profile. If not specified, then all
address spaces are included in the profile.</p>
<p><em>RangeBase</em> - Address of the first byte of the address range
for which profiling information is to be collected.</p>
<p><em>RangeSize</em> - Size of the address range for which profiling
information is to be collected. The <em>RangeBase</em> and
<em>RangeSize</em> parameters are interpreted such that
<em>RangeBase</em> &lt;= address &lt;
<em>RangeBase</em>+<em>RangeSize</em> generates a profile hit.</p>
<p><em>BucketSize</em> - Log base 2 of the size of a profiling bucket.
Thus, <em>BucketSize</em> = 2 yields 4-byte buckets, <em>BucketSize</em>
= 7 yields 128-byte buckets. All profile hits in a given bucket
increment the corresponding counter in <em>Buffer</em>. Buckets cannot
be smaller than a ULONG.</p>
<p>The profile object is initialized with the specified parameter
values, and its state is set to stopped. <strong>KeStartProfile</strong>
must be called to actually start profiling.</p>
<h4 id="start-profile">2.2.8.2 Start Profile</h4>
<p><strong>KeStartProfile</strong> must be called to start gathering
data for a profile object.</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeStartProfile</strong> (</p>
<p><strong>IN PKPROFILE</strong> <em>Profile</em>,</p>
<p><strong>IN PULONG</strong> <em>Buffer</em></p>
<p>);</p>
<p><u>Parameters</u>:</p>
<p><em>Profile</em> - A pointer to a control object of type profile.</p>
<p><em>Buffer</em> - Array of ULONGs. Each ULONG is a hit counter, which
records the number of hits in the corresponding bucket. The
<em>Buffer</em> must be accessible at DPC_LEVEL and above.</p>
<p>The value TRUE is returned if the profile object is successfully
started. FALSE is returned if the object is already in the started
state. An exception (STATUS_INSUFFICIENT_RESOURCES) is raised if there
are insufficient resources available to make the profile active.</p>
<h4 id="stop-profile">2.2.8.3 Stop Profile</h4>
<p><strong>KeStopProfile</strong> is called to stop gathering data for a
profile object.</p>
<p><strong>BOOLEAN</strong></p>
<p><strong>KeStopProfile</strong> (</p>
<p><strong>IN PKPROFILE</strong> <em>Profile</em></p>
<p>)<strong>;</strong></p>
<p><u>Parameters:</u></p>
<p><em>Profile</em> - A pointer to a control object of type profile.</p>
<p>TRUE is returned if the profile is successfully stopped, FALSE if it
is not already in the started state. Once a profile is stopped, no more
updates are written into its buffer.</p>
<h4 id="set-system-profile-interval">2.2.8.4 Set System Profile
Interval</h4>
<p>The time interval between profile interrupts (and thus the profiling
rate) is set by calling <strong>KeSetIntervalProfile.</strong></p>
<p><strong>VOID</strong></p>
<p><strong>KeSetIntervalProfile</strong> (</p>
<p><strong>IN ULONG</strong> <em>Interval</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Interval</em> - The sampling interval in 100ns units.</p>
<p>The actual interval set by the system is the closest available, but
may differ significantly. <strong>KeQueryIntervalProfile</strong>
returns the actual value in use by the system.</p>
<p>The value is set globally; it affects all profiles on all
processors.</p>
<p>IMPLEMENTATION NOTE:</p>
<p>PC-based i386 and i486 machines offer sampling intervals from about
10,000 units (1 millisecond) to 300 units (30 microseconds).</p>
<h4 id="query-system-profile-interval">2.2.8.5 Query System Profile
Interval</h4>
<p><strong>KeQueryIntervalProfile</strong> returns the current profile
sampling interval.</p>
<p><strong>ULONG</strong></p>
<p><strong>KeQueryIntervalProfile</strong> (</p>
<p>);</p>
<p>The current profile sampling interval is returned in units of 100ns.
This is the value the system is actually using, and thus may be
different from the value set with
<strong>KeSetIntervalProfile</strong>.</p>
<h1 id="wait-operations">3. Wait Operations</h1>
<p>Threads synchronize their access to dispatcher objects with
object-specific functions and the generic kernel Wait functions. When a
thread desires to wait until a dispatcher object attains a Signaled
state, it executes one of the kernel Wait functions specifying the
dispatcher object as a parameter. If the dispatcher object is not
currently in a Signaled state, then the kernel puts the thread in a
Waiting state and selects another thread to run on the current
processor.</p>
<p>At some future point, a cooperating thread or system operation will
cause the specified dispatcher object to attain a state of Signaled.
When this occurs, the thread will be given a priority boost and enter
the Ready state. The thread will be dispatched for execution according
to its priority.</p>
<p>The kernel Wait functions also allow a thread to wait on more than
one dispatcher object at a time. The conditions under which the Wait
will be satisfied can be specified as <em>WaitAny</em> or
<em>WaitAll</em>.</p>
<p>If <em>WaitAny</em> is specified, then the Wait will be satisfied
when any of the objects attain a state of Signaled. If <em>WaitAll</em>
is specified, then the Wait will not be satisfied until all of the
objects <em>concurrently</em> attain a state of Signaled.</p>
<p>Each Wait operation can optionally specify a timeout value. If a
timeout value is specified, then the Wait will be automatically
satisfied if the timeout period is exceeded without the Wait being
satisfied in the normal manner.</p>
<p>If a timeout value of zero is specified, then no wait will actually
occur, but an attempt will be made to satisfy the Wait immediately. If
the Wait can be satisfied, then all side effects are performed (e.g.
acquiring a mutex). Otherwise, no side effects are performed.</p>
<p>Wait operations can be alertable or nonalertable. If a wait is
alertable and the subject thread is alerted while it is waiting, then
the wait will be satisifed with a completion status of
STATUS_ALERTED.</p>
<p>Wait operations also take a processor mode as a parameter which
specifies on whose behalf the Wait is actually occurring. This is
required since executive code itself performs the Wait operation and the
previous mode of the processor is not necessarily the correct mode. This
mode determines what happens when the subject thread is alerted or an
APC is queued while the thread is in a Waiting state.</p>
<p>Each Wait operation also takes a Wait reason as a parameter. The Wait
reason is an enumerated type supplied by the kernel and is used for
debugging system code and for system management functions (i.e., it will
be possible to display the reason a thread is in a Waiting state).</p>
<p>Programming interfaces that support wait operations include:</p>
<p><strong>KeWaitForMultipleObjects</strong> - Wait for dispatcher
objects</p>
<p><strong>KeWaitForSingleObject</strong> - Wait for one dispatcher
object</p>
<h2 id="wait-for-multiple-objects">3.1 Wait For Multiple Objects</h2>
<p>A thread can wait for a set of dispatcher objects with the
<strong>KeWaitForMultipleObjects</strong> function:</p>
<p><strong>NTSTATUS</strong></p>
<p><strong>KeWaitForMultipleObjects</strong> (</p>
<p><strong>IN</strong> <strong>CCHAR</strong> <em>Count</em>,</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>Objects[]</em>,</p>
<p><strong>IN</strong> <strong>WAIT_TYPE</strong> <em>WaitType</em>,</p>
<p><strong>IN</strong> <strong>KWAIT_REASON</strong>
<em>WaitReason</em>,</p>
<p><strong>IN</strong> <strong>KPROCESSOR_MODE</strong>
<em>WaitMode</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Alertable</em>,</p>
<p><strong>IN</strong> <strong>PTIME</strong> <em>Timeout</em>
<strong>OPTIONAL</strong>,</p>
<p><strong>IN PKWAIT_BLOCK</strong> <em>WaitBlockArray</em>
<strong>OPTIONAL</strong></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Count</em> - A count of the number of objects that are to be
waited on.</p>
<p><em>Objects</em> - An array of pointers to dispatcher objects.</p>
<p><em>WaitType</em> - The type of wait operation that is to be
performed (<em>WaitAny</em> or <em>WaitAll</em>).</p>
<p><em>WaitReason</em> - The reason for the Wait.</p>
<p><em>WaitMode</em> - The processor mode on whose behalf the Wait is
occurring.</p>
<p><em>Alertable</em> - A boolean value that specifies whether the Wait
is alertable.</p>
<p><em>Timeout</em> - An optional pointer to timeout value that
specifies the absolute or relative time over which the Wait is to be
completed.</p>
<p><em>WaitBlockArray</em> - An optional pointer to an array of wait
blocks that are to be used to describe the wait operation.</p>
<p>Each thread object has a builtin array of wait blocks that can be
used to wait on multiple objects concurrently. Whenever possible, the
builtin array of wait blocks should be used in a wait multiple operation
since no additional wait block storage need be allocated and later
deallocated. However, if the number of objects to be waited on
concurrently is greater than the number of builtin wait blocks, then the
<em>WaitBlockArray</em> parameter can be used to specify an alternate
set of wait blocks to be used in the wait operation.</p>
<p>If the <em>WaitBlockArray</em> parameter is not specified, then the
<em>Count</em> parameter must be less than or equal to
THREAD_WAIT_OBJECTS which defines the number of builtin wait objects. If
the <em>WaitBlockArray</em> parameter is not specified and the
<em>Count</em> parameter is greater than THREAD_WAIT_BLOCKS, then a bug
check will occur.</p>
<p>If the <em>WaitBlockArray</em> parameter is specified, then the
<em>Count</em> parameter must be less than or equal to
MAXIMUM_WAIT_OBJECTS which is the maximum number of objects that can be
waited on concurrently. If the <em>WaitBlockParameter</em> is specified
and the <em>Count</em> parameter is greater than MAXIMUM_WAIT_OBJECTS,
then a bug check will occur.</p>
<p>The current state for each of the specified objects is examined to
determine if the Wait can be satisfied immediately. If the Wait can be
satisfied, then necessary side effects are performed on the objects and
an appropriate value is returned as the function value. If the Wait
cannot be satisfied immediately, and either no timeout value or a
nonzero timeout value is specified, then the current thread is put in a
Waiting state and a new thread is selected for execution on the current
processor.</p>
<p>The <em>WaitType</em> parameter specifies the type of wait operation
that is to be performed. If the <em>WaitType</em> is <em>WaitAll</em>,
then all of the specified objects must attain a state of Signaled before
the Wait will be satisfied. If the <em>WaitType</em> is
<em>WaitAny</em>, then any of the objects must attain a state of
Signaled before the Wait will be satisifed.</p>
<p>The reason for the Wait is set to the value specified by the
<em>WaitReason</em> parameter.</p>
<p>The <em>WaitMode</em> parameter specifies on whose behalf the Wait is
occurring.</p>
<p>The <em>Alertable</em> parameter specifies whether the thread can be
alerted while it is in the Waiting state. If the value of this parameter
is TRUE and the thread is alerted for a mode that is equal to or more
privileged than the Wait mode, then the thread's Wait will be satisfied
with a completion status of STATUS_ALERTED.</p>
<p>If the <em>WaitMode</em> parameter is <em>UserMode</em> and the
<em>Alertable</em> parameter TRUE, then the thread can also be awakened
to deliver a user mode APC. Kernel mode APCs always cause the subject
thread to be awakened if the Wait IRQL is zero and there is not a kernel
APC in progress.</p>
<p>The <em>Timeout</em> parameter is optional. If a timeout value is
specified, then the Wait will be automatically satisfied if the timeout
occurs before the specified Wait conditions are met.</p>
<p>If a zero timeout value is specified, then the Wait will not actually
Wait regardless of whether it can be satisfied or not. An explicit
timeout value of zero allows for the testing of a set of Wait
conditions, and conditionally performing any side effects if the Wait
can be immediately satisifed (e.g. the acquisition of a mutex).</p>
<p>The expiration time of the timeout is expressed as either an absolute
time at which the Wait is to be automatically satisifed, or a time that
is relative to the current system time. If the value of the
<em>Timeout</em> parameter is negative, then the expiration time is
relative. Otherwise, the expiration time is absolute.</p>
<p>The values returned by the <strong>KeWaitForMultipleObjects</strong>
function determine how the Wait was satisfied.</p>
<p>A value in the range of zero to <em>Count</em> minus one is returned
if the Wait is satisfied by one or more of the dispatcher objects
specified by the <em>Objects</em> parameter and none of the dispatcher
objects satisfying the Wait is an abandoned mutant object. The actual
value returned is the index of the object (zero based) in the
<em>Objects</em> array that satisfied the Wait.</p>
<p>A value in the range of STATUS_ABANDONED to STATUS_ABANDONED plus
<em>Count</em> minus one is returned if the Wait is satisfied by one or
more of the dispatcher objects specified by the <em>Objects</em>
parameter and one or more of the dispatcher objects satisfying the Wait
is an abandoned mutant object. The actual value returned is the index of
the object (zero based) in the <em>Objects</em> array that satisfied the
Wait plus the value of STATUS_ABANDONED.</p>
<p>A value of STATUS_ALERTED is returned if the Wait was completed
because the thread was alerted.</p>
<p>If a value of STATUS_TIMEROUT is returned, then timeout occurred
before the specified set of wait conditions were met. Note that this
value can be returned when an explicit timeout value of zero is
specified and the specified set of wait conditions cannot be immediately
met.</p>
<p>A value of STATUS_USER_APC is returned if a user mode APC is to be
delivered.</p>
<h2 id="wait-for-single-object">3.2 Wait For Single Object</h2>
<p>A thread can wait for a single dispatcher object with the
<strong>KeWaitForSingleObject</strong> function:</p>
<p><strong>NTSTATUS</strong></p>
<p><strong>KeWaitForSingleObject</strong> (</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>Object</em>,</p>
<p><strong>IN</strong> <strong>KWAIT_REASON</strong>
<em>WaitReason</em>,</p>
<p><strong>IN</strong> <strong>KPROCESSOR_MODE</strong>
<em>WaitMode</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Alertable</em>,</p>
<p><strong>IN</strong> <strong>PTIME</strong> <em>Timeout</em>
<strong>OPTIONAL</strong></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Object</em> - A pointer to a dispatcher object.</p>
<p><em>WaitReason</em> - The reason for the Wait.</p>
<p><em>WaitMode</em> - The processor mode on whose behalf the Wait is
occurring.</p>
<p><em>Alertable</em> - A boolean value that specifies whether the Wait
is alertable.</p>
<p><em>Timeout</em> - An optional pointer to timeout value that
specifies the absolute or relative time over which the Wait is to be
completed.</p>
<p>The current state of the specified object is examined to determine if
the Wait can be satisfied immediately. If the Wait can be satisfied,
then necessary side effects are performed on the object and an
appropriate value is returned as the function value. If the Wait cannot
be satisfied immediately, and either no timeout value or a nonzero
timeout value is specified, then the current thread is put in a Waiting
state and a new thread is selected for execution on the current
processor.</p>
<p>The reason for the Wait is set to the value specified by the
<em>WaitReason</em> parameter.</p>
<p>The <em>WaitMode</em> parameter specifies on whose behalf the Wait is
occurring.</p>
<p>The <em>Alertable</em> parameter specifies whether the thread can be
alerted while it is in the Waiting state. If the value of this parameter
is TRUE and the thread is alerted for a mode that is equal to or more
privileged than the Wait mode, then the thread's Wait will be satisfied
with a completion status of STATUS_ALERTED.</p>
<p>If the <em>WaitMode</em> parameter is <em>UserMode</em> and the
<em>Alertable</em> parameter TRUE, then the thread can also be awakened
to deliver a user mode APC. Kernel mode APCs always cause the subject
thread to be awakened if the Wait IRQL is zero and there is not a kernel
APC in progress.</p>
<p>The <em>Timeout</em> parameter is optional. If a timeout value is
specified, then the Wait will be automatically satisfied if the timeout
occurs before the specified Wait conditions are met.</p>
<p>If a zero timeout value is specified, then the Wait will not actually
Wait regardless of whether it can be satisfied or not. An explicit
timeout value of zero allows for the testing of a set of Wait
conditions, and conditionally performing any side effects if the Wait
can be immediately satisifed (e.g. the acquisition of a mutex).</p>
<p>The expiration time of the timeout is expressed as either an absolute
time at which the Wait is to be automatically satisifed, or a time that
is relative to the current system time. If the value of the
<em>Timeout</em> parameter is negative, then the expiration time is
relative. Otherwise, the expiration time is absolute.</p>
<p>The values returned by the <strong>KeWaitForSingleObject</strong>
function determine how the Wait was satisfied.</p>
<p>A value of STATUS_SUCCESS is returned if the dispatcher object
specified by the <em>Object</em> parameter satisfied the Wait.</p>
<p>A value of STATUS_ABANDONED is returned if the dispatcher object
specified by the <em>Object</em> parameter satisfied the Wait and is a
mutant object that was previously abandoned.</p>
<p>A value of STATUS_ALERTED is returned if the Wait was completed
because the thread was alerted.</p>
<p>If a value of STATUS_TIMEOUT is returned, then timeout occurred
before the specified wait condition was met. Note that this value can be
returned when an explicit timeout value of zero is specified and the
specified set of wait conditions cannot be immediately met.</p>
<p>A value of STATUS_USER_APC is returned if a user mode APC is to be
delivered.</p>
<h1 id="miscellaneous-operations">4. Miscellaneous Operations</h1>
<p>Several miscellaneous functions are provided to perform
hardware-related operations and to provide the operations necessary to
debug a multiprocessor operating system.</p>
<p>The exact implementation for some of these operations varies,
depending on the particular host architecture. Implementation notes have
been provided for these functions.</p>
<p>Programming interfaces that support miscellaneous operations
include:</p>
<p><strong>KeBugCheck</strong> - Generate bug check halt</p>
<p><strong>KeContextFromKframes</strong> - Move machine state to context
frames</p>
<p><strong>KeContextToKframes</strong> - Move machine state from context
frames</p>
<p><strong>KeFillEntryTb</strong> - Fill translation buffer entry</p>
<p><strong>KeFlushDcache</strong> - Flush data cache</p>
<p><strong>KeFlushEntireTb</strong> - Flush entire translation
buffer</p>
<p><strong>KeFlushIcache</strong> - Flush instruction cache</p>
<p><strong>KeFlushIoBuffers</strong> - Flush I/O buffers from the data
cache</p>
<p><strong>KeFlushSingleTb</strong> - Flush single translation buffer
entry</p>
<p><strong>KeFreezeExecution</strong> - Freeze processor execution</p>
<p><strong>KeGetCurrentApcEnvironment</strong> - Get the current APC
environment</p>
<p><strong>KeGetCurrentIrql</strong> - Get the current IRQL</p>
<p><strong>KeGetPreviousMode</strong> - Get previous processor mode</p>
<p><strong>KeLowerIrql</strong> - Lower the current IRQL to the
specified value</p>
<p><strong>KeQuerySystemTime</strong> - Query the current system
time</p>
<p><strong>KeRaiseIrql</strong> - Raise the current IRQL to the
specified value</p>
<p><strong>KeRundownThread</strong> - Run down thread before
termination</p>
<p><strong>KeSetSystemTime</strong> - Set the current system time</p>
<p><strong>KeStallExecutionProcessor</strong> - Stall processor
execution</p>
<p><strong>KeUnFreezeExecution</strong> - Unfreeze processor
execution</p>
<h2 id="bug-check">4.1 Bug Check</h2>
<p>A bug check halt can be generated with the
<strong>KeBugCheck</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeBugCheck</strong> (</p>
<p><strong>IN</strong> <strong>ULONG</strong> <em>BugCheckCode</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>BugCheckCode</em> - A value that specifies the reason for the bug
check.</p>
<p>A bug check is a system-detected error that causes a controlled
shutdown of the system. The various kernel mode components of the system
perform online consistency checking. When an inconsistency is
discovered, a bug check is generated.</p>
<h2 id="context-frame-manipulation">4.2 Context Frame Manipulation</h2>
<p>The kernel trap handler is responsible for saving and restoring
machine state when an interrupt, exception, system call, or other
trapping condition is detected by system hardware.</p>
<p>Depending on the type of trapping condition, the trap handler may
save only the volatile register state, or may save both the volatile and
the nonvolatile register state. In addition, the previous processor
state and floating point status are also saved.</p>
<p>This state information is saved on the kernel stack in the form of a
call frame. Separate call frames are used to store the volatile and the
nonvolatile register state. These frames are called the trap frame and
exception frame respectively.</p>
<p>A third structure, called a context frame, is constructed from the
information contained in the trap and exception frames. This structure
contains the complete machine state for a thread of execution.</p>
<p>A context frame is used to specify the initial machine state of a
thread, to save the previous machine state when an exception handler is
invoked, and to continue the execution of a thread after an exception
has been handled.</p>
<p>The kernel supplies two routines to marshal information to/from a
context frame.</p>
<h3 id="move-machine-state-to-context-frame">4.2.1 Move Machine State To
Context Frame</h3>
<p>Saved machine state can be moved from a trap frame and/or an
exception frame to a context frame with the
<strong>KeContextFromKframes</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeContextFromKframes</strong> (</p>
<p><strong>IN PKTRAP_FRAME</strong> <em>TrapFrame</em>,</p>
<p><strong>IN PKEXCEPTION_FRAME</strong> <em>ExceptionFrame</em>,</p>
<p><strong>IN OUT PCONTEXT</strong> <em>ContextFrame</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>TrapFrame</em> - A pointer to a trap frame.</p>
<p><em>ExceptionFrame</em> - A pointer to an exception frame.</p>
<p><em>ContextFrame</em> - A pointer to a context frame.</p>
<p>Saved machine state is moved from the specified trap frame and/or the
specified exception frame to the specified context frame. The
<em>ContextFlags</em> field of the context frame controls the
information that is moved.</p>
<p>ContextFlags Field</p>
<p><em>CONTEXT_CONTROL</em> - Specifies that the processor state
information from the trap frame is to be moved to the context frame.</p>
<p><em>CONTEXT_FLOATING_POINT</em> - Specifies that the floating point
register state from the trap and exception frames is to be moved to the
context frame.</p>
<p><em>CONTEXT_INTEGER</em> - Specifies that the integer register state
from the trap and exception frames is to be moved to the context
frame.</p>
<p><em>CONTEXT_PIPELINE</em> - Specifies that the floating point pipe
state is to be moved from the trap frame to the context frame.</p>
<p><em>CONTEXT_FULL</em> - Specifies that all of the state information
from the trap and exception frames is to be moved to the context
frame.</p>
<h3 id="move-machine-state-from-context-frame">4.2.2 Move Machine State
From Context Frame</h3>
<p>Saved machine state can be moved from a context frame to a trap frame
and/or an exception frame with the <strong>KeContextToKframes</strong>
function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeContextToKframes</strong> (</p>
<p><strong>IN OUT PKTRAP_FRAME</strong> <em>TrapFrame</em>,</p>
<p><strong>IN OUT PKEXCEPTION_FRAME</strong>
<em>ExceptionFrame</em>,</p>
<p><strong>IN PCONTEXT</strong> <em>ContextFrame</em>,</p>
<p><strong>IN ULONG</strong> <em>ContextFlags</em>,</p>
<p><strong>IN KPROCESSOR_MODE</strong> <em>PreviousMode</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>TrapFrame</em> - A pointer to a trap frame.</p>
<p><em>ExceptionFrame</em> - A pointer to an exception frame.</p>
<p><em>ContextFrame</em> - A pointer to a context frame.</p>
<p><em>ContextFlags</em> - A set of flags that specifies the state
information that is to be moved from the specified context frame to the
specified trap frame and/or the specified exception frame.</p>
<p>ContextFlags Flags</p>
<p><em>CONTEXT_CONTROL</em> - Specifies that the processor state
information from the context frame is to be moved to the trap frame.</p>
<p><em>CONTEXT_FLOATING_POINT</em> - Specifies that the floating point
register state from the context frame is to be moved to the trap and
exception frames.</p>
<p><em>CONTEXT_INTEGER</em> - Specifies that the integer register state
from the context frame is to be moved to the trap and exception
frames.</p>
<p><em>CONTEXT_PIPELINE</em> - Specifies that the floating point pipe
state is to be moved from the context frame to the trap frame.</p>
<p><em>CONTEXT_FULL</em> - Specifies that all of the state information
from the context frame is to be moved to the trap and exception
frames.</p>
<p><em>PreviousMode</em> - The processor mode for which the context
frame is specified.</p>
<p>Saved machine state is moved from the specified context frame to the
specified trap frame and/or the specified exception frame. The
<em>ContextFlags</em> parameter specifies the information that is to be
moved. The <em>PreviousMode</em> parameter determines which bits the
caller may specify if the processor state information is being moved to
the trap frame.</p>
<h2 id="fill-entry-translation-buffer">4.3 Fill Entry Translation
Buffer</h2>
<p>A page table entry can be inserted into the translation buffer of the
current processor with the <strong>KeFillEntryTb</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeFillEntryTb</strong> (</p>
<p><strong>IN</strong> <strong>HARDWARE_PTE</strong>
<em>Pte[1]</em>,</p>
<p><strong>IN PVOID</strong> <em>Virtual</em>,</p>
<p><strong>IN BOOLEAN</strong> <em>Invalid</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Pte</em> - A pointer to a page table entry, or a pair of page
table entries, that are to be inserted into the translation buffer of
the current processor.</p>
<p><em>Virtual</em> - The virtual address that corresponds to the first
page table entry.</p>
<p><em>Invalid</em> - A boolean value that determines whether a
translation buffer entry should be invalidated if the host architecture
does not provide a software-managed translation buffer.</p>
<p>This function is intended for use by memory management software for
the following cases:</p>
<p>1. A page table entry transitions from the invalid to the valid
state.</p>
<p>2. A page table entry transitions from the unmodified (clean) to the
modified (dirty) state.</p>
<p>3. A page table entry transitions from the unaccessed to the accessed
state.</p>
<p>None of these transitions affects other processors in the
configuration; however, they provide the opportunity to optimize the
filling of the translation buffer on systems that have a
software-managed translation buffer.</p>
<p>If the page table entry is transitioning from the invalid to the
valid state, then the <em>Invalid</em> parameter should be FALSE.
Otherwise, the <em>Invalid</em> parameter should be TRUE.</p>
<p>If the specified virtual address is already mapped by the translation
buffer, then the contents of the specified page table entry(s) replace
the page table entry in the translation buffer. Otherwise, a new
translation buffer entry is created that maps the specified virtual
address.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>The Intel i860 does not have a software-managed translation buffer.
It also cannot invalidate a single translation buffer entry. Therefore,
if the <em>Invalid</em> parameter is TRUE, then the entire translation
buffer is invalidated. Otherwise, no operation is performed.</p>
<p>The Intel i386 and i486 do not have a software-managed translation
buffer. Also neither of these processors can invalidate a single
translation buffer entry. Therefore, if the <em>Invalid</em> parameter
is TRUE, the entire translation buffer is invalidated. Otherwise, no
operation is performed.</p>
<p>\ The i486 can invalidate a single translation buffer entry, but it
is not yet supported. \</p>
<p>The MIPS r3000, r4000SP, and r4000MP have software-managed
translation buffers. Therefore, the specified page table entry either
replaces the current translation buffer entry or a new translation
buffer entry is created to map the specified virtual address.</p>
<h2 id="flush-data-cache">4.4 Flush Data Cache</h2>
<p>The data cache can be flushed on all processors, or only that set of
processors that are currently executing threads that belong to the
current thread's process with the <strong>KeFlushDcache</strong>
function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeFlushDcache</strong> (</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong>
<em>AllProcessors</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>AllProcessors</em> - A boolean value that determines which data
caches are to be flushed.</p>
<p>This function is intended for use by memory management and device
driver software to keep the data cache coherent with DMA I/O
operations.</p>
<p>If the <em>AllProcessors</em> parameter is TRUE, then the data cache
is flushed on all processors in the system. Otherwise, only the data
caches on processors running threads that belong to the current thread's
process are flushed.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>The Intel i860 employs a writeback data cache with virtual tags that
does not maintain coherency with DMA I/O operations. Therefore, this
function must flush the data cache.</p>
<p>The Intel i386 and i486 employ data caches that maintain coherency
with I/O operations. Therefore, this function performs no operation.</p>
<p>The MIPS r3000 and r4000SP employ data caches that do not maintain
coherency with I/O operations. Therefore, the data cache must be flushed
for this function.</p>
<p>The MIPS r4000MP employs a data cache that maintains coherency with
I/O operations. Therefore, this function performs no operation.</p>
<h2 id="flush-entire-translation-buffer">4.5 Flush Entire Translation
Buffer</h2>
<p>The entire translation buffer can be flushed on all processors, or
only that set of processors that are currently executing threads that
belong to the current thread's process with the
<strong>KeFlushEntireTb</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeFlushEntireTb</strong> (</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Invalid</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong>
<em>AllProcessors</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Invalid</em> - A boolean value that specifies why the translation
buffer is being flushed.</p>
<p><em>AllProcessors</em> - A boolean value that determines which
translation buffers are to be flushed.</p>
<p>This function is intended for use by memory management software when
virtual pages are deleted, removed from the process working set, or
their protection is changed. Normally, the entire translation buffer is
not flushed when virtual pages are removed from the process working set.
However, when a number of pages are removed all at once, it is more
efficient to simply flush the entire translation buffer rather than
flush individual entries.</p>
<p>If the value of the <em>Invalid</em> parameter is TRUE, then the
translation buffer is being flushed because one or more pages have
become invalid and not present in memory. If the value of the
<em>Invalid</em> parameter is FALSE, then the translation buffer is
being flushed because the protection on one or more pages has been
changed.</p>
<p>If the <em>AllProcessors</em> parameter is TRUE, then the entire
translation buffer is flushed on all processors in the system.
Otherwise, only the translation buffers on processors running threads
that belong to the current thread's process are flushed.</p>
<p>IMPLEMENTATION NOTE:</p>
<p>The Intel i860 employs a data cache with virtual tags. It also cannot
flush the translation buffer without also flushing the instruction
cache. If the <em>Invalid</em> parameter is TRUE, then the data cache is
flushed in addition to flushing the instruction cache and invalidating
the translation buffer. Otherwise, the instruction cache is flushed and
the translation buffer is invalidated.</p>
<p>The Intel i386 and i486 flush the translation buffer for this
function.</p>
<p>The MIPS r3000, r4000SP, and r4000MP flush the random part of the
software-managed translation buffer for this function. The fixed part of
the translation buffer is not affected.</p>
<h2 id="flush-instruction-cache">4.6 Flush Instruction Cache</h2>
<p>The instruction cache can be flushed on all processors, or only that
set of processors that are currently executing threads that belong to
the current thread's process with the <strong>KeFlushIcache</strong>
function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeFlushIcache</strong> (</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong>
<em>AllProcessors</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>AllProcessors</em> - A boolean value that determines which
instruction caches are to be flushed.</p>
<p>This function is intended for use by system debuggers. When a
breakpoint is inserted in system code, the instruction caches of all
processors in the system must be flushed. If a breakpoint is placed in
process code, then only the instruction caches of processors executing
threads that belong to current thread's process need to be flushed.</p>
<p>The executive also exports this function for use by code that
modifies the instruction stream. After each such modification, and
before attempting to execute the modified instructions, the instruction
cache must be flushed.</p>
<p>If the <em>AllProcessors</em> parameter is TRUE, then the instruction
cache is flushed on all processors in the system. Otherwise, only the
instruction caches on processors running threads that belong to the
current thread's process are flushed.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>The Intel i860 does not maintain coherency between the data and
instruction caches. It also cannot flush the instruction cache without
invalidating the translation buffer. Therefore, the instruction cache is
flushed and the translation buffer is invalidated for this function.</p>
<p>The Intel i386 and i486 maintain coherency between the data and
instruction caches. Therefore, no operation is performed for this
function.</p>
<p>The MIPS r3000, r4000SP, and r4000MP do not maintain coherency
between the instruction and data caches. Therefore, the instruction
cache is flushed for this function.</p>
<h2 id="flush-io-buffers">4.7 Flush I/O Buffers</h2>
<p>The memory region occupied by an I/O buffer can be flushed from both
the instruction and data caches of all processors in the system with the
<strong>KeFlushIoBuffers</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeFlushIoBuffers</strong> (</p>
<p><strong>IN</strong> <strong>PMDL</strong> <em>Mdl</em>,</p>
<p><strong>IN BOOLEAN</strong> <em>ReadOperation</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Mdl</em> - A pointer to a memory descriptor list that describes
the areas of memory occupied by the I/O buffer.</p>
<p><em>ReadOperation</em> - A boolean value that determines whether the
flush is being performed for a read operation.</p>
<p>This function is intended for use by device drivers and affects all
processors in the system.</p>
<p>If the <em>ReadOperation</em> parameter is TRUE, then the I/O
operation is reading information into memory that may be valid in the
instruction and data caches. If the <em>ReadOperation</em> parameter is
FALSE, then the I/O operation is writing data from memory to a device
and information may be present in the data cache and not in memory.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>The Intel i860 employs a writeback data cache and an instruction
cache that do not maintain coherency with I/O operations. Therefore, the
data cache must be flushed for both read and write operations. The Intel
i860 also cannot flush the instruction cache without invalidating the
translation buffer. Therefore, if the <em>ReadOperation</em> parameter
is TRUE, then the instruction cache is flushed and the translation
buffer is also invalidated for this function.</p>
<p>The Intel i386 and i486 maintain data and instruction cache coherency
with I/O operations. Therefore, no operation is performed for this
function.</p>
<p>\ The i486 has a write buffer which may have to be flushed before all
I/O operations. \</p>
<p>The MIPS r3000 employs a write-through data cache and does not
maintain coherency with I/O operations for either of the instruction or
data caches. Therefore, if the <em>ReadOperation</em> parameter is TRUE,
then both the instruction and data caches must be flushed. Otherwise, no
operation is performed for this function.</p>
<p>\ The r3000 has a write buffer which must be flushed before all I/O
operations. \</p>
<p>The MIPS r4000SP employs a writeback data cache and an instruction
cache that do not maintain coherency with I/O operations. Therefore, the
data cache must be flushed for both read and write operations. In
addition, if the <em>ReadOperation</em> parameter is TRUE, then the
instruction cache is also flushed for this function.</p>
<p>The MIPS r4000MP employs a writeback data cache that maintains
coherency with I/O operations. However, cache coherency is not
maintained for the instruction cache with I/O operations. Therefore, if
the <em>ReadOperation</em> parameter is TRUE, then the instruction cache
is flushed. Otherwise, no operation is performed for this function.</p>
<h2 id="flush-single-translation-buffer-entry">4.8 Flush Single
Translation Buffer Entry</h2>
<p>A single entry can be flushed from the translation buffer of all
processors, or only that set of processors that are currently executing
threads that belong to the current thread's process with the
<strong>KeFlushSingleTb</strong> function:</p>
<p><strong>HARDWARE_PTE</strong></p>
<p><strong>KeFlushSingleTb</strong> (</p>
<p><strong>IN</strong> <strong>PVOID</strong> <em>Virtual</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong> <em>Invalid</em>,</p>
<p><strong>IN</strong> <strong>BOOLEAN</strong>
<em>AllProcessors</em>,</p>
<p><strong>IN</strong> <strong>PHARDWARE_PTE</strong>
<em>PtePointer</em>,</p>
<p><strong>IN</strong> <strong>HARDWARE_PTE</strong>
<em>PteValue</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Virtual</em> - A virtual address that is within the page whose
translation buffer entry is to be flushed.</p>
<p><em>Invalid</em> - A boolean value that specifies why the translation
buffer is being flushed.</p>
<p><em>AllProcessors</em> - A boolean value that determines which
translation buffers are to be flushed.</p>
<p><em>PtePointer</em> - A Pointer to a page table entry which is to be
updated with the new PteValue.</p>
<p><em>PteValue</em> - The new Pte value.</p>
<p><u>Return Value</u>:</p>
<p>The contents of the page table entry <em>PtePointer</em> refers to
before the entry is set to <em>PteValue</em>.</p>
<p>This function is intended for use by virtual memory management
software when a virtual page is deleted, removed from the process
working set, or its protection is changed. If several virtual pages are
removed from a process's address space at once or their protection is
changed, then it may be more efficient to use the
<strong>KeFlushEntireTb</strong> function.</p>
<p>If the value of the <em>Invalid</em> parameter is TRUE, then the
translation buffer is being flushed because a page has become invalid
and is not present in memory. If the value of the <em>Invalid</em>
parameter is FALSE, then the translation buffer is being flushed because
the protection on a page has been changed.</p>
<p>If the <em>AllProcessors</em> parameter is TRUE, then the specified
translation buffer entry is flushed on all processors in the system.
Otherwise, only the specified translation buffer entry on process
running threads that belong to the current thread's processor are
flushed.</p>
<p>IMPLEMENTATION NOTE:</p>
<p>The Intel i860 employs a data cache with virtual tags. It also cannot
invalidate a single entry from the translation buffer nor can it
invalidate the translation buffer without also flushing the instruction
cache. If the <em>Invalid</em> parameter is TRUE, then the data cache is
flushed in addition to flushing the instruction cache and invalidating
the translation buffer. Otherwise, the instruction cache is flushed and
the translation buffer is invalidated.</p>
<p>The Intel i386 and i486 cannot flush a single entry from the
translation buffer. Therefore, the entire translation buffer is
invalidated for this function.</p>
<p>\ The i486 can invalidate a single translation buffer entry, but it
is not yet supported. \</p>
<p>The MIPS r3000, r4000SP, and r4000MP provide the capability to flush
a single entry from the random part of the software-managed translation
buffer. Therefore, a single translation buffer entry is invalidated for
this function.</p>
<h2 id="freeze-execution">4.9 Freeze Execution</h2>
<p>The execution of all other processors in the system, excluding the
current processor, can be frozen with the
<strong>KeFreezeExecution</strong> function:</p>
<p><strong>KIRQL</strong></p>
<p><strong>KeFreezeExecution</strong> (</p>
<p>);</p>
<p>The IRQL is raised to the highest level, the execution of all other
processors in the host configuration is frozen, and the previous IRQL is
returned as the function value.</p>
<p>This function does not return control to the caller until the
execution of all other processors has been frozen. It is intended for
use by system debuggers and should be called whenever the debugger is
entered so that a consistent picture of the multiprocessor system can be
examined and modified.</p>
<h2 id="get-current-apc-environment">4.10 Get Current APC
Environment</h2>
<p>The APC execution environment for the current thread can be obtained
with the <strong>KeGetCurrentApcEnvironment</strong> function:</p>
<p><strong>KAPC_ENVIRONMENT</strong></p>
<p><strong>KeGetCurrentApcEnvironment</strong> (</p>
<p>);</p>
<p>The APC execution environment is obtained from the current thread and
returned as the function value.</p>
<p>Possible values that can be returned by this function include:</p>
<p>o OriginalApcEnvironment - The current APC environment is the
thread's parent process.</p>
<p>o AttachedApcEnvironment - The current APC environment is a process
that has been attached by the current thread.</p>
<h2 id="get-current-irql">4.11 Get Current IRQL</h2>
<p>The current IRQL can be obtained with the
<strong>KeGetCurrentIrql</strong> function:</p>
<p><strong>KIRQL</strong></p>
<p><strong>KeGetCurrentIrql</strong> (</p>
<p>);</p>
<p>The current IRQL is returned as the function value.</p>
<h2 id="get-previous-mode">4.12 Get Previous Mode</h2>
<p>The previous processor mode can be obtained with the
<strong>KeGetPreviousMode</strong> function:</p>
<p><strong>KPROCESSOR_MODE</strong></p>
<p><strong>KeGetPreviousMode</strong> (</p>
<p>);</p>
<p>The previous processor mode is obtained from the processor status.
This function can be used to determine the previous processor mode
during a system service.</p>
<h2 id="lower-irql">4.13 Lower IRQL</h2>
<p>The current IRQL can be lowered with the <strong>KeLowerIrql</strong>
function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeLowerIrql</strong> (</p>
<p><strong>IN</strong> <strong>KIRQL</strong> <em>NewIrql</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>NewIrql</em> - The new IRQL value.</p>
<p>If the new IRQL is greater than the current IRQL, then a bug check
will occur. Otherwise, the current IRQL is set to the specified
value.</p>
<h2 id="query-system-time">4.14 Query System Time</h2>
<p>The current system time can be queried with the
<strong>KeQuerySystemTime</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeQuerySystemTime</strong> (</p>
<p><strong>OUT PTIME</strong> <em>CurrentTime</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>CurrentTime</em> - A pointer to a variable that receives the
current system time.</p>
<p>This function returns the current system time in 100ns units. It is
the responsibility of the executive to maintain the correspondence
between system time and external time as seen by a user of the
system.</p>
<h2 id="raise-irql">4.15 Raise IRQL</h2>
<p>The current <strong>IRQL</strong> can be raised with the
<strong>KeRaiseIrql</strong> function:</p>
<p><strong>KIRQL</strong></p>
<p><strong>KeRaiseIrql</strong> (</p>
<p><strong>IN</strong> <strong>KIRQL</strong> <em>NewIrql</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>NewIrql</em> - The new IRQL value.</p>
<p>If the new IRQL is less than the current IRQL, then a bug check will
occur. Otherwise, the current IRQL is set to the specified value.</p>
<h2 id="run-down-thread">4.16 Run Down Thread</h2>
<p>Data structures for the current thread that must be guarded by the
dispatcher database lock can be run down with the
<strong>KeRundownThread</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeRundownThread</strong> (</p>
<p>);</p>
<p>This function is intended for use just prior to terminating a thread.
It run downs appropriate data structures and performs operations
necessary to terminate the thread.</p>
<p>Operations performed include:</p>
<p>1. Processing of the mutant ownership list which causes each mutant
object owned by the current thread to be released with an abandoned
status.</p>
<h2 id="set-system-time">4.17 Set System Time</h2>
<p>The current system time can be set with the
<strong>KeSetSystemTime</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeSetSystemTime</strong> (</p>
<p><strong>IN PTIME</strong> <em>NewTime</em>,</p>
<p><strong>OUT PTIME</strong> <em>OldTime</em>,</p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>NewTime</em> - A pointer to a variable that specifies the new
system time.</p>
<p><em>OldTime</em> - A pointer to a variable that receives the previous
system time.</p>
<p>This function returns the previous system time in 100ns units and
sets the system time to the specified value. It is the responsibility of
the executive to maintain the correspondence between system time and
external time as seen by a user of the system.</p>
<h2 id="stall-execution">4.18 Stall Execution</h2>
<p>The execution of the current processor can be stalled with the
<strong>KeStallExecutionProcessor</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeStallExecutionProcessor</strong> (</p>
<p><strong>IN ULONG</strong> <em>MicroSeconds</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>MicroSeconds</em> - The number of microseconds for which
execution is to be stalled.</p>
<p>This function stalls the execution of the current processor by
executing a processor-dependent routine that busy waits at least the
specified number of microseconds, but not significantly longer.</p>
<p>This routine is intended for use by device drivers and other software
that must wait a short interval which is less than a clock tick, but
larger than a few instructions.</p>
<p>IMPLEMENTATION NOTES:</p>
<p>This function is guaranteed to busy wait for at least the number of
specified microseconds and is calibrated at system initialization. Long
intervals tend to be very accurate, whereas, short intervals may busy
wait for a period that is slightly longer than the specified number of
microseconds.</p>
<h2 id="unfreeze-execution">4.19 Unfreeze Execution</h2>
<p>The execution of all other processors in a host configuration,
excluding the current processor, can be resumed with the
<strong>KeUnfreezeExecution</strong> function:</p>
<p><strong>VOID</strong></p>
<p><strong>KeUnfreezeExecution</strong> (</p>
<p><strong>IN</strong> <strong>KIRQL</strong> <em>Irql</em></p>
<p>);</p>
<p><u>Parameters:</u></p>
<p><em>Irql</em> - The previous IRQL value that is to be restored.</p>
<p>The execution of all processors in the system, excluding the current
processor, is unfrozen, the previous IRQL is restored, and the
instruction cache of each processor in the configuration is flushed.</p>
<p>This function is intended for use by system debuggers and should be
called when execution is to be continued after entering the debugger and
calling <strong>KeFreezeExecution</strong> function. Before the
execution of an unfrozen processor is continued, its instruction cache
and translation buffer are flushed.</p>
<h1 id="intel-x86-specific-functions.">5. Intel x86 Specific
Functions.</h1>
<p>There is a small set of special functions peculiar to the Intel x86
family of processors, which are necessary to fully exploit those
processors. These functions are used primarily to manipulate x86
specific control structures, such as the Ldt.</p>
<p>Programming interfaces:</p>
<p>Ke386SetLdtProcess - Set Ldt for a process</p>
<p>Ke386SetDescriptorProcess - Set entry in Ldt a process</p>
<h2 id="load-an-ldt-for-a-process.">5.1 Load an Ldt for a process.</h2>
<p>An Ldt (Local Descriptor Table) can be made the active Ldt for a
process with Ke386SetLdtProcess:</p>
<p>VOID</p>
<p>Ke386SetLdtProcess (</p>
<p>PKPROCESS Process,</p>
<p>PLDT_ENTRY Ldt[],</p>
<p>ULONG Limit</p>
<p>);</p>
<p>Parameters:</p>
<p>Process - Pointer to KPROCESS object describing the process for which
the Ldt is to be set.</p>
<p>Ldt - Pointer to an array of LDT_ENTRYs (that is, a pointer to an
Ldt.</p>
<p>Limit - Ldt limit (must be 0 mod 8)</p>
<p>The specified LDT (which may be null) will be made the active Ldt of
the specified process, for all threads thereof, on whichever processors
they are running. The change will take effect before the call
returns.</p>
<p>An Ldt address of NULL or a Limit of 0 will cause the process to
receive the NULL Ldt.</p>
<p>This function only exists on i386 and i386 compatible processors.</p>
<p>No checking is done on the validity of Ldt entries.</p>
<p>IMPLEMENATION NOTES:</p>
<p>While a single Ldt structure can be shared among processes, any edits
to the Ldt of one of those processes will only be synchronized for that
process. Thus, processes other than the one the change is applied to may
not see the change correctly.</p>
<h2 id="set-and-entry-in-a-processs-ldt.">5.2 Set and Entry in a
Process's Ldt.</h2>
<p>An individual entry in the Ldt of a process may be edited with
Ke386SetDescriptorProcess:</p>
<p>VOID</p>
<p>Ke386SetDescriptorProcess (</p>
<p>PKPROCESS Process,</p>
<p>ULONG Offset,</p>
<p>LDT_ENTRY LdtEntry</p>
<p>);</p>
<p>Parameters:</p>
<p>Process - Pointer to KPROCESS object describing the process for which
the descriptor edit is to be performed.</p>
<p>Offset - Byte offset into the Ldt of the descriptor to edit. Must be
0 mod 8.</p>
<p>LdtEntry - Value to edit into the descriptor in hardware format. No
checking is done on the validity of this item.</p>
<p>The specified LdtEntry (which could be 0, not present, etc) will be
edited into the specified Offset in the Ldt of the specified Process.
This will be synchronized across all the processors executing the
process. The edit will take affect on all processors before the call
returns.</p>
<h2 id="get-an-entry-from-a-threads-gdt.">Get an Entry from a Thread's
Gdt.</h2>
<h2 id="get-an-entry-from-a-threads-gdt.-1">Get an Entry from a Thread's
Gdt.</h2>
<h2 id="get-an-entry-from-a-threads-gdt.-2">5.3 Get an Entry from a
Thread's Gdt.</h2>
<p>An individual entry in the Gdt of a thread may be obtained using
Ke386GetGdtEntryThread:</p>
<p><strong>VOID</strong></p>
<p><strong>Ke386GetGdtEntryThread (</strong></p>
<p><strong>IN PKTHREAD</strong> <em>Thread</em>,</p>
<p><strong>IN ULONG</strong> <em>Offset</em>,</p>
<p><strong>IN PGDT_ENTRY</strong> <em>Descriptor</em></p>
<p><strong>);</strong></p>
<p><u>Parameters:</u></p>
<p><em>Thread</em> —— Supplies a pointer to the thread from whose Gdt
the entry is to come.</p>
<p><em>Offset</em> —— Supplies the descriptor number of the descriptor
to return. This value must be 0 mod 8.</p>
<p><em>Descriptor</em> —— Returns the descriptor contents</p>
<p>The Gdt entry specified by <em>Selector</em> will be copied from the
specified thread's Gdt, into <em>Descriptor</em>.</p>
<p>For descriptors that don't exist when the thread is not running
(KGDT_R3_TEB, and KGDT_LDT), the descriptor values will be
"materialized".</p>
<p>For descriptors that are processor specific, rather than thread
specific, the current processor's value will be returned.</p>
<p>For all other Gdt descriptors, the descriptor will be copied from the
Gdt.</p>
<p><strong>Revision History:</strong></p>
<p>Original Draft 1.0, March 8, 1989</p>
<p>Revision 1.1, March 16, 1989</p>
<p>1. Add text to describe the muxwait object.</p>
<p>2. Add text to describe the interrupt object.</p>
<p>3. Add text to describe the power notify object.</p>
<p>4. Add text to describe the power status object.</p>
<p>5. Add text to describe the generic wait functions.</p>
<p>6. Addition of text to describe the miscellaneous functions.</p>
<p>7. Add text to overview of document.</p>
<p>Revision 1.2, March 29, 1989</p>
<p>1. Change <strong>KeDelayExecution</strong> to return a wait
completion value.</p>
<p>2. Complete section on multiprocessor synchronization.</p>
<p>3. Complete section on device queue object.</p>
<p>4. Delete muxwait object and replace with a wait multiple function
that takes an array of pointer to dispatcher objects as a parameter.</p>
<p>Revision 1.3, April 18,1989</p>
<p>1. Alphabetically order section on miscellaneous functions.</p>
<p>2. Add <strong>KeBugCheck</strong>, <strong>KeLowerIrql</strong>, and
<strong>KeRaiseIrql</strong> miscellaneous functions.</p>
<p>3. A thread will start execution at IRQL APC_LEVEL rather than with
APCs disabled.</p>
<p>4. Returning from the executive thread start up routine will cause a
thread to enter user mode provide that a user mode context was supplied
when the thread was initialized.</p>
<p>5. Add three parameters to thread initialization to optionally
describe user mode context.</p>
<p>6. Delete builtin user mode alert APC. Alerting a thread that is
waiting alertable causes a wait completion status of ALERTED to be
returned.</p>
<p>7. Replace all reference to DPC_LEVEL with DISPATCH_LEVEL.</p>
<p>8. Put interrupt level names in hardware interrupt table.</p>
<p>9. Add pointers to the PRCB which point to the time expiration and
power notify DPC's that are system wide.</p>
<p>10. Change thread context to include ten pipeline state registers
rather than six.</p>
<p>11. Change <strong>KeResumeThread</strong> and
<strong>KeSuspendThread</strong> to return a CHAR rather than a
UCHAR.</p>
<p>12. Delete voluntary and preemption wait counters from thread
object.</p>
<p>13. Reduce number of APC and DPC system parameters to two.</p>
<p>14. If a device is Not-Busy, then release device queue spin lock but
do not lower IRQL before returning.</p>
<p>15. Allow interrupt service routine to user the floating point
registers for block moves and graphics functions.</p>
<p>16. If a thread is awakened to deliver a user mode APC, then return a
status of USER_APC.</p>
<p>Revision 1.4, May 4, 1989</p>
<p>1. Delete increment parameter from
<strong>KeReleaseMutex</strong>.</p>
<p>2. Change <em>Count</em> and <em>Limit</em> parameters of
<strong>KeInitializeSemaphore</strong> from ULONG to LONG.</p>
<p>3. Change <strong>KeReadStateSemaphore</strong> to return a LONG
rather than a ULONG.</p>
<p>4. Change <strong>KeReleaseSemaphore</strong> to return a LONG rather
than a ULONG and change the type of the <em>Adjustment</em> parameters
from ULONG to LONG.</p>
<p>5. Set the value of a semaphore to the maximum value if an attempt is
made to adjust the count of a semaphore above the limit.</p>
<p>6. Add system startup routine to <strong>KeInitializeThread</strong>
for executive level initialization.</p>
<p>7. Change the wait functions to return NTSTATUS rather than
ULONG.</p>
<p>8. Change the type of the <em>WaitType</em> parameter from KWAIT_TYPE
to WAIT_TYPE.</p>
<p>Revision 1.5, May 8, 1989</p>
<p>1. Change data type of the <strong>KeBugCheck</strong> parameter to
ULONG.</p>
<p>2. Add <em>Invalid</em> parameter to <strong>KeFlushEntireTb</strong>
and <strong>KeFlushSingleTb</strong> to allow specification of why the
flush is being performed.</p>
<p>Revision 1.6, August 14, 1989</p>
<p>1. General correction of typos and grammatical errors as suggested by
Helenc review. Clarification and rewrite of several sections.</p>
<p>2. Reorganization of section 1.0 with the deletion of redundant
information.</p>
<p>3. Added miscellaneous functions to get the previous processor mode,
get the current IRQL, and to set the current IRQL.</p>
<p>4. The interrupt object section was extensively rewritten to match
the actual implementation.</p>
<p>5. The time parameter in the <strong>KeDelayExecution</strong>
function was changed to a pointer to a time value.</p>
<p>Revision 1.7, November 15, 1989</p>
<p>1. Delete <strong>KeSetCurrentIrql</strong> function which was an
optimization of the <strong>KeRaiseIrql</strong> function that didn't
require saving the old <strong>IRQL</strong>.</p>
<p>2. Add functions <strong>KeContextToKframes</strong> and
<strong>KeContextFromKframes</strong> to move information in the trap
frame and the exception frame to/from the context frame.</p>
<p>3. Add priority increment parameter to the
<strong>KeInsertQueueApc</strong> function.</p>
<p>4. Change <strong>KeInitializeThread</strong> function to replace the
optional trap and exception frame parameters with an optional context
frame argument. If the context frame parameter is specified, then it is
assumed that the thread will execute in user mode.</p>
<p>5. Change <strong>KeAcquireSpinlock</strong> function to return the
old IRQL as an output parameter and delete the Wait parameter from the
<strong>KeReleaseSpinlock</strong> function.</p>
<p>6. Change <strong>KeInsertDeviceQueue</strong> and
<strong>KeInsertByKeyDevice</strong> functions to neither raise nor
lower IRQL.</p>
<p>7. Split the event object into two types of event objects:
synchronization and notification.</p>
<p>8. Change the definition of the state of an event object to be a
count.</p>
<p>9. Add a parameter to the <strong>KeInitializeApc</strong> function
to specify the APC execution environment. Add a function
(<strong>KeGetApcEnvironment</strong>) that returns the current APC
environment.</p>
<p>Revision 1.8, November 16, 1989</p>
<p>1. Add optional parameter to
<strong>KeWaitForMultipleObjects</strong> that allows more than the
builtin number of objects to be waited on concurrently.</p>
<p>2. Add abandoned return status from
<strong>KeWaitForMultipleObjects</strong> when one or more of the
dispatcher objects satisfying the Wait is an abandoned mutant
object.</p>
<p>3. Add new mutant object which provides for user level mutexes. Add
the functions <strong>KeInitializeMutant</strong>,
<strong>KeReadStateMutant</strong>, and <strong>KeReleaseMutant</strong>
to manipulate the mutant object.</p>
<p>Revision 1.9, November 17, 1989</p>
<p>1. Add <strong>KeRundownThread</strong> function to provide kernel
thread rundown when a thread is deleted.</p>
<p>2. Minor edits and corrections.</p>
<p>Revision 1.10, January 6, 1990</p>
<p>1. Change name of <strong>KeReadSystemTime</strong> to
<strong>KeQuerySystemTime</strong>.</p>
<p>2. Add miscellaneous kernel function
(<strong>KeSetSystemTime</strong>) to set the system time.</p>
<p>Revision 1.11, June 6, 1990</p>
<p>1. Change text that explains how a binary semaphore can be used like
a synchronization event to include a statement that the semaphore cannot
be over Signaled.</p>
<p>2. Change the definition of <strong>KeInitializeSemaphore</strong> to
omit any checks on the limit and initial value of the semaphore.</p>
<p>3. Change the semantics of release semaphore such that an attempt to
over Signal the semaphore does not cause the current count to be set to
the maximum value. The current count remains unchanged and the exception
STATUS_SEMAPHORE_COUNT_EXCEEDED is raised.</p>
<p>4. Once set, the abandoned status of a mutant object cannot be
cleared and will continually be returned by the kernel wait services.
The mutant object, however, will continue to function and ownership can
be requested and released.</p>
<p>5. If an attempt is made to release a mutant object by a nonowner
with the Abandoned parameter FALSE, then either the exception
STATUS_ABANDONED or STATUS_MUTANT_NOT_OWNED will be raised.</p>
<p>6. Remove the hard assignment of Interrupt Request Levels (IRQL's) to
kernel functions and replace with symbolic assignments. Explain that
IRQL's are hierarchically ordered by priority.</p>
<p>7. Change the return type of <strong>KeResumeThread</strong> and
<strong>KeSuspendThread</strong> to ULONG.</p>
<p>8. An attempt to suspend a thread more than MAXIMUM_SUSPEND_COUNT
times causes the exception STATUS_SUSPEND_COUNT_EXCEEDED to be
raised.</p>
<p>9. Add <strong>KeFreezeThread</strong> and
<strong>KeUnfreezeThread</strong> functions to suspend and resume a
thread on behalf of the system. These functions are identical to suspend
and resume, but are not exported to user mode.</p>
<p>10. Add <strong>KeRundownThread</strong> function to run down
appropriate kernel data structures before thread termination.</p>
<p>11. Add <strong>KeStallExecution</strong> function to enable
executive software to stall execution for short periods of time.</p>
<p>12. Add <strong>KeFlushIoBuffers</strong> function to flush the
memory region occupied by an I/O buffer from the data and instruction
caches.</p>
<p>13. Remove text that described the <strong>KeFlushIcache</strong> and
<strong>KeFlushDcache</strong> functions as intended for use in systems
in which DMA I/O operations do not invalidate caches.</p>
<p>14. Add <strong>KeFillEntryTb</strong> function to update TB entries
in systems with software-managed translation buffers.</p>
<p>15. Make explanation of thread context more general and not specific
to the Intel i860.</p>
<p>Revision 1.12, September 19, 1990 (Bryan Willman)</p>
<p>1. Add Profile object section.</p>
<p>Revision 1.13, March 11, 1991</p>
<p>1. Change the operation of the power notify object so that a DPC
object is not required and make the operation repeatable.</p>
<p>2. Add parameter to <strong>KeInitializeProcess</strong> to specific
the default data alignment handling mode for children threads.</p>
<p>3. Add <strong>KeSetAutoAlignmentThread</strong> and
<strong>KeQueryAutoAlignmentThread</strong> functions to set and query
the data alignment handling mode of the current thread.</p>
<p>4. Change the name of the <strong>KeDelayExecution</strong> function
to <strong>KeDelayExecutionThread</strong> and move the explanatory text
to the section on thread objects.</p>
<p>5. Change the name of the <strong>KeStallExecution</strong> function
to <strong>KeStallExecutionProcessor</strong>.</p>
<p>6. Change REQUEST_LEVEL with IPI_LEVEL.</p>
<p>7. Add <strong>KeQueryBasePriorityThread</strong> and
<strong>KeSetBasePriorityThread</strong> functions to set and query the
base priority of a thread object.</p>
<p>Revision 1.14, May 2, 1991</p>
<p>1. Add x86 specific section, Ke386SetLdtProcess and
Ke386SetDescriptorProcess.</p>
<p>Revision 1.15, May 28, 1991 (daveh)</p>
<p>1. Added Ke386GetThreadGdt</p>
<p>Revision 1.16, June 18, 1991 (bryanwi)</p>
<p>1. Added ShareVector parameter to KeInitializeInterrupt.</p>
<p>2. Applied spelling checker to document.</p>
<p>Revision 1.17, August 7, 1991 (shielint)</p>
<p>1. Made KeFlushSingleTb spec match reality</p>
<p>Revision 1.18, August 8, 1991 (bryanwi)</p>
<p>1. Removed coordinator, added SynchronizeIrql to
KeInitializeInterrupt.</p>
